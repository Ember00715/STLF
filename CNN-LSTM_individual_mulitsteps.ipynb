{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ceba72d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25718, 88)\n",
      "       var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  var6(t-10)  \\\n",
      "10       0.087928         0.0    0.000000    0.433333    0.545455    0.673469   \n",
      "11       0.015545         0.0    0.021277    0.433333    0.545455    0.673469   \n",
      "12       0.028905         0.0    0.042553    0.433333    0.545455    0.673469   \n",
      "13       0.005587         0.0    0.063830    0.433333    0.545455    0.667639   \n",
      "14       0.034005         0.0    0.085106    0.433333    0.545455    0.661808   \n",
      "...           ...         ...         ...         ...         ...         ...   \n",
      "25723    0.056352         1.0    0.702128    1.000000    1.000000    0.524781   \n",
      "25724    0.050765         1.0    0.723404    1.000000    1.000000    0.518950   \n",
      "25725    0.068496         1.0    0.744681    1.000000    1.000000    0.518950   \n",
      "25726    0.042750         1.0    0.765957    1.000000    1.000000    0.518950   \n",
      "25727    0.022589         1.0    0.787234    1.000000    1.000000    0.510204   \n",
      "\n",
      "       var7(t-10)  var8(t-10)  var1(t-9)  var2(t-9)  ...  var7(t-1)  \\\n",
      "10          0.930    0.166667   0.015545        0.0  ...      0.975   \n",
      "11          0.910    0.166667   0.028905        0.0  ...      0.990   \n",
      "12          0.890    0.222222   0.005587        0.0  ...      0.980   \n",
      "13          0.910    0.222222   0.034005        0.0  ...      0.970   \n",
      "14          0.930    0.111111   0.008744        0.0  ...      0.935   \n",
      "...           ...         ...        ...        ...  ...        ...   \n",
      "25723       0.795    0.055556   0.050765        1.0  ...      0.890   \n",
      "25724       0.810    0.000000   0.068496        1.0  ...      0.875   \n",
      "25725       0.800    0.000000   0.042750        1.0  ...      0.860   \n",
      "25726       0.790    0.055556   0.022589        1.0  ...      0.850   \n",
      "25727       0.820    0.055556   0.028419        1.0  ...      0.840   \n",
      "\n",
      "       var8(t-1)   var1(t)  var2(t)   var3(t)   var4(t)   var5(t)   var6(t)  \\\n",
      "10      0.111111  0.003643      0.0  0.212766  0.433333  0.545455  0.612245   \n",
      "11      0.111111  0.032062      0.0  0.234043  0.433333  0.545455  0.651604   \n",
      "12      0.111111  0.013116      0.0  0.255319  0.433333  0.545455  0.690962   \n",
      "13      0.111111  0.019917      0.0  0.276596  0.433333  0.545455  0.709913   \n",
      "14      0.111111  0.025018      0.0  0.297872  0.433333  0.545455  0.728863   \n",
      "...          ...       ...      ...       ...       ...       ...       ...   \n",
      "25723   0.055556  0.020403      1.0  0.914894  1.000000  1.000000  0.491254   \n",
      "25724   0.055556  0.028176      1.0  0.936170  1.000000  1.000000  0.492711   \n",
      "25725   0.111111  0.035706      1.0  0.957447  1.000000  1.000000  0.492711   \n",
      "25726   0.111111  0.062667      1.0  0.978723  1.000000  1.000000  0.492711   \n",
      "25727   0.111111  0.068011      1.0  1.000000  1.000000  1.000000  0.492711   \n",
      "\n",
      "       var7(t)   var8(t)  \n",
      "10       0.990  0.111111  \n",
      "11       0.980  0.111111  \n",
      "12       0.970  0.111111  \n",
      "13       0.935  0.111111  \n",
      "14       0.900  0.166667  \n",
      "...        ...       ...  \n",
      "25723    0.875  0.055556  \n",
      "25724    0.860  0.111111  \n",
      "25725    0.850  0.111111  \n",
      "25726    0.840  0.111111  \n",
      "25727    0.840  0.111111  \n",
      "\n",
      "[25718 rows x 88 columns]\n",
      "(25391, 80) 25391 (25391,)\n",
      "(25391, 10, 8) (25391,) (327, 10, 8) (327,)\n",
      "Epoch 1/200\n",
      "556/556 - 7s - loss: 0.0331 - mape: 7262.1567 - val_loss: 0.0350 - val_mape: 3475.6284\n",
      "Epoch 2/200\n",
      "556/556 - 5s - loss: 0.0282 - mape: 8090.4824 - val_loss: 0.0332 - val_mape: 3603.1226\n",
      "Epoch 3/200\n",
      "556/556 - 4s - loss: 0.0248 - mape: 6942.3369 - val_loss: 0.0255 - val_mape: 4003.9148\n",
      "Epoch 4/200\n",
      "556/556 - 4s - loss: 0.0230 - mape: 5469.5410 - val_loss: 0.0255 - val_mape: 3967.2227\n",
      "Epoch 5/200\n",
      "556/556 - 4s - loss: 0.0224 - mape: 5649.8706 - val_loss: 0.0232 - val_mape: 4136.4751\n",
      "Epoch 6/200\n",
      "556/556 - 4s - loss: 0.0221 - mape: 4289.0024 - val_loss: 0.0242 - val_mape: 3996.7058\n",
      "Epoch 7/200\n",
      "556/556 - 4s - loss: 0.0216 - mape: 4580.5684 - val_loss: 0.0216 - val_mape: 3926.9358\n",
      "Epoch 8/200\n",
      "556/556 - 4s - loss: 0.0215 - mape: 4529.7642 - val_loss: 0.0226 - val_mape: 4113.0601\n",
      "Epoch 9/200\n",
      "556/556 - 4s - loss: 0.0214 - mape: 3930.9119 - val_loss: 0.0222 - val_mape: 3861.7656\n",
      "Epoch 10/200\n",
      "556/556 - 4s - loss: 0.0213 - mape: 4123.9795 - val_loss: 0.0228 - val_mape: 3982.1311\n",
      "Epoch 11/200\n",
      "556/556 - 4s - loss: 0.0214 - mape: 4890.7231 - val_loss: 0.0203 - val_mape: 4076.3918\n",
      "Epoch 12/200\n",
      "556/556 - 4s - loss: 0.0211 - mape: 4056.0459 - val_loss: 0.0204 - val_mape: 3994.8887\n",
      "Epoch 13/200\n",
      "556/556 - 4s - loss: 0.0209 - mape: 4181.0615 - val_loss: 0.0200 - val_mape: 4141.8911\n",
      "Epoch 14/200\n",
      "556/556 - 4s - loss: 0.0209 - mape: 3874.9385 - val_loss: 0.0204 - val_mape: 3749.9141\n",
      "Epoch 15/200\n",
      "556/556 - 4s - loss: 0.0208 - mape: 4141.4814 - val_loss: 0.0207 - val_mape: 3822.3857\n",
      "Epoch 16/200\n",
      "556/556 - 4s - loss: 0.0208 - mape: 4006.1243 - val_loss: 0.0216 - val_mape: 3914.0459\n",
      "Epoch 17/200\n",
      "556/556 - 4s - loss: 0.0208 - mape: 4184.7441 - val_loss: 0.0200 - val_mape: 4057.3464\n",
      "Epoch 18/200\n",
      "556/556 - 5s - loss: 0.0207 - mape: 4051.6243 - val_loss: 0.0205 - val_mape: 3872.1353\n",
      "Epoch 19/200\n",
      "556/556 - 5s - loss: 0.0206 - mape: 3895.1768 - val_loss: 0.0214 - val_mape: 3761.1465\n",
      "Epoch 20/200\n",
      "556/556 - 5s - loss: 0.0205 - mape: 3982.2761 - val_loss: 0.0214 - val_mape: 3723.6721\n",
      "Epoch 21/200\n",
      "556/556 - 5s - loss: 0.0204 - mape: 4162.2202 - val_loss: 0.0210 - val_mape: 4431.1978\n",
      "Epoch 22/200\n",
      "556/556 - 5s - loss: 0.0204 - mape: 3982.8225 - val_loss: 0.0202 - val_mape: 4164.0474\n",
      "Epoch 23/200\n",
      "556/556 - 4s - loss: 0.0203 - mape: 4401.9209 - val_loss: 0.0214 - val_mape: 3881.3931\n",
      "Epoch 24/200\n",
      "556/556 - 5s - loss: 0.0203 - mape: 3952.2295 - val_loss: 0.0207 - val_mape: 4063.9053\n",
      "Epoch 25/200\n",
      "556/556 - 5s - loss: 0.0203 - mape: 4078.4722 - val_loss: 0.0201 - val_mape: 4015.1936\n",
      "Epoch 26/200\n",
      "556/556 - 5s - loss: 0.0201 - mape: 3978.4612 - val_loss: 0.0206 - val_mape: 4165.7891\n",
      "Epoch 27/200\n",
      "556/556 - 5s - loss: 0.0201 - mape: 3978.8438 - val_loss: 0.0203 - val_mape: 3938.1990\n",
      "Epoch 28/200\n",
      "556/556 - 5s - loss: 0.0200 - mape: 3810.5098 - val_loss: 0.0203 - val_mape: 4220.3750\n",
      "Epoch 29/200\n",
      "556/556 - 4s - loss: 0.0201 - mape: 3870.7383 - val_loss: 0.0202 - val_mape: 4835.1509\n",
      "Epoch 30/200\n",
      "556/556 - 5s - loss: 0.0199 - mape: 3918.2891 - val_loss: 0.0203 - val_mape: 4027.6072\n",
      "Epoch 31/200\n",
      "556/556 - 5s - loss: 0.0199 - mape: 3819.4768 - val_loss: 0.0201 - val_mape: 3929.5188\n",
      "Epoch 32/200\n",
      "556/556 - 5s - loss: 0.0199 - mape: 3943.6863 - val_loss: 0.0202 - val_mape: 4003.3928\n",
      "Epoch 33/200\n",
      "556/556 - 5s - loss: 0.0198 - mape: 4283.9019 - val_loss: 0.0202 - val_mape: 3980.7603\n",
      "Epoch 34/200\n",
      "556/556 - 5s - loss: 0.0198 - mape: 3965.4465 - val_loss: 0.0198 - val_mape: 3742.9890\n",
      "Epoch 35/200\n",
      "556/556 - 5s - loss: 0.0198 - mape: 3771.9932 - val_loss: 0.0196 - val_mape: 4650.6675\n",
      "Epoch 36/200\n",
      "556/556 - 5s - loss: 0.0196 - mape: 4114.5742 - val_loss: 0.0199 - val_mape: 3993.4124\n",
      "Epoch 37/200\n",
      "556/556 - 5s - loss: 0.0197 - mape: 3793.0127 - val_loss: 0.0201 - val_mape: 3811.6597\n",
      "Epoch 38/200\n",
      "556/556 - 5s - loss: 0.0194 - mape: 4191.4683 - val_loss: 0.0207 - val_mape: 4500.0596\n",
      "Epoch 39/200\n",
      "556/556 - 5s - loss: 0.0195 - mape: 3895.9658 - val_loss: 0.0202 - val_mape: 4734.6826\n",
      "Epoch 40/200\n",
      "556/556 - 5s - loss: 0.0196 - mape: 4096.0938 - val_loss: 0.0198 - val_mape: 3894.3669\n",
      "Epoch 41/200\n",
      "556/556 - 5s - loss: 0.0195 - mape: 3915.9426 - val_loss: 0.0208 - val_mape: 4010.1355\n",
      "Epoch 42/200\n",
      "556/556 - 5s - loss: 0.0195 - mape: 4253.9541 - val_loss: 0.0202 - val_mape: 4053.7107\n",
      "Epoch 43/200\n",
      "556/556 - 4s - loss: 0.0195 - mape: 4337.3047 - val_loss: 0.0199 - val_mape: 4851.5161\n",
      "Epoch 44/200\n",
      "556/556 - 5s - loss: 0.0194 - mape: 4292.2896 - val_loss: 0.0209 - val_mape: 4429.9746\n",
      "Epoch 45/200\n",
      "556/556 - 5s - loss: 0.0195 - mape: 4153.3335 - val_loss: 0.0201 - val_mape: 4649.8115\n",
      "Epoch 46/200\n",
      "556/556 - 5s - loss: 0.0194 - mape: 4470.2886 - val_loss: 0.0206 - val_mape: 4498.1587\n",
      "Epoch 47/200\n",
      "556/556 - 5s - loss: 0.0192 - mape: 4327.4585 - val_loss: 0.0200 - val_mape: 4382.1489\n",
      "Epoch 48/200\n",
      "556/556 - 5s - loss: 0.0193 - mape: 4705.8252 - val_loss: 0.0198 - val_mape: 5039.2319\n",
      "Epoch 49/200\n",
      "556/556 - 5s - loss: 0.0192 - mape: 4164.0635 - val_loss: 0.0201 - val_mape: 5010.2290\n",
      "Epoch 50/200\n",
      "556/556 - 5s - loss: 0.0192 - mape: 4675.1016 - val_loss: 0.0199 - val_mape: 5150.6982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200\n",
      "556/556 - 5s - loss: 0.0191 - mape: 4373.1689 - val_loss: 0.0196 - val_mape: 5470.4946\n",
      "Epoch 52/200\n",
      "556/556 - 5s - loss: 0.0191 - mape: 4576.2646 - val_loss: 0.0192 - val_mape: 5042.9014\n",
      "Epoch 53/200\n",
      "556/556 - 5s - loss: 0.0191 - mape: 4415.0244 - val_loss: 0.0195 - val_mape: 5128.6240\n",
      "Epoch 54/200\n",
      "556/556 - 5s - loss: 0.0188 - mape: 4593.0913 - val_loss: 0.0204 - val_mape: 5128.8076\n",
      "Epoch 55/200\n",
      "556/556 - 5s - loss: 0.0189 - mape: 3865.4373 - val_loss: 0.0198 - val_mape: 5025.9102\n",
      "Epoch 56/200\n",
      "556/556 - 5s - loss: 0.0188 - mape: 4453.1152 - val_loss: 0.0202 - val_mape: 5143.0415\n",
      "Epoch 57/200\n",
      "556/556 - 4s - loss: 0.0189 - mape: 3620.2439 - val_loss: 0.0199 - val_mape: 5028.0376\n",
      "Epoch 58/200\n",
      "556/556 - 4s - loss: 0.0187 - mape: 4534.9878 - val_loss: 0.0195 - val_mape: 5200.0293\n",
      "Epoch 59/200\n",
      "556/556 - 5s - loss: 0.0187 - mape: 4204.3223 - val_loss: 0.0197 - val_mape: 5448.4067\n",
      "Epoch 60/200\n",
      "556/556 - 5s - loss: 0.0186 - mape: 4156.1768 - val_loss: 0.0194 - val_mape: 5111.7729\n",
      "Epoch 61/200\n",
      "556/556 - 5s - loss: 0.0187 - mape: 4399.8066 - val_loss: 0.0200 - val_mape: 5354.6997\n",
      "Epoch 62/200\n",
      "556/556 - 4s - loss: 0.0186 - mape: 3891.6384 - val_loss: 0.0195 - val_mape: 5445.6846\n",
      "Epoch 63/200\n",
      "556/556 - 5s - loss: 0.0184 - mape: 3717.8818 - val_loss: 0.0197 - val_mape: 5247.9917\n",
      "Epoch 64/200\n",
      "556/556 - 4s - loss: 0.0184 - mape: 3720.5364 - val_loss: 0.0192 - val_mape: 5312.7949\n",
      "Epoch 65/200\n",
      "556/556 - 5s - loss: 0.0184 - mape: 3915.3879 - val_loss: 0.0200 - val_mape: 5576.9536\n",
      "Epoch 66/200\n",
      "556/556 - 4s - loss: 0.0184 - mape: 4231.7500 - val_loss: 0.0197 - val_mape: 5589.7749\n",
      "Epoch 67/200\n",
      "556/556 - 5s - loss: 0.0184 - mape: 3975.8618 - val_loss: 0.0199 - val_mape: 5680.8960\n",
      "Epoch 68/200\n",
      "556/556 - 5s - loss: 0.0182 - mape: 3915.7544 - val_loss: 0.0205 - val_mape: 5558.6895\n",
      "Epoch 69/200\n",
      "556/556 - 5s - loss: 0.0182 - mape: 4203.0864 - val_loss: 0.0201 - val_mape: 5514.8682\n",
      "Epoch 70/200\n",
      "556/556 - 5s - loss: 0.0182 - mape: 3868.6318 - val_loss: 0.0201 - val_mape: 5258.3076\n",
      "Epoch 71/200\n",
      "556/556 - 5s - loss: 0.0181 - mape: 4065.2654 - val_loss: 0.0196 - val_mape: 5920.0640\n",
      "Epoch 72/200\n",
      "556/556 - 5s - loss: 0.0181 - mape: 4366.6758 - val_loss: 0.0196 - val_mape: 5402.7876\n",
      "Epoch 73/200\n",
      "556/556 - 5s - loss: 0.0181 - mape: 3850.0076 - val_loss: 0.0197 - val_mape: 5796.1772\n",
      "Epoch 74/200\n",
      "556/556 - 5s - loss: 0.0180 - mape: 3844.1074 - val_loss: 0.0192 - val_mape: 5730.2490\n",
      "Epoch 75/200\n",
      "556/556 - 4s - loss: 0.0180 - mape: 4140.5146 - val_loss: 0.0190 - val_mape: 5232.2139\n",
      "Epoch 76/200\n",
      "556/556 - 4s - loss: 0.0179 - mape: 3755.9680 - val_loss: 0.0197 - val_mape: 5770.5020\n",
      "Epoch 77/200\n",
      "556/556 - 4s - loss: 0.0178 - mape: 4625.9570 - val_loss: 0.0198 - val_mape: 5632.7974\n",
      "Epoch 78/200\n",
      "556/556 - 4s - loss: 0.0180 - mape: 3851.0938 - val_loss: 0.0195 - val_mape: 5324.9492\n",
      "Epoch 79/200\n",
      "556/556 - 4s - loss: 0.0177 - mape: 3770.7434 - val_loss: 0.0195 - val_mape: 5869.8042\n",
      "Epoch 80/200\n",
      "556/556 - 4s - loss: 0.0177 - mape: 4431.5117 - val_loss: 0.0199 - val_mape: 5608.8652\n",
      "Epoch 81/200\n",
      "556/556 - 4s - loss: 0.0178 - mape: 3784.8579 - val_loss: 0.0199 - val_mape: 5417.9146\n",
      "Epoch 82/200\n",
      "556/556 - 4s - loss: 0.0177 - mape: 4148.0112 - val_loss: 0.0192 - val_mape: 5570.7217\n",
      "Epoch 83/200\n",
      "556/556 - 5s - loss: 0.0177 - mape: 4004.0398 - val_loss: 0.0195 - val_mape: 5365.2632\n",
      "Epoch 84/200\n",
      "556/556 - 5s - loss: 0.0178 - mape: 3963.5996 - val_loss: 0.0204 - val_mape: 5264.6631\n",
      "Epoch 85/200\n",
      "556/556 - 5s - loss: 0.0176 - mape: 4200.9897 - val_loss: 0.0200 - val_mape: 5479.8105\n",
      "Epoch 86/200\n",
      "556/556 - 5s - loss: 0.0177 - mape: 4555.9404 - val_loss: 0.0200 - val_mape: 5382.7896\n",
      "Epoch 87/200\n",
      "556/556 - 4s - loss: 0.0177 - mape: 4142.6577 - val_loss: 0.0200 - val_mape: 5751.8804\n",
      "Epoch 88/200\n",
      "556/556 - 4s - loss: 0.0175 - mape: 4654.8511 - val_loss: 0.0197 - val_mape: 5559.6025\n",
      "Epoch 89/200\n",
      "556/556 - 4s - loss: 0.0175 - mape: 4139.1128 - val_loss: 0.0198 - val_mape: 5764.7905\n",
      "Epoch 90/200\n",
      "556/556 - 4s - loss: 0.0175 - mape: 4522.4653 - val_loss: 0.0195 - val_mape: 5379.6958\n",
      "Epoch 91/200\n",
      "556/556 - 4s - loss: 0.0175 - mape: 4340.9165 - val_loss: 0.0200 - val_mape: 5556.2515\n",
      "Epoch 92/200\n",
      "556/556 - 4s - loss: 0.0174 - mape: 3984.8655 - val_loss: 0.0201 - val_mape: 5662.4028\n",
      "Epoch 93/200\n",
      "556/556 - 4s - loss: 0.0175 - mape: 3820.0366 - val_loss: 0.0199 - val_mape: 5561.8076\n",
      "Epoch 94/200\n",
      "556/556 - 4s - loss: 0.0173 - mape: 4258.0601 - val_loss: 0.0196 - val_mape: 5603.1064\n",
      "Epoch 95/200\n",
      "556/556 - 4s - loss: 0.0172 - mape: 4333.0078 - val_loss: 0.0204 - val_mape: 5437.5596\n",
      "Epoch 96/200\n",
      "556/556 - 4s - loss: 0.0175 - mape: 4416.9473 - val_loss: 0.0206 - val_mape: 5407.6021\n",
      "Epoch 97/200\n",
      "556/556 - 5s - loss: 0.0174 - mape: 4229.2554 - val_loss: 0.0201 - val_mape: 5651.1436\n",
      "Epoch 98/200\n",
      "556/556 - 5s - loss: 0.0173 - mape: 4042.5471 - val_loss: 0.0201 - val_mape: 5583.0688\n",
      "Epoch 99/200\n",
      "556/556 - 4s - loss: 0.0173 - mape: 4212.4736 - val_loss: 0.0198 - val_mape: 5767.9150\n",
      "Epoch 100/200\n",
      "556/556 - 4s - loss: 0.0174 - mape: 4187.2300 - val_loss: 0.0202 - val_mape: 5442.4165\n",
      "Epoch 101/200\n",
      "556/556 - 5s - loss: 0.0172 - mape: 4209.7559 - val_loss: 0.0202 - val_mape: 5695.0962\n",
      "Epoch 102/200\n",
      "556/556 - 5s - loss: 0.0173 - mape: 4036.5808 - val_loss: 0.0199 - val_mape: 5853.8413\n",
      "Epoch 103/200\n",
      "556/556 - 5s - loss: 0.0171 - mape: 4221.7471 - val_loss: 0.0202 - val_mape: 5702.3789\n",
      "Epoch 104/200\n",
      "556/556 - 5s - loss: 0.0171 - mape: 4269.8232 - val_loss: 0.0207 - val_mape: 5594.5225\n",
      "Epoch 105/200\n",
      "556/556 - 5s - loss: 0.0171 - mape: 4105.4521 - val_loss: 0.0205 - val_mape: 5465.5898\n",
      "Epoch 106/200\n",
      "556/556 - 5s - loss: 0.0171 - mape: 4351.0835 - val_loss: 0.0206 - val_mape: 5717.7959\n",
      "Epoch 107/200\n",
      "556/556 - 5s - loss: 0.0170 - mape: 4086.5969 - val_loss: 0.0200 - val_mape: 5626.8452\n",
      "Epoch 108/200\n",
      "556/556 - 5s - loss: 0.0169 - mape: 4208.2334 - val_loss: 0.0206 - val_mape: 5553.6294\n",
      "Epoch 109/200\n",
      "556/556 - 5s - loss: 0.0171 - mape: 4149.2461 - val_loss: 0.0204 - val_mape: 5231.6782\n",
      "Epoch 110/200\n",
      "556/556 - 5s - loss: 0.0169 - mape: 4444.0942 - val_loss: 0.0206 - val_mape: 5508.0430\n",
      "Epoch 111/200\n",
      "556/556 - 5s - loss: 0.0170 - mape: 3625.8684 - val_loss: 0.0201 - val_mape: 5200.5078\n",
      "Epoch 112/200\n",
      "556/556 - 5s - loss: 0.0170 - mape: 4432.3726 - val_loss: 0.0204 - val_mape: 5583.1870\n",
      "Epoch 113/200\n",
      "556/556 - 5s - loss: 0.0171 - mape: 4298.8174 - val_loss: 0.0201 - val_mape: 5370.2192\n",
      "Epoch 114/200\n",
      "556/556 - 5s - loss: 0.0169 - mape: 4378.7290 - val_loss: 0.0204 - val_mape: 5552.5498\n",
      "Epoch 115/200\n",
      "556/556 - 5s - loss: 0.0169 - mape: 4146.5757 - val_loss: 0.0204 - val_mape: 5576.1553\n",
      "Epoch 116/200\n",
      "556/556 - 5s - loss: 0.0168 - mape: 4193.7139 - val_loss: 0.0204 - val_mape: 5266.4517\n",
      "Epoch 117/200\n",
      "556/556 - 5s - loss: 0.0168 - mape: 4271.2065 - val_loss: 0.0199 - val_mape: 5336.8228\n",
      "Epoch 118/200\n",
      "556/556 - 5s - loss: 0.0169 - mape: 4270.8491 - val_loss: 0.0199 - val_mape: 5501.1704\n",
      "Epoch 119/200\n",
      "556/556 - 5s - loss: 0.0167 - mape: 4344.2109 - val_loss: 0.0201 - val_mape: 5408.8154\n",
      "Epoch 120/200\n",
      "556/556 - 5s - loss: 0.0168 - mape: 4267.0308 - val_loss: 0.0206 - val_mape: 5636.5894\n",
      "Epoch 121/200\n",
      "556/556 - 5s - loss: 0.0167 - mape: 4058.2439 - val_loss: 0.0200 - val_mape: 5497.6226\n",
      "Epoch 122/200\n",
      "556/556 - 5s - loss: 0.0168 - mape: 4556.5811 - val_loss: 0.0199 - val_mape: 5342.8589\n",
      "Epoch 123/200\n",
      "556/556 - 5s - loss: 0.0167 - mape: 4182.0244 - val_loss: 0.0198 - val_mape: 5149.7568\n",
      "Epoch 124/200\n",
      "556/556 - 5s - loss: 0.0167 - mape: 4317.3188 - val_loss: 0.0198 - val_mape: 5328.2188\n",
      "Epoch 125/200\n",
      "556/556 - 5s - loss: 0.0166 - mape: 3982.6924 - val_loss: 0.0202 - val_mape: 5458.7881\n",
      "Epoch 126/200\n",
      "556/556 - 5s - loss: 0.0167 - mape: 3959.9146 - val_loss: 0.0201 - val_mape: 5314.9585\n",
      "Epoch 127/200\n",
      "556/556 - 5s - loss: 0.0166 - mape: 4282.2925 - val_loss: 0.0203 - val_mape: 5019.7749\n",
      "Epoch 128/200\n",
      "556/556 - 5s - loss: 0.0166 - mape: 4294.1558 - val_loss: 0.0201 - val_mape: 5270.5415\n",
      "Epoch 129/200\n",
      "556/556 - 5s - loss: 0.0166 - mape: 4244.4214 - val_loss: 0.0199 - val_mape: 5209.2065\n",
      "Epoch 130/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 3899.9922 - val_loss: 0.0206 - val_mape: 5214.0283\n",
      "Epoch 131/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 4585.0239 - val_loss: 0.0204 - val_mape: 4960.9404\n",
      "Epoch 132/200\n",
      "556/556 - 5s - loss: 0.0166 - mape: 4323.5854 - val_loss: 0.0201 - val_mape: 5382.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 3961.6011 - val_loss: 0.0201 - val_mape: 4779.3521\n",
      "Epoch 134/200\n",
      "556/556 - 5s - loss: 0.0166 - mape: 4337.7168 - val_loss: 0.0202 - val_mape: 5294.9482\n",
      "Epoch 135/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 4308.2954 - val_loss: 0.0207 - val_mape: 5299.4395\n",
      "Epoch 136/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 4525.0347 - val_loss: 0.0203 - val_mape: 5152.7017\n",
      "Epoch 137/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 4480.2681 - val_loss: 0.0203 - val_mape: 5483.8604\n",
      "Epoch 138/200\n",
      "556/556 - 5s - loss: 0.0164 - mape: 4335.0063 - val_loss: 0.0200 - val_mape: 5376.4731\n",
      "Epoch 139/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 4038.1450 - val_loss: 0.0204 - val_mape: 5432.9238\n",
      "Epoch 140/200\n",
      "556/556 - 5s - loss: 0.0164 - mape: 4165.1987 - val_loss: 0.0200 - val_mape: 5139.1289\n",
      "Epoch 141/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 4426.8394 - val_loss: 0.0199 - val_mape: 5353.4629\n",
      "Epoch 142/200\n",
      "556/556 - 4s - loss: 0.0164 - mape: 4122.2544 - val_loss: 0.0200 - val_mape: 5041.9204\n",
      "Epoch 143/200\n",
      "556/556 - 5s - loss: 0.0165 - mape: 4569.0806 - val_loss: 0.0200 - val_mape: 5299.6646\n",
      "Epoch 144/200\n",
      "556/556 - 5s - loss: 0.0162 - mape: 4491.9785 - val_loss: 0.0202 - val_mape: 5534.6646\n",
      "Epoch 145/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 4320.0459 - val_loss: 0.0205 - val_mape: 5249.5063\n",
      "Epoch 146/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 3750.1167 - val_loss: 0.0197 - val_mape: 5354.6475\n",
      "Epoch 147/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 4139.2480 - val_loss: 0.0203 - val_mape: 5188.3501\n",
      "Epoch 148/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 4157.8296 - val_loss: 0.0202 - val_mape: 5209.6494\n",
      "Epoch 149/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 3959.8577 - val_loss: 0.0197 - val_mape: 5109.3887\n",
      "Epoch 150/200\n",
      "556/556 - 5s - loss: 0.0162 - mape: 4429.1792 - val_loss: 0.0203 - val_mape: 5181.0063\n",
      "Epoch 151/200\n",
      "556/556 - 5s - loss: 0.0163 - mape: 4117.8950 - val_loss: 0.0199 - val_mape: 5542.1123\n",
      "Epoch 152/200\n",
      "556/556 - 5s - loss: 0.0161 - mape: 4553.5176 - val_loss: 0.0198 - val_mape: 5156.2671\n",
      "Epoch 153/200\n",
      "556/556 - 4s - loss: 0.0162 - mape: 3996.7617 - val_loss: 0.0204 - val_mape: 5070.4795\n",
      "Epoch 154/200\n",
      "556/556 - 4s - loss: 0.0162 - mape: 4590.7080 - val_loss: 0.0211 - val_mape: 5278.3384\n",
      "Epoch 155/200\n",
      "556/556 - 4s - loss: 0.0161 - mape: 4185.0332 - val_loss: 0.0200 - val_mape: 5309.0195\n",
      "Epoch 156/200\n",
      "556/556 - 4s - loss: 0.0162 - mape: 4282.4751 - val_loss: 0.0207 - val_mape: 5168.1885\n",
      "Epoch 157/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4207.3760 - val_loss: 0.0202 - val_mape: 5329.8477\n",
      "Epoch 158/200\n",
      "556/556 - 4s - loss: 0.0162 - mape: 4518.8760 - val_loss: 0.0203 - val_mape: 5132.0347\n",
      "Epoch 159/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4343.1567 - val_loss: 0.0198 - val_mape: 5294.8306\n",
      "Epoch 160/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4337.9932 - val_loss: 0.0201 - val_mape: 5134.1377\n",
      "Epoch 161/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4211.0527 - val_loss: 0.0202 - val_mape: 5182.1152\n",
      "Epoch 162/200\n",
      "556/556 - 5s - loss: 0.0160 - mape: 4152.6055 - val_loss: 0.0202 - val_mape: 5099.1035\n",
      "Epoch 163/200\n",
      "556/556 - 4s - loss: 0.0161 - mape: 4270.1206 - val_loss: 0.0203 - val_mape: 5122.0913\n",
      "Epoch 164/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4345.6069 - val_loss: 0.0202 - val_mape: 5425.3271\n",
      "Epoch 165/200\n",
      "556/556 - 4s - loss: 0.0161 - mape: 4432.9155 - val_loss: 0.0207 - val_mape: 5398.0532\n",
      "Epoch 166/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4206.7505 - val_loss: 0.0209 - val_mape: 5288.1074\n",
      "Epoch 167/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4165.1084 - val_loss: 0.0203 - val_mape: 5189.4917\n",
      "Epoch 168/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4078.1711 - val_loss: 0.0207 - val_mape: 5056.6899\n",
      "Epoch 169/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 3974.8269 - val_loss: 0.0207 - val_mape: 5082.3823\n",
      "Epoch 170/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4211.0542 - val_loss: 0.0211 - val_mape: 4918.0303\n",
      "Epoch 171/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4520.6401 - val_loss: 0.0209 - val_mape: 5289.8511\n",
      "Epoch 172/200\n",
      "556/556 - 4s - loss: 0.0161 - mape: 3195.6130 - val_loss: 0.0211 - val_mape: 5337.4844\n",
      "Epoch 173/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4165.9829 - val_loss: 0.0208 - val_mape: 5396.5566\n",
      "Epoch 174/200\n",
      "556/556 - 4s - loss: 0.0161 - mape: 4221.0942 - val_loss: 0.0201 - val_mape: 5080.8003\n",
      "Epoch 175/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 3979.4417 - val_loss: 0.0200 - val_mape: 5156.6709\n",
      "Epoch 176/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4440.2510 - val_loss: 0.0204 - val_mape: 4949.5073\n",
      "Epoch 177/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4085.2849 - val_loss: 0.0208 - val_mape: 5261.7676\n",
      "Epoch 178/200\n",
      "556/556 - 4s - loss: 0.0160 - mape: 4403.7046 - val_loss: 0.0203 - val_mape: 5317.4067\n",
      "Epoch 179/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4026.7520 - val_loss: 0.0207 - val_mape: 5223.7881\n",
      "Epoch 180/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4366.3130 - val_loss: 0.0206 - val_mape: 5170.2456\n",
      "Epoch 181/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4403.1587 - val_loss: 0.0205 - val_mape: 5020.2939\n",
      "Epoch 182/200\n",
      "556/556 - 5s - loss: 0.0160 - mape: 3917.5393 - val_loss: 0.0208 - val_mape: 4953.2524\n",
      "Epoch 183/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4632.5527 - val_loss: 0.0205 - val_mape: 4889.0576\n",
      "Epoch 184/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4171.9365 - val_loss: 0.0207 - val_mape: 5414.7295\n",
      "Epoch 185/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4478.7217 - val_loss: 0.0207 - val_mape: 4766.1406\n",
      "Epoch 186/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4435.9165 - val_loss: 0.0204 - val_mape: 5345.1699\n",
      "Epoch 187/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4058.9590 - val_loss: 0.0210 - val_mape: 5097.3735\n",
      "Epoch 188/200\n",
      "556/556 - 4s - loss: 0.0159 - mape: 4145.1118 - val_loss: 0.0203 - val_mape: 5262.5107\n",
      "Epoch 189/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4450.4565 - val_loss: 0.0207 - val_mape: 5365.5420\n",
      "Epoch 190/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4222.5713 - val_loss: 0.0206 - val_mape: 4886.7734\n",
      "Epoch 191/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4231.0405 - val_loss: 0.0204 - val_mape: 5303.6118\n",
      "Epoch 192/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 3931.7266 - val_loss: 0.0205 - val_mape: 5532.9976\n",
      "Epoch 193/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4378.4624 - val_loss: 0.0205 - val_mape: 5281.4375\n",
      "Epoch 194/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4513.3389 - val_loss: 0.0203 - val_mape: 5445.6274\n",
      "Epoch 195/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4810.4644 - val_loss: 0.0207 - val_mape: 5327.3823\n",
      "Epoch 196/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4298.2974 - val_loss: 0.0211 - val_mape: 5086.0923\n",
      "Epoch 197/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4415.1470 - val_loss: 0.0206 - val_mape: 5188.8774\n",
      "Epoch 198/200\n",
      "556/556 - 4s - loss: 0.0158 - mape: 4628.2427 - val_loss: 0.0208 - val_mape: 5458.3159\n",
      "Epoch 199/200\n",
      "556/556 - 4s - loss: 0.0156 - mape: 4375.5044 - val_loss: 0.0209 - val_mape: 5344.4541\n",
      "Epoch 200/200\n",
      "556/556 - 4s - loss: 0.0157 - mape: 4570.4004 - val_loss: 0.0209 - val_mape: 5276.6367\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.150\n",
      "0.0707943\n",
      "0.6953991\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# load dataset\n",
    "dataset = read_csv('CER_1002.csv', header=0, index_col=0)\n",
    "dataset = dataset.loc[:, ['Power', 'holidays', 'Hour', 'Days', 'Month', 'Temperature', 'humiduity', 'Wind_speed']]\n",
    "values = dataset.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# specify the number of lag hours\n",
    "n_hours = 10\n",
    "n_features = 8\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)\n",
    "print(reframed.shape)\n",
    "print(reframed)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 529 * 48 - 1\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(layers.Conv1D(filters = 48, kernel_size = 3, padding='same', \n",
    "                        activation='relu', kernel_initializer =\"glorot_uniform\"))\n",
    "model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(layers.Conv1D(filters = 32, kernel_size = 3, padding='same', \n",
    "                        activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
    "model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(layers.Conv1D(filters = 16, kernel_size = 3, padding='same', \n",
    "                        activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
    "model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(LSTM(174, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(174, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "#model.add(LSTM(174, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "#model.add(LSTM(123, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(174, return_sequences=False, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "#model.add(Dense(32, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "optimizer = optimizers.Adam(learning_rate=0.0003)\n",
    "model.compile(loss='mae', metrics=['mape'], optimizer=optimizer)\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=200, batch_size=32, validation_split=0.3, \n",
    "                     verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='valiation')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(mean_absolute_error(inv_y, inv_yhat))\n",
    "print(mean_absolute_percentage_error(inv_y, inv_yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1263ac4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "223/223 [==============================] - 3s 6ms/step - loss: 0.0568 - mape: 175.1813 - val_loss: 0.0441 - val_mape: 91.1263\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0552 - mape: 262.4468 - val_loss: 0.0425 - val_mape: 82.1531\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0536 - mape: 350.7730 - val_loss: 0.0409 - val_mape: 73.9139\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0520 - mape: 438.3636 - val_loss: 0.0395 - val_mape: 68.2834\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0506 - mape: 523.9396 - val_loss: 0.0383 - val_mape: 65.4712\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0494 - mape: 608.3530 - val_loss: 0.0373 - val_mape: 64.2286\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0483 - mape: 692.2153 - val_loss: 0.0364 - val_mape: 64.2658\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0473 - mape: 780.9227 - val_loss: 0.0356 - val_mape: 65.1818\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0463 - mape: 864.6729 - val_loss: 0.0349 - val_mape: 66.8369\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0454 - mape: 947.4790 - val_loss: 0.0343 - val_mape: 69.1512\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0445 - mape: 1042.2759 - val_loss: 0.0337 - val_mape: 72.0396\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0437 - mape: 1137.2260 - val_loss: 0.0334 - val_mape: 75.3114\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0430 - mape: 1199.0238 - val_loss: 0.0331 - val_mape: 78.7452\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0424 - mape: 1267.9303 - val_loss: 0.0329 - val_mape: 82.1165\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0419 - mape: 1353.6693 - val_loss: 0.0327 - val_mape: 85.4492\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0414 - mape: 1388.6473 - val_loss: 0.0326 - val_mape: 88.7598\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0410 - mape: 1491.6270 - val_loss: 0.0325 - val_mape: 91.9996\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0406 - mape: 1485.7636 - val_loss: 0.0324 - val_mape: 95.0707\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0403 - mape: 1577.3775 - val_loss: 0.0324 - val_mape: 97.8900\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0400 - mape: 1604.4218 - val_loss: 0.0324 - val_mape: 100.4906\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0398 - mape: 1601.6525 - val_loss: 0.0323 - val_mape: 102.7855\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0396 - mape: 1647.5091 - val_loss: 0.0323 - val_mape: 104.7717\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0394 - mape: 1686.8810 - val_loss: 0.0323 - val_mape: 106.5398\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0393 - mape: 1778.2295 - val_loss: 0.0323 - val_mape: 108.0515\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0392 - mape: 1753.8013 - val_loss: 0.0323 - val_mape: 109.3350\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0391 - mape: 1793.3120 - val_loss: 0.0323 - val_mape: 110.3305\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0391 - mape: 1809.1782 - val_loss: 0.0323 - val_mape: 111.2391\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0390 - mape: 1775.6032 - val_loss: 0.0324 - val_mape: 111.9383\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0389 - mape: 1820.0910 - val_loss: 0.0324 - val_mape: 112.6106\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0389 - mape: 1820.0214 - val_loss: 0.0324 - val_mape: 113.1398\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0389 - mape: 1790.3799 - val_loss: 0.0324 - val_mape: 113.6016\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0388 - mape: 1840.5916 - val_loss: 0.0324 - val_mape: 114.0259\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0388 - mape: 1885.9274 - val_loss: 0.0324 - val_mape: 114.3937\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0285 - mape: 96.2729\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 12ms/step - loss: 0.0450 - mape: 165.9663 - val_loss: 0.0443 - val_mape: 92.1742\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0436 - mape: 241.1218 - val_loss: 0.0429 - val_mape: 84.3008\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0422 - mape: 318.1859 - val_loss: 0.0414 - val_mape: 76.5711\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0409 - mape: 395.8729 - val_loss: 0.0401 - val_mape: 70.4129\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0396 - mape: 471.3643 - val_loss: 0.0390 - val_mape: 66.7261\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0385 - mape: 546.8325 - val_loss: 0.0380 - val_mape: 64.7212\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0375 - mape: 620.9394 - val_loss: 0.0371 - val_mape: 63.9585\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0365 - mape: 692.2973 - val_loss: 0.0363 - val_mape: 64.0745\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0357 - mape: 764.7379 - val_loss: 0.0356 - val_mape: 64.7899\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0348 - mape: 838.5714 - val_loss: 0.0350 - val_mape: 66.0667\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0341 - mape: 911.8292 - val_loss: 0.0344 - val_mape: 67.8271\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0334 - mape: 990.8602 - val_loss: 0.0339 - val_mape: 70.0213\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0328 - mape: 1068.2776 - val_loss: 0.0335 - val_mape: 72.5730\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0322 - mape: 1129.3339 - val_loss: 0.0332 - val_mape: 75.4014\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0318 - mape: 1204.6282 - val_loss: 0.0330 - val_mape: 78.2710\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0314 - mape: 1254.1253 - val_loss: 0.0328 - val_mape: 81.0444\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0311 - mape: 1316.4245 - val_loss: 0.0327 - val_mape: 83.6667\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0308 - mape: 1358.1773 - val_loss: 0.0326 - val_mape: 86.1863\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0306 - mape: 1387.1252 - val_loss: 0.0325 - val_mape: 88.5946\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0304 - mape: 1435.0285 - val_loss: 0.0324 - val_mape: 90.8399\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0302 - mape: 1486.7625 - val_loss: 0.0323 - val_mape: 92.9183\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0301 - mape: 1520.8852 - val_loss: 0.0323 - val_mape: 94.7943\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0300 - mape: 1582.9112 - val_loss: 0.0323 - val_mape: 96.4508\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0299 - mape: 1600.9347 - val_loss: 0.0323 - val_mape: 97.8974\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0299 - mape: 1630.2317 - val_loss: 0.0322 - val_mape: 99.1613\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0298 - mape: 1643.5876 - val_loss: 0.0322 - val_mape: 100.2929\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0298 - mape: 1654.5001 - val_loss: 0.0322 - val_mape: 101.2008\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0298 - mape: 1588.2151 - val_loss: 0.0322 - val_mape: 101.9897\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0297 - mape: 1631.2442 - val_loss: 0.0322 - val_mape: 102.6041\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0297 - mape: 1677.8636 - val_loss: 0.0322 - val_mape: 103.1567\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0297 - mape: 1700.1049 - val_loss: 0.0322 - val_mape: 103.5771\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0297 - mape: 1698.5790 - val_loss: 0.0322 - val_mape: 103.9553\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1697.2893 - val_loss: 0.0322 - val_mape: 104.2974\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0296 - mape: 1727.8197 - val_loss: 0.0322 - val_mape: 104.5872\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1671.8554 - val_loss: 0.0322 - val_mape: 104.8282\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1683.1393 - val_loss: 0.0322 - val_mape: 105.0001\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1711.6210 - val_loss: 0.0322 - val_mape: 105.1612\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1692.7958 - val_loss: 0.0322 - val_mape: 105.2852\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1730.3647 - val_loss: 0.0322 - val_mape: 105.3515\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1733.6637 - val_loss: 0.0322 - val_mape: 105.4158\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0296 - mape: 1762.9311 - val_loss: 0.0322 - val_mape: 105.4313\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0296 - mape: 1712.3448 - val_loss: 0.0322 - val_mape: 105.4907\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1723.4776 - val_loss: 0.0322 - val_mape: 105.5464\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1743.3820 - val_loss: 0.0322 - val_mape: 105.5825\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0296 - mape: 1726.6280 - val_loss: 0.0321 - val_mape: 105.6256\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0296 - mape: 1733.7231 - val_loss: 0.0321 - val_mape: 105.6637\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0295 - mape: 1720.3991 - val_loss: 0.0321 - val_mape: 105.6606\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1680.1533 - val_loss: 0.0321 - val_mape: 105.6484\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0295 - mape: 1722.1321 - val_loss: 0.0321 - val_mape: 105.6878\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0295 - mape: 1711.2994 - val_loss: 0.0321 - val_mape: 105.6593\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0295 - mape: 1723.5334 - val_loss: 0.0321 - val_mape: 105.6980\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1748.5563 - val_loss: 0.0321 - val_mape: 105.6760\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1769.8354 - val_loss: 0.0321 - val_mape: 105.6648\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0295 - mape: 1739.1267 - val_loss: 0.0321 - val_mape: 105.6914\n",
      "Epoch 55/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1714.5951 - val_loss: 0.0321 - val_mape: 105.7166\n",
      "Epoch 56/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0295 - mape: 1718.9454 - val_loss: 0.0321 - val_mape: 105.7275\n",
      "Epoch 57/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1737.4846 - val_loss: 0.0321 - val_mape: 105.7393\n",
      "Epoch 58/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1757.5101 - val_loss: 0.0321 - val_mape: 105.7180\n",
      "Epoch 59/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1765.8440 - val_loss: 0.0321 - val_mape: 105.6929\n",
      "Epoch 60/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0295 - mape: 1747.7524 - val_loss: 0.0321 - val_mape: 105.6581\n",
      "Epoch 61/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1716.0640 - val_loss: 0.0321 - val_mape: 105.6357\n",
      "Epoch 62/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1721.4260 - val_loss: 0.0321 - val_mape: 105.6291\n",
      "Epoch 63/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0295 - mape: 1711.2641 - val_loss: 0.0321 - val_mape: 105.6075\n",
      "Epoch 64/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0295 - mape: 1758.4424 - val_loss: 0.0321 - val_mape: 105.6276\n",
      "Epoch 65/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1753.6537 - val_loss: 0.0321 - val_mape: 105.6319\n",
      "Epoch 66/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0295 - mape: 1742.8041 - val_loss: 0.0321 - val_mape: 105.6212\n",
      "Epoch 67/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1722.9948 - val_loss: 0.0321 - val_mape: 105.5472\n",
      "Epoch 68/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0295 - mape: 1756.2890 - val_loss: 0.0321 - val_mape: 105.5415\n",
      "Epoch 69/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1756.4104 - val_loss: 0.0321 - val_mape: 105.5777\n",
      "Epoch 70/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1709.3006 - val_loss: 0.0321 - val_mape: 105.5442\n",
      "Epoch 71/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1677.2744 - val_loss: 0.0320 - val_mape: 105.4898\n",
      "Epoch 72/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1796.0176 - val_loss: 0.0320 - val_mape: 105.5040\n",
      "Epoch 73/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1752.1874 - val_loss: 0.0320 - val_mape: 105.4641\n",
      "Epoch 74/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1749.3762 - val_loss: 0.0320 - val_mape: 105.4503\n",
      "Epoch 75/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1716.8312 - val_loss: 0.0320 - val_mape: 105.4592\n",
      "Epoch 76/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1714.5727 - val_loss: 0.0320 - val_mape: 105.4413\n",
      "Epoch 77/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1729.5334 - val_loss: 0.0320 - val_mape: 105.4150\n",
      "Epoch 78/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1750.2122 - val_loss: 0.0320 - val_mape: 105.3991\n",
      "Epoch 79/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1764.3681 - val_loss: 0.0320 - val_mape: 105.4071\n",
      "Epoch 80/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1776.9940 - val_loss: 0.0320 - val_mape: 105.4014\n",
      "Epoch 81/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1744.4283 - val_loss: 0.0320 - val_mape: 105.4042\n",
      "Epoch 82/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1711.4617 - val_loss: 0.0320 - val_mape: 105.4009\n",
      "Epoch 83/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0294 - mape: 1726.9880 - val_loss: 0.0320 - val_mape: 105.3896\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1770.4804 - val_loss: 0.0320 - val_mape: 105.3601\n",
      "Epoch 85/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0294 - mape: 1679.1219 - val_loss: 0.0320 - val_mape: 105.3558\n",
      "Epoch 86/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1742.6836 - val_loss: 0.0320 - val_mape: 105.3677\n",
      "Epoch 87/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1738.8402 - val_loss: 0.0320 - val_mape: 105.3853\n",
      "Epoch 88/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0294 - mape: 1748.8901 - val_loss: 0.0320 - val_mape: 105.3294\n",
      "Epoch 89/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0294 - mape: 1732.8717 - val_loss: 0.0320 - val_mape: 105.3042\n",
      "Epoch 90/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0294 - mape: 1730.4239 - val_loss: 0.0320 - val_mape: 105.2608\n",
      "Epoch 91/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1758.8957 - val_loss: 0.0319 - val_mape: 105.2809\n",
      "Epoch 92/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1792.7927 - val_loss: 0.0319 - val_mape: 105.2372\n",
      "Epoch 93/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1770.4791 - val_loss: 0.0319 - val_mape: 105.2493\n",
      "Epoch 94/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1817.3929 - val_loss: 0.0319 - val_mape: 105.2542\n",
      "Epoch 95/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1748.6022 - val_loss: 0.0319 - val_mape: 105.2491\n",
      "Epoch 96/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1756.2957 - val_loss: 0.0319 - val_mape: 105.2543\n",
      "Epoch 97/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1799.7450 - val_loss: 0.0319 - val_mape: 105.2590\n",
      "Epoch 98/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1769.4373 - val_loss: 0.0319 - val_mape: 105.2092\n",
      "Epoch 99/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0293 - mape: 1743.6993 - val_loss: 0.0319 - val_mape: 105.2252\n",
      "Epoch 100/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0293 - mape: 1788.6245 - val_loss: 0.0319 - val_mape: 105.2282\n",
      "Epoch 101/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1735.3244 - val_loss: 0.0319 - val_mape: 105.1659\n",
      "Epoch 102/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1795.9823 - val_loss: 0.0319 - val_mape: 105.1392\n",
      "Epoch 103/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1787.1363 - val_loss: 0.0319 - val_mape: 105.1019\n",
      "Epoch 104/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1726.3914 - val_loss: 0.0318 - val_mape: 105.0683\n",
      "Epoch 105/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1742.7930 - val_loss: 0.0318 - val_mape: 104.9594\n",
      "Epoch 106/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1717.1305 - val_loss: 0.0318 - val_mape: 104.9653\n",
      "Epoch 107/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1819.2766 - val_loss: 0.0318 - val_mape: 104.9947\n",
      "Epoch 108/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0293 - mape: 1824.8117 - val_loss: 0.0318 - val_mape: 104.9386\n",
      "Epoch 109/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1785.2194 - val_loss: 0.0318 - val_mape: 104.9031\n",
      "Epoch 110/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0292 - mape: 1826.7339 - val_loss: 0.0318 - val_mape: 104.8687\n",
      "Epoch 111/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0292 - mape: 1794.6482 - val_loss: 0.0318 - val_mape: 104.8753\n",
      "Epoch 112/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1826.7669 - val_loss: 0.0318 - val_mape: 104.8425\n",
      "Epoch 113/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0292 - mape: 1815.0647 - val_loss: 0.0318 - val_mape: 104.8485\n",
      "Epoch 114/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0292 - mape: 1821.3655 - val_loss: 0.0318 - val_mape: 104.8750\n",
      "Epoch 115/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0292 - mape: 1749.8216 - val_loss: 0.0317 - val_mape: 104.7885\n",
      "Epoch 116/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1781.8989 - val_loss: 0.0317 - val_mape: 104.7492\n",
      "Epoch 117/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0292 - mape: 1760.6535 - val_loss: 0.0317 - val_mape: 104.7175\n",
      "Epoch 118/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0292 - mape: 1812.1635 - val_loss: 0.0317 - val_mape: 104.7190\n",
      "Epoch 119/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1789.2340 - val_loss: 0.0317 - val_mape: 104.6884\n",
      "Epoch 120/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1741.6356 - val_loss: 0.0317 - val_mape: 104.5982\n",
      "Epoch 121/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1851.6367 - val_loss: 0.0317 - val_mape: 104.5845\n",
      "Epoch 122/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1814.3267 - val_loss: 0.0317 - val_mape: 104.6011\n",
      "Epoch 123/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1847.4390 - val_loss: 0.0316 - val_mape: 104.5683\n",
      "Epoch 124/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0291 - mape: 1752.1809 - val_loss: 0.0316 - val_mape: 104.5772\n",
      "Epoch 125/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0291 - mape: 1801.4840 - val_loss: 0.0316 - val_mape: 104.5371\n",
      "Epoch 126/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1860.3924 - val_loss: 0.0316 - val_mape: 104.4647\n",
      "Epoch 127/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1777.9185 - val_loss: 0.0316 - val_mape: 104.4340\n",
      "Epoch 128/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1772.1797 - val_loss: 0.0316 - val_mape: 104.3976\n",
      "Epoch 129/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1802.6755 - val_loss: 0.0316 - val_mape: 104.3800\n",
      "Epoch 130/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0291 - mape: 1827.7249 - val_loss: 0.0316 - val_mape: 104.2958\n",
      "Epoch 131/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0291 - mape: 1780.7710 - val_loss: 0.0315 - val_mape: 104.2779\n",
      "Epoch 132/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1857.5357 - val_loss: 0.0315 - val_mape: 104.2355\n",
      "Epoch 133/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0291 - mape: 1845.3059 - val_loss: 0.0315 - val_mape: 104.1102\n",
      "Epoch 134/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0291 - mape: 1832.2944 - val_loss: 0.0315 - val_mape: 104.1648\n",
      "Epoch 135/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0290 - mape: 1838.3876 - val_loss: 0.0315 - val_mape: 104.0802\n",
      "Epoch 136/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0290 - mape: 1762.3864 - val_loss: 0.0315 - val_mape: 104.0099\n",
      "Epoch 137/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0291 - mape: 1850.9086 - val_loss: 0.0314 - val_mape: 103.9691\n",
      "Epoch 138/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0290 - mape: 1815.6728 - val_loss: 0.0314 - val_mape: 103.9551\n",
      "Epoch 139/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0290 - mape: 1856.6386 - val_loss: 0.0314 - val_mape: 103.8629\n",
      "Epoch 140/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0290 - mape: 1889.8274 - val_loss: 0.0314 - val_mape: 103.8092\n",
      "Epoch 141/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0290 - mape: 1974.8141 - val_loss: 0.0314 - val_mape: 103.8218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0290 - mape: 1797.0773 - val_loss: 0.0314 - val_mape: 103.6838\n",
      "Epoch 143/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0290 - mape: 1784.3335 - val_loss: 0.0313 - val_mape: 103.5918\n",
      "Epoch 144/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0290 - mape: 1897.8775 - val_loss: 0.0313 - val_mape: 103.4714\n",
      "Epoch 145/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0290 - mape: 1862.0178 - val_loss: 0.0313 - val_mape: 103.4053\n",
      "Epoch 146/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0289 - mape: 1949.7923 - val_loss: 0.0313 - val_mape: 103.3559\n",
      "Epoch 147/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0290 - mape: 1890.3094 - val_loss: 0.0313 - val_mape: 103.3646\n",
      "Epoch 148/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0289 - mape: 1871.2786 - val_loss: 0.0312 - val_mape: 103.3632\n",
      "Epoch 149/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0289 - mape: 1929.1246 - val_loss: 0.0312 - val_mape: 103.3672\n",
      "Epoch 150/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0289 - mape: 1944.4704 - val_loss: 0.0312 - val_mape: 103.2829\n",
      "Epoch 151/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0289 - mape: 1889.2147 - val_loss: 0.0312 - val_mape: 103.2250\n",
      "Epoch 152/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0288 - mape: 1937.1384 - val_loss: 0.0312 - val_mape: 103.1624\n",
      "Epoch 153/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1727.9078 - val_loss: 0.0311 - val_mape: 103.1427\n",
      "Epoch 154/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0288 - mape: 1756.6560 - val_loss: 0.0311 - val_mape: 103.1540\n",
      "Epoch 155/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0289 - mape: 1988.3514 - val_loss: 0.0311 - val_mape: 103.0351\n",
      "Epoch 156/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1979.0704 - val_loss: 0.0311 - val_mape: 102.9391\n",
      "Epoch 157/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0288 - mape: 1767.9378 - val_loss: 0.0310 - val_mape: 102.9049\n",
      "Epoch 158/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0288 - mape: 2054.7270 - val_loss: 0.0310 - val_mape: 102.7938\n",
      "Epoch 159/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1738.4188 - val_loss: 0.0310 - val_mape: 102.6074\n",
      "Epoch 160/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0288 - mape: 2139.8849 - val_loss: 0.0310 - val_mape: 102.5149\n",
      "Epoch 161/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1983.0921 - val_loss: 0.0310 - val_mape: 102.4358\n",
      "Epoch 162/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0287 - mape: 1900.1345 - val_loss: 0.0309 - val_mape: 102.2847\n",
      "Epoch 163/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0287 - mape: 2044.8637 - val_loss: 0.0309 - val_mape: 102.2153\n",
      "Epoch 164/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1919.8035 - val_loss: 0.0309 - val_mape: 102.0383\n",
      "Epoch 165/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1910.5206 - val_loss: 0.0309 - val_mape: 101.8879\n",
      "Epoch 166/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0288 - mape: 1848.8580 - val_loss: 0.0309 - val_mape: 101.8089\n",
      "Epoch 167/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0288 - mape: 1937.1567 - val_loss: 0.0308 - val_mape: 101.6988\n",
      "Epoch 168/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0287 - mape: 1914.7528 - val_loss: 0.0308 - val_mape: 101.6420\n",
      "Epoch 169/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0287 - mape: 1881.7950 - val_loss: 0.0308 - val_mape: 101.6483\n",
      "Epoch 170/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0287 - mape: 1989.3036 - val_loss: 0.0308 - val_mape: 101.7324\n",
      "Epoch 171/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0287 - mape: 1839.7587 - val_loss: 0.0307 - val_mape: 101.6337\n",
      "Epoch 172/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0287 - mape: 2001.7837 - val_loss: 0.0307 - val_mape: 101.4499\n",
      "Epoch 173/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0287 - mape: 1848.7699 - val_loss: 0.0307 - val_mape: 101.3407\n",
      "Epoch 174/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0286 - mape: 1919.9676 - val_loss: 0.0307 - val_mape: 101.2555\n",
      "Epoch 175/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0286 - mape: 2026.9561 - val_loss: 0.0307 - val_mape: 101.1678\n",
      "Epoch 176/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0287 - mape: 2099.9513 - val_loss: 0.0306 - val_mape: 100.9808\n",
      "Epoch 177/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0287 - mape: 2080.6509 - val_loss: 0.0306 - val_mape: 100.8912\n",
      "Epoch 178/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0287 - mape: 1820.7769 - val_loss: 0.0306 - val_mape: 100.8112\n",
      "Epoch 179/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0286 - mape: 1983.2069 - val_loss: 0.0306 - val_mape: 100.7339\n",
      "Epoch 180/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 1937.8010 - val_loss: 0.0306 - val_mape: 100.5809\n",
      "Epoch 181/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 1845.1267 - val_loss: 0.0305 - val_mape: 100.3951\n",
      "Epoch 182/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 1920.2716 - val_loss: 0.0305 - val_mape: 100.3581\n",
      "Epoch 183/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0286 - mape: 1943.4423 - val_loss: 0.0305 - val_mape: 100.3344\n",
      "Epoch 184/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 2036.9244 - val_loss: 0.0305 - val_mape: 100.1762\n",
      "Epoch 185/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 1930.0986 - val_loss: 0.0304 - val_mape: 100.2105\n",
      "Epoch 186/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0285 - mape: 2126.1313 - val_loss: 0.0304 - val_mape: 100.1322\n",
      "Epoch 187/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0285 - mape: 1975.6545 - val_loss: 0.0304 - val_mape: 100.0506\n",
      "Epoch 188/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0286 - mape: 1899.0732 - val_loss: 0.0304 - val_mape: 100.0357\n",
      "Epoch 189/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0285 - mape: 1962.9967 - val_loss: 0.0304 - val_mape: 99.8756\n",
      "Epoch 190/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0285 - mape: 2121.3883 - val_loss: 0.0304 - val_mape: 99.7333\n",
      "Epoch 191/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0285 - mape: 1809.3215 - val_loss: 0.0303 - val_mape: 99.7595\n",
      "Epoch 192/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 2053.1007 - val_loss: 0.0303 - val_mape: 99.7653\n",
      "Epoch 193/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0285 - mape: 2052.5304 - val_loss: 0.0303 - val_mape: 99.6143\n",
      "Epoch 194/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0286 - mape: 2142.2912 - val_loss: 0.0303 - val_mape: 99.4635\n",
      "Epoch 195/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0285 - mape: 1935.8038 - val_loss: 0.0303 - val_mape: 99.4314\n",
      "Epoch 196/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0285 - mape: 2340.4215 - val_loss: 0.0302 - val_mape: 99.4296\n",
      "Epoch 197/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0284 - mape: 2060.9839 - val_loss: 0.0302 - val_mape: 99.4517\n",
      "Epoch 198/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0285 - mape: 2090.5096 - val_loss: 0.0302 - val_mape: 99.3270\n",
      "Epoch 199/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0285 - mape: 2091.0382 - val_loss: 0.0302 - val_mape: 99.3708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0285 - mape: 2213.9457 - val_loss: 0.0302 - val_mape: 99.2217\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0396 - mape: 86.5002\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 5s 8ms/step - loss: 0.0474 - mape: 163.9696 - val_loss: 0.0443 - val_mape: 92.4305\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0460 - mape: 237.3351 - val_loss: 0.0429 - val_mape: 84.7921\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0447 - mape: 311.5311 - val_loss: 0.0416 - val_mape: 77.3104\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0434 - mape: 385.2762 - val_loss: 0.0403 - val_mape: 71.2380\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0421 - mape: 458.9595 - val_loss: 0.0392 - val_mape: 67.2669\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0411 - mape: 529.4785 - val_loss: 0.0382 - val_mape: 65.0192\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0401 - mape: 601.7357 - val_loss: 0.0374 - val_mape: 64.0339\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0391 - mape: 672.7842 - val_loss: 0.0366 - val_mape: 63.9087\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0382 - mape: 745.0279 - val_loss: 0.0359 - val_mape: 64.4001\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0374 - mape: 815.2023 - val_loss: 0.0352 - val_mape: 65.4162\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0365 - mape: 887.6471 - val_loss: 0.0347 - val_mape: 66.9068\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0358 - mape: 958.8772 - val_loss: 0.0341 - val_mape: 68.8212\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0351 - mape: 1026.1880 - val_loss: 0.0337 - val_mape: 71.1060\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0344 - mape: 1099.4916 - val_loss: 0.0333 - val_mape: 73.7290\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0338 - mape: 1164.1985 - val_loss: 0.0331 - val_mape: 76.6338\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0333 - mape: 1224.2098 - val_loss: 0.0328 - val_mape: 79.6841\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0328 - mape: 1299.6702 - val_loss: 0.0327 - val_mape: 82.7647\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0324 - mape: 1352.2435 - val_loss: 0.0325 - val_mape: 85.8648\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0320 - mape: 1400.5550 - val_loss: 0.0324 - val_mape: 88.9762\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0317 - mape: 1468.3798 - val_loss: 0.0323 - val_mape: 92.0453\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0314 - mape: 1526.6467 - val_loss: 0.0323 - val_mape: 95.0573\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0312 - mape: 1569.7652 - val_loss: 0.0323 - val_mape: 97.9524\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0310 - mape: 1621.6668 - val_loss: 0.0322 - val_mape: 100.6885\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0308 - mape: 1654.3759 - val_loss: 0.0322 - val_mape: 103.2625\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0307 - mape: 1683.7272 - val_loss: 0.0322 - val_mape: 105.6024\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0306 - mape: 1708.8420 - val_loss: 0.0323 - val_mape: 107.6847\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0305 - mape: 1754.8700 - val_loss: 0.0323 - val_mape: 109.5096\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0304 - mape: 1769.9948 - val_loss: 0.0323 - val_mape: 111.0660\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0304 - mape: 1789.4051 - val_loss: 0.0323 - val_mape: 112.3681\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0304 - mape: 1822.4550 - val_loss: 0.0323 - val_mape: 113.4425\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0303 - mape: 1831.3835 - val_loss: 0.0323 - val_mape: 114.3168\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0303 - mape: 1825.0103 - val_loss: 0.0323 - val_mape: 115.0121\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0303 - mape: 1848.2634 - val_loss: 0.0323 - val_mape: 115.6732\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0303 - mape: 1869.0351 - val_loss: 0.0323 - val_mape: 116.2313\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0359 - mape: 99.3470\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 4s 8ms/step - loss: 0.0472 - mape: 98.3499 - val_loss: 0.0444 - val_mape: 92.2041\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0459 - mape: 91.3581 - val_loss: 0.0430 - val_mape: 84.3363\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0445 - mape: 84.4843 - val_loss: 0.0416 - val_mape: 76.7195\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0431 - mape: 78.8809 - val_loss: 0.0403 - val_mape: 70.6903\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0419 - mape: 75.4001 - val_loss: 0.0392 - val_mape: 66.8822\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0408 - mape: 73.2101 - val_loss: 0.0383 - val_mape: 64.7449\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0398 - mape: 71.8698 - val_loss: 0.0374 - val_mape: 63.9431\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0388 - mape: 71.0288 - val_loss: 0.0366 - val_mape: 63.9998\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0379 - mape: 70.6237 - val_loss: 0.0359 - val_mape: 64.6546\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0370 - mape: 70.6159 - val_loss: 0.0353 - val_mape: 65.8807\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0362 - mape: 70.9688 - val_loss: 0.0347 - val_mape: 67.5931\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0354 - mape: 71.6369 - val_loss: 0.0342 - val_mape: 69.7742\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0347 - mape: 72.6207 - val_loss: 0.0337 - val_mape: 72.3436\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0340 - mape: 73.8895 - val_loss: 0.0334 - val_mape: 75.2875\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0334 - mape: 75.3826 - val_loss: 0.0331 - val_mape: 78.5145\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0329 - mape: 77.1050 - val_loss: 0.0329 - val_mape: 81.9516\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0324 - mape: 78.9825 - val_loss: 0.0327 - val_mape: 85.5420\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0319 - mape: 81.0411 - val_loss: 0.0326 - val_mape: 89.2550\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0315 - mape: 83.2319 - val_loss: 0.0325 - val_mape: 92.9768\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0312 - mape: 85.5484 - val_loss: 0.0324 - val_mape: 96.6770\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0309 - mape: 87.8610 - val_loss: 0.0324 - val_mape: 100.2744\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0307 - mape: 90.1919 - val_loss: 0.0324 - val_mape: 103.7070\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0305 - mape: 92.5350 - val_loss: 0.0324 - val_mape: 106.8868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0304 - mape: 94.5994 - val_loss: 0.0324 - val_mape: 109.6902\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0303 - mape: 96.4377 - val_loss: 0.0324 - val_mape: 112.0623\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 1s 4ms/step - loss: 0.0303 - mape: 98.1627 - val_loss: 0.0325 - val_mape: 113.9920\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 1s 7ms/step - loss: 0.0302 - mape: 99.5655 - val_loss: 0.0325 - val_mape: 115.5715\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0302 - mape: 100.7916 - val_loss: 0.0325 - val_mape: 116.9310\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0302 - mape: 101.6892 - val_loss: 0.0325 - val_mape: 118.0769\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0302 - mape: 102.4137 - val_loss: 0.0325 - val_mape: 119.0508\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0302 - mape: 103.1985 - val_loss: 0.0325 - val_mape: 119.9522\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0301 - mape: 103.7883 - val_loss: 0.0325 - val_mape: 120.7184\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0417 - mape: 31477.0820\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 8ms/step - loss: 0.0472 - mape: 98.2972 - val_loss: 0.0529 - val_mape: 1482.8392\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 1s 7ms/step - loss: 0.0458 - mape: 91.2093 - val_loss: 0.0514 - val_mape: 2885.0972\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 1s 7ms/step - loss: 0.0444 - mape: 84.2005 - val_loss: 0.0500 - val_mape: 4293.5391\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0430 - mape: 78.5448 - val_loss: 0.0486 - val_mape: 5660.7754\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0418 - mape: 75.1154 - val_loss: 0.0474 - val_mape: 6981.2627\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0407 - mape: 72.9799 - val_loss: 0.0463 - val_mape: 8263.3398\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 1s 7ms/step - loss: 0.0396 - mape: 71.6808 - val_loss: 0.0454 - val_mape: 9550.0869\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 1s 7ms/step - loss: 0.0386 - mape: 70.9070 - val_loss: 0.0445 - val_mape: 10846.0283\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0377 - mape: 70.6080 - val_loss: 0.0438 - val_mape: 12148.7881\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0367 - mape: 70.7486 - val_loss: 0.0431 - val_mape: 13463.5586\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0359 - mape: 71.2752 - val_loss: 0.0425 - val_mape: 14792.3818\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0351 - mape: 72.1835 - val_loss: 0.0420 - val_mape: 16120.4092\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0343 - mape: 73.4861 - val_loss: 0.0416 - val_mape: 17436.7988\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0336 - mape: 75.1078 - val_loss: 0.0413 - val_mape: 18740.5215\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0330 - mape: 77.0275 - val_loss: 0.0411 - val_mape: 20042.3008\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0324 - mape: 79.2275 - val_loss: 0.0411 - val_mape: 21341.8672\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0319 - mape: 81.7193 - val_loss: 0.0410 - val_mape: 22623.2148\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0315 - mape: 84.3548 - val_loss: 0.0410 - val_mape: 23861.0781\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0311 - mape: 87.2357 - val_loss: 0.0411 - val_mape: 25024.5898\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0308 - mape: 90.0715 - val_loss: 0.0412 - val_mape: 26080.0469\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0306 - mape: 92.7938 - val_loss: 0.0413 - val_mape: 26988.4844\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0305 - mape: 95.1281 - val_loss: 0.0413 - val_mape: 27715.5078\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0305 - mape: 97.2382 - val_loss: 0.0414 - val_mape: 28299.5996\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0304 - mape: 98.7433 - val_loss: 0.0415 - val_mape: 28771.5059\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0304 - mape: 100.1666 - val_loss: 0.0415 - val_mape: 29149.4238\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0304 - mape: 101.3790 - val_loss: 0.0416 - val_mape: 29475.5820\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 1s 5ms/step - loss: 0.0303 - mape: 102.3023 - val_loss: 0.0416 - val_mape: 29759.1973\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0315 - mape: 93.7189\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 13s 38ms/step - loss: 0.0378 - mape: 1739.0300 - val_loss: 0.0321 - val_mape: 99.5736\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0377 - mape: 1561.5778 - val_loss: 0.0321 - val_mape: 96.6102\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0378 - mape: 1562.1061 - val_loss: 0.0321 - val_mape: 96.4315\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0379 - mape: 1557.3405 - val_loss: 0.0321 - val_mape: 96.8385\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0378 - mape: 1560.8336 - val_loss: 0.0321 - val_mape: 96.4221\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0378 - mape: 1558.6659 - val_loss: 0.0321 - val_mape: 96.6687\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0378 - mape: 1561.8832 - val_loss: 0.0321 - val_mape: 96.7946\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0378 - mape: 1557.5854 - val_loss: 0.0321 - val_mape: 96.5686\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0378 - mape: 1559.3148 - val_loss: 0.0321 - val_mape: 96.7091\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0378 - mape: 1560.0176 - val_loss: 0.0321 - val_mape: 96.1194\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0379 - mape: 1557.5164 - val_loss: 0.0321 - val_mape: 96.3465\n",
      "159/159 [==============================] - 1s 7ms/step - loss: 0.0282 - mape: 89.9361\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 13s 38ms/step - loss: 0.0310 - mape: 1662.6134 - val_loss: 0.0321 - val_mape: 99.2651\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0293 - mape: 1543.2034 - val_loss: 0.0321 - val_mape: 97.4740\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0292 - mape: 1540.6497 - val_loss: 0.0321 - val_mape: 97.1927\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0292 - mape: 1545.4281 - val_loss: 0.0321 - val_mape: 97.6359\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0292 - mape: 1541.0502 - val_loss: 0.0321 - val_mape: 97.3685\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0292 - mape: 1539.5158 - val_loss: 0.0321 - val_mape: 97.6824\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0292 - mape: 1546.2411 - val_loss: 0.0321 - val_mape: 97.7312\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0292 - mape: 1538.7867 - val_loss: 0.0321 - val_mape: 97.5085\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 7s 32ms/step - loss: 0.0292 - mape: 1540.2570 - val_loss: 0.0321 - val_mape: 98.0919\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0292 - mape: 1543.0168 - val_loss: 0.0321 - val_mape: 97.6101\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0292 - mape: 1544.7205 - val_loss: 0.0321 - val_mape: 97.1772\n",
      "159/159 [==============================] - 1s 6ms/step - loss: 0.0415 - mape: 89.6762\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 14s 40ms/step - loss: 0.0314 - mape: 1503.8345 - val_loss: 0.0321 - val_mape: 99.6235\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1579.7418 - val_loss: 0.0321 - val_mape: 97.6933\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1593.1322 - val_loss: 0.0321 - val_mape: 97.4864\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1587.9925 - val_loss: 0.0321 - val_mape: 97.8522\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0297 - mape: 1591.1430 - val_loss: 0.0321 - val_mape: 97.3619\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1591.2922 - val_loss: 0.0321 - val_mape: 97.7226\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1592.1954 - val_loss: 0.0321 - val_mape: 97.2768\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1592.5961 - val_loss: 0.0321 - val_mape: 98.1531\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1589.0682 - val_loss: 0.0321 - val_mape: 98.3658\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0297 - mape: 1589.3418 - val_loss: 0.0321 - val_mape: 97.4749\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0297 - mape: 1592.0984 - val_loss: 0.0321 - val_mape: 97.3060\n",
      "159/159 [==============================] - 2s 10ms/step - loss: 0.0357 - mape: 97.3878\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 11s 31ms/step - loss: 0.0312 - mape: 118.5815 - val_loss: 0.0322 - val_mape: 108.1686\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0296 - mape: 113.0814 - val_loss: 0.0322 - val_mape: 101.1600\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0296 - mape: 113.0913 - val_loss: 0.0322 - val_mape: 102.0554\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.2111 - val_loss: 0.0322 - val_mape: 102.0035\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0296 - mape: 113.1218 - val_loss: 0.0322 - val_mape: 102.7087\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.1458 - val_loss: 0.0322 - val_mape: 103.2621\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.2773 - val_loss: 0.0322 - val_mape: 102.5615\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.1384 - val_loss: 0.0322 - val_mape: 103.9151\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0296 - mape: 113.3267 - val_loss: 0.0322 - val_mape: 103.7992\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0296 - mape: 113.2551 - val_loss: 0.0322 - val_mape: 103.8116\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.2197 - val_loss: 0.0322 - val_mape: 104.4376\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0296 - mape: 113.3022 - val_loss: 0.0322 - val_mape: 103.7486\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.1237 - val_loss: 0.0322 - val_mape: 104.4580\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0296 - mape: 113.3452 - val_loss: 0.0322 - val_mape: 103.6505\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.3291 - val_loss: 0.0322 - val_mape: 104.3677\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 8s 34ms/step - loss: 0.0296 - mape: 113.3698 - val_loss: 0.0322 - val_mape: 104.2933\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.0415 - mape: 31597.0469\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 14s 38ms/step - loss: 0.0312 - mape: 118.7704 - val_loss: 0.0411 - val_mape: 27765.4004\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.0412 - val_loss: 0.0408 - val_mape: 26109.8340\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.1080 - val_loss: 0.0408 - val_mape: 26144.1523\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0296 - mape: 113.1736 - val_loss: 0.0408 - val_mape: 26151.9219\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0296 - mape: 113.2226 - val_loss: 0.0409 - val_mape: 26223.1602\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2037 - val_loss: 0.0409 - val_mape: 26389.2773\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 6s 28ms/step - loss: 0.0296 - mape: 113.3448 - val_loss: 0.0409 - val_mape: 26321.6562\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 7s 33ms/step - loss: 0.0296 - mape: 113.2521 - val_loss: 0.0409 - val_mape: 26349.2930\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0296 - mape: 113.1711 - val_loss: 0.0409 - val_mape: 26500.9902\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0296 - mape: 113.2957 - val_loss: 0.0409 - val_mape: 26473.3750\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.2297 - val_loss: 0.0409 - val_mape: 26477.9785\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 113.1984 - val_loss: 0.0409 - val_mape: 26638.0859\n",
      "159/159 [==============================] - 1s 9ms/step - loss: 0.0311 - mape: 105.1525\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 11ms/step - loss: 0.0381 - mape: 1685.8242 - val_loss: 0.0321 - val_mape: 98.3444\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0378 - mape: 1562.4006 - val_loss: 0.0321 - val_mape: 97.6976\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0378 - mape: 1561.9878 - val_loss: 0.0321 - val_mape: 96.5553\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0378 - mape: 1558.2398 - val_loss: 0.0321 - val_mape: 96.4962\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0379 - mape: 1558.7598 - val_loss: 0.0321 - val_mape: 96.5723\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0378 - mape: 1561.9207 - val_loss: 0.0321 - val_mape: 96.8382\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0378 - mape: 1561.7109 - val_loss: 0.0321 - val_mape: 96.5067\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0378 - mape: 1556.8684 - val_loss: 0.0321 - val_mape: 96.3002\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0379 - mape: 1561.6058 - val_loss: 0.0321 - val_mape: 96.7969\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0378 - mape: 1559.6595 - val_loss: 0.0321 - val_mape: 96.4345\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0379 - mape: 1561.9221 - val_loss: 0.0321 - val_mape: 96.5262\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0283 - mape: 89.1156\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 12ms/step - loss: 0.0308 - mape: 1605.7167 - val_loss: 0.0321 - val_mape: 97.6057\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0293 - mape: 1541.3502 - val_loss: 0.0321 - val_mape: 97.6028\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0292 - mape: 1542.0721 - val_loss: 0.0321 - val_mape: 97.1571\n",
      "Epoch 4/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0292 - mape: 1542.3809 - val_loss: 0.0321 - val_mape: 97.4925\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0292 - mape: 1539.5146 - val_loss: 0.0321 - val_mape: 97.5252\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0292 - mape: 1543.5124 - val_loss: 0.0321 - val_mape: 98.6921\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0292 - mape: 1542.8626 - val_loss: 0.0321 - val_mape: 97.5774\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0292 - mape: 1538.6162 - val_loss: 0.0321 - val_mape: 97.1255\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0292 - mape: 1541.5204 - val_loss: 0.0321 - val_mape: 98.2219\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0292 - mape: 1539.8743 - val_loss: 0.0321 - val_mape: 97.7316\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0292 - mape: 1542.3042 - val_loss: 0.0321 - val_mape: 97.8665\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0292 - mape: 1543.3320 - val_loss: 0.0321 - val_mape: 97.1017\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0292 - mape: 1544.6474 - val_loss: 0.0321 - val_mape: 98.1070\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0292 - mape: 1539.5943 - val_loss: 0.0321 - val_mape: 97.7236\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0292 - mape: 1542.1791 - val_loss: 0.0321 - val_mape: 97.8643\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0292 - mape: 1543.4182 - val_loss: 0.0321 - val_mape: 97.1098\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0416 - mape: 89.4005\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 3s 7ms/step - loss: 0.0314 - mape: 1496.9339 - val_loss: 0.0321 - val_mape: 99.0356\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0297 - mape: 1590.0087 - val_loss: 0.0321 - val_mape: 96.9831\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0297 - mape: 1589.9574 - val_loss: 0.0321 - val_mape: 98.1167\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0297 - mape: 1588.3787 - val_loss: 0.0321 - val_mape: 97.2213\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 1s 6ms/step - loss: 0.0297 - mape: 1588.5879 - val_loss: 0.0321 - val_mape: 97.5278\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0297 - mape: 1591.9012 - val_loss: 0.0321 - val_mape: 97.8833\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0297 - mape: 1588.9773 - val_loss: 0.0321 - val_mape: 96.9037\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0297 - mape: 1591.6952 - val_loss: 0.0321 - val_mape: 97.3850\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0297 - mape: 1592.2801 - val_loss: 0.0321 - val_mape: 98.1506\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0297 - mape: 1591.6586 - val_loss: 0.0321 - val_mape: 97.8014\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0297 - mape: 1590.8564 - val_loss: 0.0321 - val_mape: 97.6802\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0357 - mape: 96.7978\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 11ms/step - loss: 0.0313 - mape: 118.1647 - val_loss: 0.0323 - val_mape: 111.1313\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.0901 - val_loss: 0.0322 - val_mape: 101.2008\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.0408 - val_loss: 0.0322 - val_mape: 101.1405\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.1621 - val_loss: 0.0322 - val_mape: 102.2529\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.1609 - val_loss: 0.0322 - val_mape: 102.6400\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.2237 - val_loss: 0.0322 - val_mape: 103.0235\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.2018 - val_loss: 0.0322 - val_mape: 103.5308\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.3179 - val_loss: 0.0322 - val_mape: 102.5987\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.1942 - val_loss: 0.0322 - val_mape: 103.2483\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.3606 - val_loss: 0.0322 - val_mape: 103.3796\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.3212 - val_loss: 0.0322 - val_mape: 103.9915\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.1296 - val_loss: 0.0322 - val_mape: 103.8980\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.3303 - val_loss: 0.0322 - val_mape: 103.7956\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0296 - mape: 113.3051 - val_loss: 0.0322 - val_mape: 103.8348\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.2534 - val_loss: 0.0322 - val_mape: 104.4693\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.2103 - val_loss: 0.0322 - val_mape: 104.4892\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.3096 - val_loss: 0.0322 - val_mape: 104.5110\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.1185 - val_loss: 0.0322 - val_mape: 104.4570\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.3504 - val_loss: 0.0322 - val_mape: 103.6565\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.3388 - val_loss: 0.0322 - val_mape: 104.3793\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0415 - mape: 31633.0781\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 10ms/step - loss: 0.0312 - mape: 117.5964 - val_loss: 0.0411 - val_mape: 27855.1992\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.0656 - val_loss: 0.0408 - val_mape: 26137.6113\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.1638 - val_loss: 0.0418 - val_mape: 31562.3027\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0298 - mape: 113.4770 - val_loss: 0.0409 - val_mape: 26792.0547\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.2754 - val_loss: 0.0409 - val_mape: 26593.3887\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.2185 - val_loss: 0.0409 - val_mape: 26553.8281\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.2443 - val_loss: 0.0409 - val_mape: 26533.8438\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.2092 - val_loss: 0.0409 - val_mape: 26672.9434\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.2279 - val_loss: 0.0409 - val_mape: 26348.0469\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 8ms/step - loss: 0.0296 - mape: 113.3227 - val_loss: 0.0409 - val_mape: 26604.6211\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0296 - mape: 113.2102 - val_loss: 0.0409 - val_mape: 26478.0762\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 7ms/step - loss: 0.0296 - mape: 113.2638 - val_loss: 0.0409 - val_mape: 26447.8555\n",
      "159/159 [==============================] - 0s 1ms/step - loss: 0.0311 - mape: 105.2619\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 4s 11ms/step - loss: 0.0425 - mape: 1614.1592 - val_loss: 0.0313 - val_mape: 93.5940\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0352 - mape: 2609.1867 - val_loss: 0.0264 - val_mape: 105.3977\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0306 - mape: 2844.3275 - val_loss: 0.0243 - val_mape: 103.3617\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0282 - mape: 2704.4343 - val_loss: 0.0258 - val_mape: 105.4357\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0268 - mape: 2739.0774 - val_loss: 0.0219 - val_mape: 92.1770\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0261 - mape: 2462.8354 - val_loss: 0.0256 - val_mape: 110.7606\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0274 - mape: 2315.3056 - val_loss: 0.0223 - val_mape: 92.8007\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0248 - mape: 2210.5481 - val_loss: 0.0224 - val_mape: 95.9345\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0247 - mape: 1991.2678 - val_loss: 0.0237 - val_mape: 98.3647\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0248 - mape: 2056.7345 - val_loss: 0.0218 - val_mape: 88.8757\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0244 - mape: 1939.9821 - val_loss: 0.0205 - val_mape: 85.1023\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0235 - mape: 2125.8642 - val_loss: 0.0219 - val_mape: 91.9723\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0235 - mape: 1624.1172 - val_loss: 0.0205 - val_mape: 84.4979\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0229 - mape: 1665.4755 - val_loss: 0.0214 - val_mape: 90.4015\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0235 - mape: 1606.6010 - val_loss: 0.0198 - val_mape: 76.7426\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0227 - mape: 1676.9856 - val_loss: 0.0193 - val_mape: 70.7159\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0225 - mape: 1528.8842 - val_loss: 0.0197 - val_mape: 76.2145\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0226 - mape: 1788.4860 - val_loss: 0.0195 - val_mape: 77.0102\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0219 - mape: 1328.7638 - val_loss: 0.0190 - val_mape: 68.4186\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0221 - mape: 1457.8064 - val_loss: 0.0197 - val_mape: 80.6494\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0222 - mape: 1644.4294 - val_loss: 0.0192 - val_mape: 73.8644\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0220 - mape: 1785.5430 - val_loss: 0.0191 - val_mape: 68.9810\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0219 - mape: 1566.7430 - val_loss: 0.0191 - val_mape: 71.6885\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0219 - mape: 1377.8659 - val_loss: 0.0196 - val_mape: 82.8160\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0221 - mape: 1864.5513 - val_loss: 0.0189 - val_mape: 64.3336\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0215 - mape: 1859.4229 - val_loss: 0.0202 - val_mape: 87.6469\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0222 - mape: 1861.6826 - val_loss: 0.0191 - val_mape: 75.6494\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0216 - mape: 1615.7666 - val_loss: 0.0193 - val_mape: 79.6034\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0221 - mape: 1518.5631 - val_loss: 0.0195 - val_mape: 80.0055\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0219 - mape: 1740.5316 - val_loss: 0.0191 - val_mape: 72.0292\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0216 - mape: 1705.0117 - val_loss: 0.0195 - val_mape: 80.1272\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0218 - mape: 1568.1641 - val_loss: 0.0190 - val_mape: 71.2125\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0213 - mape: 1564.4982 - val_loss: 0.0196 - val_mape: 81.8045\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0217 - mape: 1748.2425 - val_loss: 0.0191 - val_mape: 67.6923\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0212 - mape: 1374.8480 - val_loss: 0.0191 - val_mape: 72.0657\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0215 - mape: 68.9090\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 5s 12ms/step - loss: 0.0323 - mape: 1622.3296 - val_loss: 0.0310 - val_mape: 89.0807\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0280 - mape: 2176.1930 - val_loss: 0.0290 - val_mape: 84.5213\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0270 - mape: 2425.4397 - val_loss: 0.0273 - val_mape: 75.7016\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0252 - mape: 3144.4507 - val_loss: 0.0309 - val_mape: 73.9042\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0245 - mape: 2732.8645 - val_loss: 0.0254 - val_mape: 71.4216\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0233 - mape: 2141.5814 - val_loss: 0.0274 - val_mape: 69.3369\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0235 - mape: 2021.0241 - val_loss: 0.0217 - val_mape: 68.6045\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0222 - mape: 2081.1279 - val_loss: 0.0215 - val_mape: 70.0728\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0218 - mape: 1872.6668 - val_loss: 0.0247 - val_mape: 63.9189\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0216 - mape: 2033.3165 - val_loss: 0.0233 - val_mape: 61.1348\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0217 - mape: 1980.8912 - val_loss: 0.0222 - val_mape: 65.1431\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0214 - mape: 1858.7292 - val_loss: 0.0219 - val_mape: 68.2451\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0215 - mape: 1623.0814 - val_loss: 0.0228 - val_mape: 62.9906\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0211 - mape: 1765.9753 - val_loss: 0.0226 - val_mape: 65.6728\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0213 - mape: 1464.6702 - val_loss: 0.0232 - val_mape: 65.7358\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0212 - mape: 1836.1939 - val_loss: 0.0247 - val_mape: 63.0217\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0213 - mape: 1875.3390 - val_loss: 0.0238 - val_mape: 60.3969\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0215 - mape: 2036.5356 - val_loss: 0.0215 - val_mape: 65.4327\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0267 - mape: 73.7355\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 5s 13ms/step - loss: 0.0330 - mape: 1641.6603 - val_loss: 0.0319 - val_mape: 92.6187\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0285 - mape: 2306.4359 - val_loss: 0.0280 - val_mape: 100.9654\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0274 - mape: 2481.1199 - val_loss: 0.0255 - val_mape: 118.4918\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0257 - mape: 2693.2761 - val_loss: 0.0324 - val_mape: 143.9296\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0239 - mape: 2867.1094 - val_loss: 0.0328 - val_mape: 148.0794\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0231 - mape: 2689.8918 - val_loss: 0.0354 - val_mape: 164.6504\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0227 - mape: 2196.0870 - val_loss: 0.0292 - val_mape: 125.1226\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0224 - mape: 2365.6132 - val_loss: 0.0340 - val_mape: 148.2703\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0222 - mape: 2536.8855 - val_loss: 0.0280 - val_mape: 121.9339\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0219 - mape: 2222.3491 - val_loss: 0.0259 - val_mape: 111.7406\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0216 - mape: 2311.9487 - val_loss: 0.0221 - val_mape: 91.8334\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0214 - mape: 2064.8540 - val_loss: 0.0250 - val_mape: 106.6674\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0214 - mape: 2204.3299 - val_loss: 0.0219 - val_mape: 91.0044\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0212 - mape: 2028.1430 - val_loss: 0.0216 - val_mape: 82.8635\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0213 - mape: 1935.2951 - val_loss: 0.0200 - val_mape: 80.4536\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0211 - mape: 1807.6454 - val_loss: 0.0221 - val_mape: 100.1858\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0210 - mape: 1946.5047 - val_loss: 0.0222 - val_mape: 96.0981\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0211 - mape: 1690.5014 - val_loss: 0.0208 - val_mape: 82.5605\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0211 - mape: 1537.3862 - val_loss: 0.0208 - val_mape: 86.8207\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0209 - mape: 2109.8981 - val_loss: 0.0201 - val_mape: 83.2869\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0209 - mape: 1904.4245 - val_loss: 0.0195 - val_mape: 75.0813\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0208 - mape: 1782.9174 - val_loss: 0.0194 - val_mape: 73.6039\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0210 - mape: 1777.5800 - val_loss: 0.0199 - val_mape: 83.6863\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0208 - mape: 1717.5031 - val_loss: 0.0195 - val_mape: 79.1462\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0207 - mape: 2079.2018 - val_loss: 0.0194 - val_mape: 72.8126\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0205 - mape: 1581.8400 - val_loss: 0.0190 - val_mape: 71.2989\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0206 - mape: 1736.2537 - val_loss: 0.0189 - val_mape: 70.4075\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0205 - mape: 1948.8192 - val_loss: 0.0191 - val_mape: 71.5282\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0206 - mape: 1784.1958 - val_loss: 0.0188 - val_mape: 69.5745\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0206 - mape: 1677.3874 - val_loss: 0.0193 - val_mape: 73.2479\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0206 - mape: 1862.8716 - val_loss: 0.0190 - val_mape: 69.7476\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0206 - mape: 1941.6743 - val_loss: 0.0190 - val_mape: 71.4783\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0205 - mape: 1619.5868 - val_loss: 0.0189 - val_mape: 72.6029\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0204 - mape: 1661.5100 - val_loss: 0.0190 - val_mape: 72.2938\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0204 - mape: 1684.7876 - val_loss: 0.0188 - val_mape: 70.2579\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0204 - mape: 1630.5489 - val_loss: 0.0188 - val_mape: 73.8429\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0203 - mape: 1672.9888 - val_loss: 0.0188 - val_mape: 69.2945\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0204 - mape: 1681.6891 - val_loss: 0.0188 - val_mape: 68.7497\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0204 - mape: 1518.7180 - val_loss: 0.0186 - val_mape: 64.8107\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0202 - mape: 1618.7697 - val_loss: 0.0187 - val_mape: 72.6796\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0203 - mape: 1896.1204 - val_loss: 0.0192 - val_mape: 77.5381\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0203 - mape: 1506.8540 - val_loss: 0.0193 - val_mape: 72.3852\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0204 - mape: 1150.9342 - val_loss: 0.0184 - val_mape: 65.6543\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 1778.9833 - val_loss: 0.0186 - val_mape: 67.2111\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0202 - mape: 1748.0996 - val_loss: 0.0186 - val_mape: 65.2825\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0202 - mape: 1511.1099 - val_loss: 0.0185 - val_mape: 64.2678\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 1535.1476 - val_loss: 0.0187 - val_mape: 62.8142\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0201 - mape: 1541.5623 - val_loss: 0.0185 - val_mape: 62.2697\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0202 - mape: 1694.9577 - val_loss: 0.0185 - val_mape: 62.2248\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0201 - mape: 1539.9428 - val_loss: 0.0186 - val_mape: 62.5548\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0201 - mape: 1694.7851 - val_loss: 0.0185 - val_mape: 62.9069\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0200 - mape: 1687.0133 - val_loss: 0.0187 - val_mape: 62.6139\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0201 - mape: 1747.9367 - val_loss: 0.0185 - val_mape: 64.6614\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0225 - mape: 62.1005\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 5s 12ms/step - loss: 0.0327 - mape: 104.4749 - val_loss: 0.0322 - val_mape: 82.6631\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0280 - mape: 104.9578 - val_loss: 0.0301 - val_mape: 77.2893\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0270 - mape: 107.0470 - val_loss: 0.0284 - val_mape: 78.8326\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0257 - mape: 104.2342 - val_loss: 0.0265 - val_mape: 79.6482\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0244 - mape: 99.2929 - val_loss: 0.0281 - val_mape: 130.0947\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0241 - mape: 98.5307 - val_loss: 0.0289 - val_mape: 138.9141\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0231 - mape: 92.5905 - val_loss: 0.0285 - val_mape: 135.2448\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0226 - mape: 90.7127 - val_loss: 0.0280 - val_mape: 132.3668\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0220 - mape: 88.8116 - val_loss: 0.0277 - val_mape: 128.4420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0220 - mape: 87.1273 - val_loss: 0.0243 - val_mape: 104.2006\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0214 - mape: 86.8738 - val_loss: 0.0242 - val_mape: 105.4842\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0210 - mape: 84.7348 - val_loss: 0.0234 - val_mape: 103.8522\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0210 - mape: 84.3170 - val_loss: 0.0232 - val_mape: 105.1484\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0208 - mape: 83.8728 - val_loss: 0.0225 - val_mape: 102.4325\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0209 - mape: 84.8313 - val_loss: 0.0218 - val_mape: 91.2087\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0206 - mape: 83.5487 - val_loss: 0.0235 - val_mape: 112.5024\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0206 - mape: 83.3550 - val_loss: 0.0223 - val_mape: 97.1376\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0205 - mape: 82.4282 - val_loss: 0.0230 - val_mape: 108.6275\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0205 - mape: 82.0277 - val_loss: 0.0213 - val_mape: 91.2412\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0204 - mape: 81.9571 - val_loss: 0.0220 - val_mape: 99.8312\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0206 - mape: 83.5813 - val_loss: 0.0215 - val_mape: 93.6154\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0203 - mape: 81.2082 - val_loss: 0.0215 - val_mape: 94.8911\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0203 - mape: 82.0512 - val_loss: 0.0208 - val_mape: 86.6166\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 81.0305 - val_loss: 0.0216 - val_mape: 97.8828\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0204 - mape: 82.1251 - val_loss: 0.0210 - val_mape: 90.9531\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0201 - mape: 80.8419 - val_loss: 0.0218 - val_mape: 100.0486\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 82.1875 - val_loss: 0.0206 - val_mape: 83.3699\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0203 - mape: 81.7907 - val_loss: 0.0226 - val_mape: 108.5890\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 80.6742 - val_loss: 0.0211 - val_mape: 92.1660\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 82.5965 - val_loss: 0.0201 - val_mape: 77.5038\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0200 - mape: 79.2741 - val_loss: 0.0215 - val_mape: 97.7652\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0200 - mape: 81.9647 - val_loss: 0.0200 - val_mape: 77.5985\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0199 - mape: 81.4410 - val_loss: 0.0206 - val_mape: 88.0518\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0201 - mape: 81.3578 - val_loss: 0.0204 - val_mape: 83.7783\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0198 - mape: 80.8444 - val_loss: 0.0202 - val_mape: 82.1100\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0198 - mape: 79.5728 - val_loss: 0.0206 - val_mape: 88.3361\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0197 - mape: 80.1460 - val_loss: 0.0195 - val_mape: 70.8768\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 78.3777 - val_loss: 0.0197 - val_mape: 74.3019\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 79.3209 - val_loss: 0.0198 - val_mape: 76.8187\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 78.7813 - val_loss: 0.0198 - val_mape: 76.3366\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 78.4722 - val_loss: 0.0195 - val_mape: 73.2277\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0198 - mape: 80.4698 - val_loss: 0.0195 - val_mape: 69.9929\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 79.3731 - val_loss: 0.0215 - val_mape: 100.1451\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0198 - mape: 80.4416 - val_loss: 0.0200 - val_mape: 81.2151\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 79.3204 - val_loss: 0.0198 - val_mape: 77.7036\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 80.6753 - val_loss: 0.0196 - val_mape: 73.2522\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0196 - mape: 79.9001 - val_loss: 0.0194 - val_mape: 70.2621\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0194 - mape: 79.8825 - val_loss: 0.0193 - val_mape: 68.8986\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0194 - mape: 78.4738 - val_loss: 0.0192 - val_mape: 69.5793\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0195 - mape: 78.3865 - val_loss: 0.0191 - val_mape: 62.7417\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0195 - mape: 79.2191 - val_loss: 0.0192 - val_mape: 63.4114\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0193 - mape: 78.0209 - val_loss: 0.0194 - val_mape: 72.8561\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0196 - mape: 80.1242 - val_loss: 0.0190 - val_mape: 63.5640\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0194 - mape: 78.7529 - val_loss: 0.0194 - val_mape: 60.4935\n",
      "Epoch 55/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0195 - mape: 80.5440 - val_loss: 0.0193 - val_mape: 62.2382\n",
      "Epoch 56/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0193 - mape: 78.2992 - val_loss: 0.0193 - val_mape: 60.0777\n",
      "Epoch 57/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0193 - mape: 78.0166 - val_loss: 0.0194 - val_mape: 59.7488\n",
      "Epoch 58/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0192 - mape: 77.6364 - val_loss: 0.0191 - val_mape: 62.4564\n",
      "Epoch 59/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0194 - mape: 79.9286 - val_loss: 0.0192 - val_mape: 60.7213\n",
      "Epoch 60/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0191 - mape: 77.9912 - val_loss: 0.0196 - val_mape: 60.3921\n",
      "Epoch 61/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0192 - mape: 78.7757 - val_loss: 0.0194 - val_mape: 60.0938\n",
      "Epoch 62/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0191 - mape: 77.5162 - val_loss: 0.0191 - val_mape: 59.5731\n",
      "Epoch 63/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0191 - mape: 77.3451 - val_loss: 0.0193 - val_mape: 59.4151\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0286 - mape: 20113.1895\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 4s 11ms/step - loss: 0.0329 - mape: 103.7403 - val_loss: 0.0396 - val_mape: 27399.7344\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0281 - mape: 109.7845 - val_loss: 0.0404 - val_mape: 19678.6484\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0273 - mape: 103.1040 - val_loss: 0.0363 - val_mape: 31122.0742\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0256 - mape: 104.8718 - val_loss: 0.0350 - val_mape: 34761.9648\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0245 - mape: 99.7039 - val_loss: 0.0366 - val_mape: 39509.5703\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0242 - mape: 97.4343 - val_loss: 0.0337 - val_mape: 36371.5586\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0233 - mape: 94.2173 - val_loss: 0.0331 - val_mape: 35422.7656\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0224 - mape: 91.1142 - val_loss: 0.0316 - val_mape: 31452.3301\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0218 - mape: 88.9866 - val_loss: 0.0313 - val_mape: 32544.2969\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0213 - mape: 86.5627 - val_loss: 0.0313 - val_mape: 29726.2461\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0216 - mape: 86.6685 - val_loss: 0.0319 - val_mape: 33491.1836\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0212 - mape: 85.7300 - val_loss: 0.0307 - val_mape: 26292.8516\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0208 - mape: 83.8098 - val_loss: 0.0315 - val_mape: 28669.8184\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 9ms/step - loss: 0.0211 - mape: 85.5492 - val_loss: 0.0302 - val_mape: 26091.3301\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0206 - mape: 83.0717 - val_loss: 0.0304 - val_mape: 24768.0742\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0208 - mape: 83.9259 - val_loss: 0.0302 - val_mape: 24709.9941\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0204 - mape: 82.5937 - val_loss: 0.0305 - val_mape: 24466.1211\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0205 - mape: 82.6143 - val_loss: 0.0302 - val_mape: 20221.8789\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0205 - mape: 82.6440 - val_loss: 0.0309 - val_mape: 28388.6230\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0206 - mape: 83.2959 - val_loss: 0.0301 - val_mape: 22933.8789\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0204 - mape: 82.7557 - val_loss: 0.0300 - val_mape: 21292.0586\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0203 - mape: 82.3182 - val_loss: 0.0301 - val_mape: 20367.5742\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0203 - mape: 82.2479 - val_loss: 0.0298 - val_mape: 21089.5078\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 81.2922 - val_loss: 0.0303 - val_mape: 23510.1719\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0204 - mape: 82.5875 - val_loss: 0.0300 - val_mape: 21067.3867\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0204 - mape: 81.9720 - val_loss: 0.0299 - val_mape: 19538.5820\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0203 - mape: 81.4981 - val_loss: 0.0301 - val_mape: 24139.9570\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0201 - mape: 81.2196 - val_loss: 0.0302 - val_mape: 25966.2559\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 80.9310 - val_loss: 0.0299 - val_mape: 21771.3770\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0202 - mape: 81.8390 - val_loss: 0.0300 - val_mape: 22235.2617\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0201 - mape: 80.1192 - val_loss: 0.0300 - val_mape: 18753.4668\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0200 - mape: 79.9244 - val_loss: 0.0298 - val_mape: 19749.4668\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0200 - mape: 80.3317 - val_loss: 0.0299 - val_mape: 20218.2949\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0206 - mape: 93.1281\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 4s 13ms/step - loss: 13423.5776 - mape: 100265246.6693 - val_loss: 0.0348 - val_mape: 185.5446\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0495 - mape: 2253.2038 - val_loss: 0.0644 - val_mape: 205.1363\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0496 - mape: 4353.6745 - val_loss: 0.0323 - val_mape: 120.8359\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0444 - mape: 3848.2634 - val_loss: 0.0396 - val_mape: 251.0274\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0479 - mape: 3964.4101 - val_loss: 0.0409 - val_mape: 73.8727\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0449 - mape: 3935.5660 - val_loss: 0.0432 - val_mape: 86.0801\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0448 - mape: 2266.4198 - val_loss: 0.0356 - val_mape: 64.0742\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0447 - mape: 4862.2762 - val_loss: 0.0390 - val_mape: 66.1772\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0466 - mape: 1306.3885 - val_loss: 0.0322 - val_mape: 118.0053\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0500 - mape: 2846.0551 - val_loss: 0.0409 - val_mape: 74.1829\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0430 - mape: 4536.4679 - val_loss: 0.0328 - val_mape: 141.7034\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0436 - mape: 753.6673 - val_loss: 0.0381 - val_mape: 233.4637\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0503 - mape: 3406.5719 - val_loss: 0.0736 - val_mape: 256.5468\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0477 - mape: 4369.2518 - val_loss: 0.0425 - val_mape: 82.0213\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0473 - mape: 1680.3621 - val_loss: 0.0526 - val_mape: 138.5585\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0450 - mape: 3825.7271 - val_loss: 0.0436 - val_mape: 292.1599\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0513 - mape: 4618.0299 - val_loss: 0.0337 - val_mape: 69.7676\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0487 - mape: 3875.6444 - val_loss: 0.0962 - val_mape: 383.1647\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0588 - mape: 3506.5499 - val_loss: 0.0547 - val_mape: 150.3869\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0275 - mape: 103.4115\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 4s 13ms/step - loss: 13470.2336 - mape: 48662563.5955 - val_loss: 0.0584 - val_mape: 171.2860\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0538 - mape: 4024.5531 - val_loss: 0.0330 - val_mape: 74.7101\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 11ms/step - loss: 0.0552 - mape: 4816.5049 - val_loss: 0.0452 - val_mape: 97.5822\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0425 - mape: 3795.7804 - val_loss: 0.0331 - val_mape: 73.1090\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0423 - mape: 2008.6544 - val_loss: 0.0476 - val_mape: 110.9213\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0446 - mape: 3229.6708 - val_loss: 0.0460 - val_mape: 101.8694\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0433 - mape: 2391.6926 - val_loss: 0.0672 - val_mape: 220.7598\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0406 - mape: 2355.3021 - val_loss: 0.0324 - val_mape: 81.3226\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0462 - mape: 2558.6324 - val_loss: 0.0325 - val_mape: 130.1704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0404 - mape: 3508.7942 - val_loss: 0.0357 - val_mape: 200.6079\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0491 - mape: 3403.3857 - val_loss: 0.0331 - val_mape: 151.0768\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0499 - mape: 2849.0657 - val_loss: 0.0382 - val_mape: 64.5955\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0440 - mape: 3350.2433 - val_loss: 0.0370 - val_mape: 63.5087\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0439 - mape: 2062.8502 - val_loss: 0.0334 - val_mape: 158.8431\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0498 - mape: 3292.6563 - val_loss: 0.0539 - val_mape: 146.2612\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0573 - mape: 3701.0540 - val_loss: 0.0396 - val_mape: 68.2722\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0510 - mape: 4063.8221 - val_loss: 0.0321 - val_mape: 93.8493\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 3s 12ms/step - loss: 0.0379 - mape: 1749.7459 - val_loss: 0.0628 - val_mape: 195.7993\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0517 - mape: 3509.6590 - val_loss: 0.0370 - val_mape: 218.8181\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0420 - mape: 4088.3351 - val_loss: 0.0461 - val_mape: 102.6019\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 3s 13ms/step - loss: 0.0530 - mape: 2745.7972 - val_loss: 0.0634 - val_mape: 199.1716\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0602 - mape: 2997.8346 - val_loss: 0.0327 - val_mape: 77.1033\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 3s 16ms/step - loss: 0.0412 - mape: 3179.8755 - val_loss: 0.0324 - val_mape: 129.2522\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0381 - mape: 2871.6593 - val_loss: 0.0336 - val_mape: 70.2652\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0462 - mape: 2997.7237 - val_loss: 0.0487 - val_mape: 117.1140\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0388 - mape: 1999.7875 - val_loss: 0.0354 - val_mape: 196.2772\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0373 - mape: 1973.2884 - val_loss: 0.0375 - val_mape: 63.7746\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0422 - mape: 87.0970\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 20ms/step - loss: 5367.4382 - mape: 19352413.6037 - val_loss: 0.0332 - val_mape: 153.9405\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0382 - mape: 1891.0094 - val_loss: 0.0336 - val_mape: 69.8916\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0390 - mape: 2863.7210 - val_loss: 0.0536 - val_mape: 144.3568\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0426 - mape: 3072.3621 - val_loss: 0.0360 - val_mape: 63.7203\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0371 - mape: 3569.4224 - val_loss: 0.0412 - val_mape: 267.8206\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0389 - mape: 3343.4837 - val_loss: 0.0428 - val_mape: 284.2812\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0408 - mape: 4322.3628 - val_loss: 0.0401 - val_mape: 69.9960\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0389 - mape: 1936.4926 - val_loss: 0.0342 - val_mape: 67.3503\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0371 - mape: 2583.7848 - val_loss: 0.0359 - val_mape: 203.8235\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0529 - mape: 3062.5107 - val_loss: 0.0638 - val_mape: 452.6822\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0411 - mape: 1636.3334 - val_loss: 0.0388 - val_mape: 241.2520\n",
      "159/159 [==============================] - 1s 3ms/step - loss: 0.0370 - mape: 151.3510\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 19ms/step - loss: 22018.5196 - mape: 80078685.8409 - val_loss: 0.0322 - val_mape: 107.8251\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0386 - mape: 164.3187 - val_loss: 0.0369 - val_mape: 215.3969\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0397 - mape: 173.2875 - val_loss: 0.0388 - val_mape: 238.7040\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0446 - mape: 206.0872 - val_loss: 0.0328 - val_mape: 137.0212\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 3s 14ms/step - loss: 0.0405 - mape: 179.8414 - val_loss: 0.0367 - val_mape: 212.2500\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0396 - mape: 173.3610 - val_loss: 0.0327 - val_mape: 134.8207\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 3s 11ms/step - loss: 0.0439 - mape: 194.0931 - val_loss: 0.0408 - val_mape: 261.1067\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 3s 15ms/step - loss: 0.0403 - mape: 177.5000 - val_loss: 0.0356 - val_mape: 196.5728\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0371 - mape: 160.1876 - val_loss: 0.0323 - val_mape: 115.5380\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 16ms/step - loss: 0.0383 - mape: 165.8315 - val_loss: 0.0528 - val_mape: 369.7189\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0449 - mape: 205.7901 - val_loss: 0.0450 - val_mape: 302.7881\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0417 - mape: 32977.3438\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 5s 19ms/step - loss: 12509.3451 - mape: 45302572.5647 - val_loss: 0.0460 - val_mape: 45803.0156\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0549 - mape: 260.0470 - val_loss: 0.0459 - val_mape: 45493.8281\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0546 - mape: 260.4851 - val_loss: 0.0421 - val_mape: 15277.6865\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0368 - mape: 154.5723 - val_loss: 0.0440 - val_mape: 40118.3320\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0378 - mape: 162.9904 - val_loss: 0.0458 - val_mape: 45210.7734\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0370 - mape: 161.9494 - val_loss: 0.0498 - val_mape: 54081.2969\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0397 - mape: 173.6715 - val_loss: 0.0566 - val_mape: 65649.2578\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0399 - mape: 176.9531 - val_loss: 0.0454 - val_mape: 44273.3555\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0377 - mape: 159.8863 - val_loss: 0.0476 - val_mape: 49635.6172\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0396 - mape: 173.4346 - val_loss: 0.0522 - val_mape: 58504.5156\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0392 - mape: 175.7611 - val_loss: 0.0446 - val_mape: 42040.0625\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 4s 19ms/step - loss: 0.0369 - mape: 158.1617 - val_loss: 0.0449 - val_mape: 42826.4453\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0383 - mape: 166.2898 - val_loss: 0.0856 - val_mape: 106017.7422\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.0330 - mape: 70.4177\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 13s 29ms/step - loss: 0.0437 - mape: 1593.7550 - val_loss: 0.0322 - val_mape: 91.6248\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0382 - mape: 1592.8634 - val_loss: 0.0322 - val_mape: 90.6963\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0382 - mape: 1580.9091 - val_loss: 0.0322 - val_mape: 88.9778\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0382 - mape: 1571.5857 - val_loss: 0.0322 - val_mape: 88.5560\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0383 - mape: 1559.5699 - val_loss: 0.0322 - val_mape: 87.5782\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0384 - mape: 1542.3882 - val_loss: 0.0322 - val_mape: 87.0295\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0384 - mape: 1534.2232 - val_loss: 0.0322 - val_mape: 86.8208\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0385 - mape: 1536.1605 - val_loss: 0.0322 - val_mape: 86.5223\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0385 - mape: 1527.4721 - val_loss: 0.0322 - val_mape: 86.5309\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0385 - mape: 1524.9960 - val_loss: 0.0322 - val_mape: 86.5864\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0385 - mape: 1526.4433 - val_loss: 0.0322 - val_mape: 86.4363\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0386 - mape: 1526.9472 - val_loss: 0.0322 - val_mape: 86.1782\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0288 - mape: 84.1738\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 15s 33ms/step - loss: 0.0327 - mape: 1575.4970 - val_loss: 0.0322 - val_mape: 90.8675\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 6s 28ms/step - loss: 0.0293 - mape: 1575.1209 - val_loss: 0.0321 - val_mape: 91.4159\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 6s 27ms/step - loss: 0.0292 - mape: 1586.1276 - val_loss: 0.0321 - val_mape: 90.7979\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0292 - mape: 1578.9985 - val_loss: 0.0322 - val_mape: 90.1985\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0292 - mape: 1572.5295 - val_loss: 0.0322 - val_mape: 90.1191\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 6s 28ms/step - loss: 0.0292 - mape: 1569.3611 - val_loss: 0.0322 - val_mape: 89.3484\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 7s 30ms/step - loss: 0.0292 - mape: 1562.0393 - val_loss: 0.0322 - val_mape: 88.7791\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 6s 28ms/step - loss: 0.0292 - mape: 1559.9413 - val_loss: 0.0322 - val_mape: 88.2576\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0292 - mape: 1552.3354 - val_loss: 0.0322 - val_mape: 88.3170\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0292 - mape: 1549.0783 - val_loss: 0.0322 - val_mape: 87.8822\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0292 - mape: 1546.8606 - val_loss: 0.0322 - val_mape: 87.3986\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0292 - mape: 1542.1126 - val_loss: 0.0322 - val_mape: 87.3216\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.0425 - mape: 85.9646\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 12s 29ms/step - loss: 0.0331 - mape: 1701.0504 - val_loss: 0.0322 - val_mape: 91.6556\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0297 - mape: 1721.3051 - val_loss: 0.0321 - val_mape: 91.6069\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 16ms/step - loss: 0.0296 - mape: 1765.7116 - val_loss: 0.0321 - val_mape: 91.1365\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0296 - mape: 1809.3073 - val_loss: 0.0322 - val_mape: 88.9666\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0296 - mape: 1832.8948 - val_loss: 0.0322 - val_mape: 89.0287\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0296 - mape: 1832.6233 - val_loss: 0.0322 - val_mape: 87.8442\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0296 - mape: 1844.6572 - val_loss: 0.0322 - val_mape: 87.4721\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0296 - mape: 1867.0183 - val_loss: 0.0322 - val_mape: 85.9690\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0296 - mape: 1881.2682 - val_loss: 0.0323 - val_mape: 85.6582\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0297 - mape: 1889.1872 - val_loss: 0.0323 - val_mape: 85.2941\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0297 - mape: 1901.6925 - val_loss: 0.0323 - val_mape: 84.7199\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0297 - mape: 1915.2384 - val_loss: 0.0323 - val_mape: 84.2535\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.0357 - mape: 89.3371\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 12s 21ms/step - loss: 0.0327 - mape: 104.2133 - val_loss: 0.0326 - val_mape: 83.5230\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 105.5763 - val_loss: 0.0325 - val_mape: 83.7183\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0295 - mape: 105.7740 - val_loss: 0.0325 - val_mape: 85.1155\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0295 - mape: 106.4500 - val_loss: 0.0325 - val_mape: 85.6933\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0295 - mape: 106.0173 - val_loss: 0.0324 - val_mape: 86.6321\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0295 - mape: 105.8078 - val_loss: 0.0324 - val_mape: 87.1080\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.6785 - val_loss: 0.0324 - val_mape: 87.1730\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.4950 - val_loss: 0.0324 - val_mape: 87.6443\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0295 - mape: 105.4767 - val_loss: 0.0324 - val_mape: 87.8270\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.3902 - val_loss: 0.0324 - val_mape: 88.3533\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0295 - mape: 105.3233 - val_loss: 0.0323 - val_mape: 88.7821\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.2839 - val_loss: 0.0323 - val_mape: 89.2222\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 6s 26ms/step - loss: 0.0295 - mape: 105.2227 - val_loss: 0.0323 - val_mape: 89.7635\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.1954 - val_loss: 0.0323 - val_mape: 90.3664\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0295 - mape: 105.1445 - val_loss: 0.0323 - val_mape: 91.5274\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 4s 16ms/step - loss: 0.0294 - mape: 105.1538 - val_loss: 0.0323 - val_mape: 92.0426\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0294 - mape: 105.0468 - val_loss: 0.0323 - val_mape: 92.7810\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0294 - mape: 105.0463 - val_loss: 0.0323 - val_mape: 93.4204\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 5s 25ms/step - loss: 0.0294 - mape: 105.0553 - val_loss: 0.0323 - val_mape: 94.5660\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0294 - mape: 105.0914 - val_loss: 0.0323 - val_mape: 94.6975\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 104.9710 - val_loss: 0.0323 - val_mape: 94.9664\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 104.9344 - val_loss: 0.0322 - val_mape: 95.4152\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 104.8216 - val_loss: 0.0322 - val_mape: 96.0427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0294 - mape: 104.8288 - val_loss: 0.0322 - val_mape: 96.9697\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 104.7090 - val_loss: 0.0322 - val_mape: 97.7011\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 104.6932 - val_loss: 0.0322 - val_mape: 98.4636\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 104.8577 - val_loss: 0.0322 - val_mape: 99.2834\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0294 - mape: 104.8975 - val_loss: 0.0322 - val_mape: 99.7005\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0293 - mape: 104.9530 - val_loss: 0.0322 - val_mape: 100.3541\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 104.9847 - val_loss: 0.0322 - val_mape: 100.8714\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0293 - mape: 104.9345 - val_loss: 0.0322 - val_mape: 101.4746\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 104.9976 - val_loss: 0.0322 - val_mape: 101.8889\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0293 - mape: 104.9788 - val_loss: 0.0322 - val_mape: 102.4650\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 104.9936 - val_loss: 0.0322 - val_mape: 102.8468\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 4s 18ms/step - loss: 0.0293 - mape: 104.9354 - val_loss: 0.0322 - val_mape: 103.3877\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 4s 20ms/step - loss: 0.0293 - mape: 105.0481 - val_loss: 0.0322 - val_mape: 103.7423\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0293 - mape: 104.9983 - val_loss: 0.0322 - val_mape: 104.1661\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 105.0321 - val_loss: 0.0322 - val_mape: 104.4776\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0293 - mape: 105.0310 - val_loss: 0.0322 - val_mape: 104.8093\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 105.0378 - val_loss: 0.0322 - val_mape: 105.0904\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 105.0716 - val_loss: 0.0322 - val_mape: 105.4853\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 105.1183 - val_loss: 0.0322 - val_mape: 105.7634\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 105.0699 - val_loss: 0.0322 - val_mape: 106.1364\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0293 - mape: 105.1311 - val_loss: 0.0322 - val_mape: 106.4488\n",
      "159/159 [==============================] - 1s 5ms/step - loss: 0.0415 - mape: 31469.6738\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 9s 21ms/step - loss: 0.0330 - mape: 102.6104 - val_loss: 0.0407 - val_mape: 21619.8164\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 23ms/step - loss: 0.0297 - mape: 104.8310 - val_loss: 0.0406 - val_mape: 22018.0605\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.5242 - val_loss: 0.0406 - val_mape: 21843.8262\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0295 - mape: 105.5115 - val_loss: 0.0406 - val_mape: 22360.4805\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 25ms/step - loss: 0.0295 - mape: 105.3567 - val_loss: 0.0406 - val_mape: 22410.8242\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 25ms/step - loss: 0.0295 - mape: 105.2870 - val_loss: 0.0405 - val_mape: 22652.2480\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0295 - mape: 105.2332 - val_loss: 0.0405 - val_mape: 22793.1270\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 5s 25ms/step - loss: 0.0295 - mape: 105.1803 - val_loss: 0.0405 - val_mape: 22919.8242\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0295 - mape: 105.1766 - val_loss: 0.0405 - val_mape: 23032.4941\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0295 - mape: 105.1252 - val_loss: 0.0406 - val_mape: 23200.1777\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 25ms/step - loss: 0.0294 - mape: 105.1331 - val_loss: 0.0406 - val_mape: 23345.3594\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0294 - mape: 105.0415 - val_loss: 0.0406 - val_mape: 23482.5469\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0294 - mape: 105.0151 - val_loss: 0.0406 - val_mape: 23613.1719\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 105.0734 - val_loss: 0.0406 - val_mape: 23833.7539\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 6s 25ms/step - loss: 0.0294 - mape: 105.0626 - val_loss: 0.0406 - val_mape: 24007.7129\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 105.0431 - val_loss: 0.0406 - val_mape: 24126.8164\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 5s 24ms/step - loss: 0.0294 - mape: 105.0527 - val_loss: 0.0406 - val_mape: 24198.3906\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.9910 - val_loss: 0.0406 - val_mape: 24233.7070\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0313 - mape: 92.9176\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 15s 57ms/step - loss: 0.0493 - mape: 1652.9153 - val_loss: 0.0331 - val_mape: 85.8050\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 12s 53ms/step - loss: 0.0401 - mape: 1642.7846 - val_loss: 0.0326 - val_mape: 84.4661\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 12s 53ms/step - loss: 0.0394 - mape: 1716.2596 - val_loss: 0.0322 - val_mape: 83.8435\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 12s 52ms/step - loss: 0.0388 - mape: 1718.6914 - val_loss: 0.0315 - val_mape: 85.8016\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 12s 52ms/step - loss: 0.0377 - mape: 2054.1394 - val_loss: 0.0303 - val_mape: 86.4852\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 38ms/step - loss: 0.0363 - mape: 2239.1283 - val_loss: 0.0290 - val_mape: 88.4083\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 11s 49ms/step - loss: 0.0351 - mape: 1872.8442 - val_loss: 0.0283 - val_mape: 89.7691\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 12s 52ms/step - loss: 0.0344 - mape: 2318.2877 - val_loss: 0.0281 - val_mape: 86.7944\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 12s 52ms/step - loss: 0.0338 - mape: 2307.5367 - val_loss: 0.0278 - val_mape: 84.9046\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 12s 53ms/step - loss: 0.0334 - mape: 2342.1450 - val_loss: 0.0273 - val_mape: 86.8447\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 12s 53ms/step - loss: 0.0329 - mape: 2510.8032 - val_loss: 0.0269 - val_mape: 86.9673\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 12s 53ms/step - loss: 0.0327 - mape: 2072.3521 - val_loss: 0.0268 - val_mape: 86.0351\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 12s 52ms/step - loss: 0.0322 - mape: 2304.1713 - val_loss: 0.0264 - val_mape: 85.7301\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 9s 38ms/step - loss: 0.0318 - mape: 2344.8554 - val_loss: 0.0261 - val_mape: 85.8156\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0315 - mape: 2505.8494 - val_loss: 0.0256 - val_mape: 86.6103\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0310 - mape: 2036.5365 - val_loss: 0.0255 - val_mape: 84.5136\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0307 - mape: 2703.6473 - val_loss: 0.0251 - val_mape: 84.1532\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 9s 39ms/step - loss: 0.0302 - mape: 2767.8993 - val_loss: 0.0247 - val_mape: 83.7951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0297 - mape: 1849.7998 - val_loss: 0.0246 - val_mape: 82.0415\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 8s 38ms/step - loss: 0.0297 - mape: 2434.3911 - val_loss: 0.0243 - val_mape: 81.6040\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0290 - mape: 2237.0014 - val_loss: 0.0239 - val_mape: 81.5418\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0286 - mape: 2871.2566 - val_loss: 0.0238 - val_mape: 79.3591\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 9s 38ms/step - loss: 0.0283 - mape: 2531.8827 - val_loss: 0.0236 - val_mape: 78.3864\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0281 - mape: 2151.1746 - val_loss: 0.0234 - val_mape: 76.8111\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0279 - mape: 2379.7446 - val_loss: 0.0230 - val_mape: 77.4714\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0275 - mape: 2142.5240 - val_loss: 0.0228 - val_mape: 76.8070\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 8s 38ms/step - loss: 0.0273 - mape: 2049.8258 - val_loss: 0.0231 - val_mape: 72.5687\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0269 - mape: 2569.2148 - val_loss: 0.0227 - val_mape: 72.8037\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0267 - mape: 3222.1191 - val_loss: 0.0226 - val_mape: 72.5803\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0265 - mape: 2804.9537 - val_loss: 0.0222 - val_mape: 72.5971\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0262 - mape: 2411.4498 - val_loss: 0.0224 - val_mape: 70.1402\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0262 - mape: 2565.7091 - val_loss: 0.0223 - val_mape: 69.5406\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0257 - mape: 2293.7516 - val_loss: 0.0220 - val_mape: 69.8407\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0259 - mape: 2230.2360 - val_loss: 0.0221 - val_mape: 68.3832\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0256 - mape: 2836.1375 - val_loss: 0.0217 - val_mape: 69.8961\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0257 - mape: 2184.4184 - val_loss: 0.0215 - val_mape: 69.2332\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0255 - mape: 2056.9712 - val_loss: 0.0222 - val_mape: 66.8311\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0252 - mape: 1984.5941 - val_loss: 0.0218 - val_mape: 66.6905\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0251 - mape: 2262.3977 - val_loss: 0.0216 - val_mape: 66.4174\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0249 - mape: 2069.6786 - val_loss: 0.0217 - val_mape: 66.4413\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0248 - mape: 2195.8332 - val_loss: 0.0220 - val_mape: 65.3385\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0247 - mape: 2174.7976 - val_loss: 0.0223 - val_mape: 64.9332\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0245 - mape: 2153.9078 - val_loss: 0.0214 - val_mape: 66.1458\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0245 - mape: 2159.9565 - val_loss: 0.0218 - val_mape: 64.9501\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0245 - mape: 2227.1955 - val_loss: 0.0216 - val_mape: 65.0953\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0244 - mape: 2174.0077 - val_loss: 0.0219 - val_mape: 63.8495\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0240 - mape: 2247.2567 - val_loss: 0.0222 - val_mape: 63.6203\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0242 - mape: 2172.3498 - val_loss: 0.0221 - val_mape: 62.9173\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0240 - mape: 1873.3905 - val_loss: 0.0215 - val_mape: 63.6573\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0241 - mape: 2197.2704 - val_loss: 0.0224 - val_mape: 62.7961\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0237 - mape: 2399.2479 - val_loss: 0.0222 - val_mape: 62.6444\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0241 - mape: 2090.8650 - val_loss: 0.0219 - val_mape: 63.1091\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0239 - mape: 2131.1249 - val_loss: 0.0219 - val_mape: 62.3506\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.0219 - mape: 69.5594\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 10s 37ms/step - loss: 0.0367 - mape: 1547.8763 - val_loss: 0.0330 - val_mape: 83.9807\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 9s 39ms/step - loss: 0.0303 - mape: 1601.4672 - val_loss: 0.0324 - val_mape: 80.5903\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 9s 39ms/step - loss: 0.0296 - mape: 1703.2737 - val_loss: 0.0316 - val_mape: 82.0571\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0288 - mape: 1807.3533 - val_loss: 0.0308 - val_mape: 82.8883\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0283 - mape: 2119.7200 - val_loss: 0.0302 - val_mape: 82.0916\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0280 - mape: 2207.1113 - val_loss: 0.0299 - val_mape: 81.7740\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0279 - mape: 2399.9162 - val_loss: 0.0298 - val_mape: 79.7597\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 9s 40ms/step - loss: 0.0276 - mape: 2284.1840 - val_loss: 0.0295 - val_mape: 80.0019\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0275 - mape: 2067.2210 - val_loss: 0.0293 - val_mape: 79.3032\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0274 - mape: 2465.0188 - val_loss: 0.0293 - val_mape: 78.2459\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0272 - mape: 2294.8948 - val_loss: 0.0289 - val_mape: 79.0409\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0269 - mape: 2553.7132 - val_loss: 0.0287 - val_mape: 78.1915\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0267 - mape: 2517.4901 - val_loss: 0.0283 - val_mape: 78.3372\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0265 - mape: 2070.0111 - val_loss: 0.0281 - val_mape: 77.3917\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 9s 38ms/step - loss: 0.0263 - mape: 2563.7280 - val_loss: 0.0273 - val_mape: 79.0343\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0261 - mape: 2019.8777 - val_loss: 0.0269 - val_mape: 79.1785\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0258 - mape: 2298.2541 - val_loss: 0.0263 - val_mape: 77.7338\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0257 - mape: 1886.3776 - val_loss: 0.0257 - val_mape: 78.9379\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 9s 38ms/step - loss: 0.0254 - mape: 1925.6519 - val_loss: 0.0254 - val_mape: 79.3002\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0251 - mape: 2445.4636 - val_loss: 0.0252 - val_mape: 77.2598\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0248 - mape: 2744.1486 - val_loss: 0.0247 - val_mape: 76.1782\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0244 - mape: 2783.3683 - val_loss: 0.0240 - val_mape: 78.8155\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0243 - mape: 2261.1254 - val_loss: 0.0237 - val_mape: 76.9664\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0240 - mape: 2655.8743 - val_loss: 0.0233 - val_mape: 75.8277\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0238 - mape: 2206.0684 - val_loss: 0.0230 - val_mape: 74.6298\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0236 - mape: 2224.3110 - val_loss: 0.0227 - val_mape: 73.5095\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0233 - mape: 2234.0988 - val_loss: 0.0225 - val_mape: 71.5548\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0232 - mape: 2853.6888 - val_loss: 0.0221 - val_mape: 72.5864\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 8s 37ms/step - loss: 0.0230 - mape: 2269.9416 - val_loss: 0.0217 - val_mape: 73.5312\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 9s 38ms/step - loss: 0.0228 - mape: 2662.0258 - val_loss: 0.0217 - val_mape: 70.9649\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0226 - mape: 2629.4691 - val_loss: 0.0217 - val_mape: 69.4678\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0225 - mape: 2125.5451 - val_loss: 0.0216 - val_mape: 69.0678\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0225 - mape: 2318.6709 - val_loss: 0.0211 - val_mape: 71.6522\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 2316.3608 - val_loss: 0.0210 - val_mape: 71.9106\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0222 - mape: 2223.6669 - val_loss: 0.0210 - val_mape: 69.8960\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0222 - mape: 2301.3451 - val_loss: 0.0208 - val_mape: 70.3261\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0222 - mape: 2396.0266 - val_loss: 0.0211 - val_mape: 68.9669\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0219 - mape: 2314.4659 - val_loss: 0.0211 - val_mape: 67.2906\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0220 - mape: 2466.7783 - val_loss: 0.0206 - val_mape: 68.7494\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 2243.0390 - val_loss: 0.0208 - val_mape: 68.2939\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0218 - mape: 2489.5920 - val_loss: 0.0210 - val_mape: 66.3253\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0218 - mape: 2327.7645 - val_loss: 0.0207 - val_mape: 67.6245\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0219 - mape: 2402.9653 - val_loss: 0.0209 - val_mape: 65.7998\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 2436.4081 - val_loss: 0.0204 - val_mape: 69.6943\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 2406.3339 - val_loss: 0.0205 - val_mape: 68.7882\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0217 - mape: 1965.1677 - val_loss: 0.0207 - val_mape: 66.0676\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0216 - mape: 2286.4232 - val_loss: 0.0204 - val_mape: 67.5797\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0217 - mape: 1967.0755 - val_loss: 0.0208 - val_mape: 65.4916\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0217 - mape: 2253.1037 - val_loss: 0.0205 - val_mape: 66.7124\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 2263.0538 - val_loss: 0.0206 - val_mape: 64.1221\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0215 - mape: 1972.5366 - val_loss: 0.0208 - val_mape: 63.8455\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 1946.6184 - val_loss: 0.0210 - val_mape: 62.7778\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 2379.3816 - val_loss: 0.0208 - val_mape: 63.0345\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 2168.9503 - val_loss: 0.0210 - val_mape: 63.6192\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.0256 - mape: 69.7324\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 10s 37ms/step - loss: 0.0385 - mape: 1773.2014 - val_loss: 0.0330 - val_mape: 86.1242\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0311 - mape: 1922.9160 - val_loss: 0.0324 - val_mape: 81.8003\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0303 - mape: 1945.5974 - val_loss: 0.0319 - val_mape: 81.4805\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0295 - mape: 1978.6922 - val_loss: 0.0311 - val_mape: 84.6299\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0288 - mape: 2127.8353 - val_loss: 0.0299 - val_mape: 85.7413\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0284 - mape: 2348.5273 - val_loss: 0.0292 - val_mape: 85.8474\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0281 - mape: 2218.3773 - val_loss: 0.0286 - val_mape: 85.4833\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0278 - mape: 2448.0274 - val_loss: 0.0280 - val_mape: 86.8283\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0275 - mape: 2797.0939 - val_loss: 0.0274 - val_mape: 88.8104\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0274 - mape: 2769.7282 - val_loss: 0.0270 - val_mape: 88.7413\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0272 - mape: 2956.4113 - val_loss: 0.0265 - val_mape: 89.7168\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0270 - mape: 2545.8183 - val_loss: 0.0261 - val_mape: 91.2858\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0268 - mape: 3114.3707 - val_loss: 0.0258 - val_mape: 91.4449\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0269 - mape: 2928.3249 - val_loss: 0.0256 - val_mape: 90.9221\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0266 - mape: 2901.5800 - val_loss: 0.0253 - val_mape: 91.5354\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0262 - mape: 2331.0792 - val_loss: 0.0251 - val_mape: 91.3287\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0262 - mape: 2688.7419 - val_loss: 0.0249 - val_mape: 91.3659\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0259 - mape: 2540.5955 - val_loss: 0.0247 - val_mape: 90.4127\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0256 - mape: 2814.9527 - val_loss: 0.0245 - val_mape: 91.3368\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0255 - mape: 2526.1772 - val_loss: 0.0244 - val_mape: 89.4810\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0253 - mape: 2659.3773 - val_loss: 0.0243 - val_mape: 89.5795\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0251 - mape: 2053.3798 - val_loss: 0.0241 - val_mape: 89.7688\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0249 - mape: 2756.4660 - val_loss: 0.0239 - val_mape: 85.2011\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0247 - mape: 2053.2667 - val_loss: 0.0239 - val_mape: 89.1186\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0246 - mape: 1876.3003 - val_loss: 0.0236 - val_mape: 86.1859\n",
      "Epoch 26/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0242 - mape: 2164.3749 - val_loss: 0.0234 - val_mape: 85.9034\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0242 - mape: 2404.3834 - val_loss: 0.0232 - val_mape: 81.9999\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0241 - mape: 1982.5618 - val_loss: 0.0230 - val_mape: 79.9960\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0238 - mape: 2441.6135 - val_loss: 0.0228 - val_mape: 78.9139\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0235 - mape: 2312.5486 - val_loss: 0.0226 - val_mape: 81.4477\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0235 - mape: 2672.5402 - val_loss: 0.0224 - val_mape: 79.9734\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0233 - mape: 2496.3344 - val_loss: 0.0222 - val_mape: 82.0909\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0234 - mape: 2508.4102 - val_loss: 0.0221 - val_mape: 78.5909\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0232 - mape: 2225.8317 - val_loss: 0.0220 - val_mape: 76.6352\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0228 - mape: 2338.1126 - val_loss: 0.0219 - val_mape: 74.7951\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0229 - mape: 2126.3997 - val_loss: 0.0220 - val_mape: 72.2373\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0228 - mape: 2223.6053 - val_loss: 0.0216 - val_mape: 75.6391\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0227 - mape: 2035.2467 - val_loss: 0.0215 - val_mape: 74.7436\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0227 - mape: 2129.5522 - val_loss: 0.0214 - val_mape: 73.0333\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0226 - mape: 2256.5574 - val_loss: 0.0215 - val_mape: 72.0490\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0225 - mape: 1860.8696 - val_loss: 0.0214 - val_mape: 70.2901\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0224 - mape: 2888.8526 - val_loss: 0.0213 - val_mape: 71.1249\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0225 - mape: 2222.6851 - val_loss: 0.0211 - val_mape: 71.6512\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 2696.1247 - val_loss: 0.0211 - val_mape: 70.9856\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 2029.2144 - val_loss: 0.0211 - val_mape: 70.1953\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0222 - mape: 2058.0434 - val_loss: 0.0212 - val_mape: 68.4596\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0223 - mape: 2267.3856 - val_loss: 0.0208 - val_mape: 70.5352\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0221 - mape: 2031.3174 - val_loss: 0.0210 - val_mape: 68.4169\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0222 - mape: 2032.5808 - val_loss: 0.0207 - val_mape: 70.5695\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 2260.5492 - val_loss: 0.0208 - val_mape: 69.0070\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0220 - mape: 2040.5784 - val_loss: 0.0208 - val_mape: 67.7723\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0221 - mape: 2325.1745 - val_loss: 0.0215 - val_mape: 65.0068\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 2467.6808 - val_loss: 0.0206 - val_mape: 67.5020\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0218 - mape: 1882.1852 - val_loss: 0.0207 - val_mape: 66.7612\n",
      "Epoch 55/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 1692.6742 - val_loss: 0.0206 - val_mape: 67.2380\n",
      "Epoch 56/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0218 - mape: 2225.3058 - val_loss: 0.0206 - val_mape: 65.9443\n",
      "Epoch 57/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 2061.1356 - val_loss: 0.0205 - val_mape: 66.2611\n",
      "Epoch 58/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 1998.6488 - val_loss: 0.0204 - val_mape: 66.5192\n",
      "Epoch 59/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0218 - mape: 2100.8372 - val_loss: 0.0205 - val_mape: 65.8106\n",
      "Epoch 60/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 2261.2689 - val_loss: 0.0202 - val_mape: 67.5146\n",
      "Epoch 61/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 2396.9159 - val_loss: 0.0202 - val_mape: 66.3312\n",
      "Epoch 62/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 2057.6503 - val_loss: 0.0203 - val_mape: 65.6423\n",
      "Epoch 63/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 2289.0868 - val_loss: 0.0201 - val_mape: 66.4920\n",
      "Epoch 64/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 2000.0839 - val_loss: 0.0201 - val_mape: 66.0261\n",
      "Epoch 65/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 2315.6166 - val_loss: 0.0202 - val_mape: 65.6473\n",
      "Epoch 66/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 2276.7561 - val_loss: 0.0201 - val_mape: 65.7423\n",
      "Epoch 67/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2276.0686 - val_loss: 0.0203 - val_mape: 64.7453\n",
      "Epoch 68/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 1688.7035 - val_loss: 0.0200 - val_mape: 65.4872\n",
      "Epoch 69/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2181.0745 - val_loss: 0.0200 - val_mape: 66.0524\n",
      "Epoch 70/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2093.7222 - val_loss: 0.0199 - val_mape: 66.6315\n",
      "Epoch 71/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2122.1336 - val_loss: 0.0199 - val_mape: 65.5452\n",
      "Epoch 72/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2208.5762 - val_loss: 0.0201 - val_mape: 64.4067\n",
      "Epoch 73/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 2311.6144 - val_loss: 0.0199 - val_mape: 66.2260\n",
      "Epoch 74/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 1959.3259 - val_loss: 0.0197 - val_mape: 66.2430\n",
      "Epoch 75/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 2063.5527 - val_loss: 0.0198 - val_mape: 64.9574\n",
      "Epoch 76/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 2029.0911 - val_loss: 0.0198 - val_mape: 65.9046\n",
      "Epoch 77/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 1992.5361 - val_loss: 0.0198 - val_mape: 65.0471\n",
      "Epoch 78/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2096.9715 - val_loss: 0.0197 - val_mape: 66.2030\n",
      "Epoch 79/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 1996.8764 - val_loss: 0.0198 - val_mape: 64.7923\n",
      "Epoch 80/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 1953.2663 - val_loss: 0.0197 - val_mape: 65.3007\n",
      "Epoch 81/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 1933.5222 - val_loss: 0.0196 - val_mape: 65.6331\n",
      "Epoch 82/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 2025.6612 - val_loss: 0.0197 - val_mape: 65.2580\n",
      "Epoch 83/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 2168.8571 - val_loss: 0.0198 - val_mape: 64.7001\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 1806.2790 - val_loss: 0.0197 - val_mape: 64.8173\n",
      "Epoch 85/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 1777.1395 - val_loss: 0.0196 - val_mape: 65.3571\n",
      "Epoch 86/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 2041.7954 - val_loss: 0.0198 - val_mape: 64.4648\n",
      "Epoch 87/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 2044.2695 - val_loss: 0.0202 - val_mape: 62.9520\n",
      "Epoch 88/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2126.8654 - val_loss: 0.0194 - val_mape: 65.2204\n",
      "Epoch 89/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2144.8396 - val_loss: 0.0197 - val_mape: 64.5339\n",
      "Epoch 90/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 2037.0179 - val_loss: 0.0197 - val_mape: 64.1367\n",
      "Epoch 91/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 1938.8765 - val_loss: 0.0195 - val_mape: 65.2391\n",
      "Epoch 92/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 2065.1534 - val_loss: 0.0196 - val_mape: 64.9668\n",
      "Epoch 93/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 1934.8257 - val_loss: 0.0201 - val_mape: 62.8178\n",
      "Epoch 94/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2039.2312 - val_loss: 0.0195 - val_mape: 64.6678\n",
      "Epoch 95/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 1812.4747 - val_loss: 0.0201 - val_mape: 63.0030\n",
      "Epoch 96/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 1983.5885 - val_loss: 0.0193 - val_mape: 65.4823\n",
      "Epoch 97/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 2132.0005 - val_loss: 0.0196 - val_mape: 64.2495\n",
      "Epoch 98/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 1887.2358 - val_loss: 0.0197 - val_mape: 63.7245\n",
      "Epoch 99/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2131.5657 - val_loss: 0.0196 - val_mape: 64.2120\n",
      "Epoch 100/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2003.9599 - val_loss: 0.0193 - val_mape: 66.7827\n",
      "Epoch 101/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 1718.0976 - val_loss: 0.0199 - val_mape: 63.0782\n",
      "Epoch 102/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 2118.3473 - val_loss: 0.0196 - val_mape: 64.0762\n",
      "Epoch 103/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 2043.8896 - val_loss: 0.0193 - val_mape: 64.4743\n",
      "Epoch 104/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 2042.6279 - val_loss: 0.0196 - val_mape: 64.5505\n",
      "Epoch 105/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 1991.4365 - val_loss: 0.0195 - val_mape: 64.2141\n",
      "Epoch 106/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 1592.2812 - val_loss: 0.0197 - val_mape: 64.5206\n",
      "Epoch 107/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 1969.0043 - val_loss: 0.0194 - val_mape: 65.5312\n",
      "Epoch 108/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 1940.5571 - val_loss: 0.0193 - val_mape: 63.5849\n",
      "Epoch 109/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2030.1076 - val_loss: 0.0199 - val_mape: 62.5575\n",
      "Epoch 110/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 2105.2134 - val_loss: 0.0194 - val_mape: 64.9182\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.0231 - mape: 65.5881\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 10s 37ms/step - loss: 0.0375 - mape: 92.5640 - val_loss: 0.0328 - val_mape: 105.6811\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0308 - mape: 102.7459 - val_loss: 0.0322 - val_mape: 105.0110\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0299 - mape: 103.1285 - val_loss: 0.0317 - val_mape: 105.2404\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0290 - mape: 104.0454 - val_loss: 0.0309 - val_mape: 98.8046\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0282 - mape: 104.2902 - val_loss: 0.0295 - val_mape: 93.3166\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0278 - mape: 106.5213 - val_loss: 0.0288 - val_mape: 88.8523\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0275 - mape: 106.3966 - val_loss: 0.0285 - val_mape: 85.9017\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0274 - mape: 105.4309 - val_loss: 0.0281 - val_mape: 86.4513\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0271 - mape: 105.1074 - val_loss: 0.0281 - val_mape: 83.8146\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0270 - mape: 105.3886 - val_loss: 0.0278 - val_mape: 83.7931\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0266 - mape: 104.2970 - val_loss: 0.0274 - val_mape: 84.1608\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0265 - mape: 103.6515 - val_loss: 0.0271 - val_mape: 85.3448\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0261 - mape: 103.3650 - val_loss: 0.0272 - val_mape: 82.8621\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0260 - mape: 102.8509 - val_loss: 0.0269 - val_mape: 84.0106\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0257 - mape: 102.3791 - val_loss: 0.0267 - val_mape: 83.6975\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0255 - mape: 101.5096 - val_loss: 0.0267 - val_mape: 82.8497\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0252 - mape: 101.1906 - val_loss: 0.0263 - val_mape: 83.9308\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0250 - mape: 101.0528 - val_loss: 0.0261 - val_mape: 84.1332\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0249 - mape: 99.5150 - val_loss: 0.0262 - val_mape: 81.8740\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0247 - mape: 99.8022 - val_loss: 0.0262 - val_mape: 80.0376\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0245 - mape: 98.0245 - val_loss: 0.0265 - val_mape: 77.2564\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0244 - mape: 98.8997 - val_loss: 0.0262 - val_mape: 77.3479\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0243 - mape: 97.2398 - val_loss: 0.0264 - val_mape: 75.6728\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0241 - mape: 96.8902 - val_loss: 0.0269 - val_mape: 72.8703\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0240 - mape: 95.9927 - val_loss: 0.0261 - val_mape: 74.4324\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0239 - mape: 95.4402 - val_loss: 0.0260 - val_mape: 73.3826\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0237 - mape: 95.2765 - val_loss: 0.0261 - val_mape: 72.6492\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0235 - mape: 94.2003 - val_loss: 0.0263 - val_mape: 70.8481\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0233 - mape: 93.7599 - val_loss: 0.0263 - val_mape: 70.5050\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0233 - mape: 93.1096 - val_loss: 0.0262 - val_mape: 69.0604\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0231 - mape: 92.5830 - val_loss: 0.0258 - val_mape: 69.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0229 - mape: 91.8926 - val_loss: 0.0258 - val_mape: 68.8939\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0228 - mape: 91.3613 - val_loss: 0.0262 - val_mape: 68.1162\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 8s 36ms/step - loss: 0.0228 - mape: 90.6878 - val_loss: 0.0262 - val_mape: 67.2733\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0227 - mape: 90.9435 - val_loss: 0.0256 - val_mape: 67.6755\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0226 - mape: 90.6031 - val_loss: 0.0259 - val_mape: 66.3497\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0224 - mape: 89.6999 - val_loss: 0.0253 - val_mape: 66.2556\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 88.9765 - val_loss: 0.0254 - val_mape: 66.4367\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 88.2593 - val_loss: 0.0250 - val_mape: 65.6950\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0221 - mape: 88.6844 - val_loss: 0.0248 - val_mape: 65.9706\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0221 - mape: 88.9943 - val_loss: 0.0255 - val_mape: 64.6672\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0220 - mape: 88.2193 - val_loss: 0.0252 - val_mape: 65.3388\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0220 - mape: 88.7791 - val_loss: 0.0254 - val_mape: 64.4274\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0218 - mape: 86.8750 - val_loss: 0.0247 - val_mape: 64.5009\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 88.1253 - val_loss: 0.0252 - val_mape: 64.1665\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 86.8777 - val_loss: 0.0249 - val_mape: 64.1592\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 87.0689 - val_loss: 0.0243 - val_mape: 63.8043\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 86.3209 - val_loss: 0.0242 - val_mape: 64.2153\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 86.6555 - val_loss: 0.0244 - val_mape: 63.9060\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 86.5348 - val_loss: 0.0237 - val_mape: 64.9806\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 87.0982 - val_loss: 0.0231 - val_mape: 65.9996\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 87.3792 - val_loss: 0.0240 - val_mape: 64.1387\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 86.5710 - val_loss: 0.0240 - val_mape: 64.3367\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 86.0494 - val_loss: 0.0242 - val_mape: 63.3420\n",
      "Epoch 55/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 86.0079 - val_loss: 0.0236 - val_mape: 64.2546\n",
      "Epoch 56/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.1656 - val_loss: 0.0234 - val_mape: 64.7074\n",
      "Epoch 57/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.4766 - val_loss: 0.0229 - val_mape: 66.3217\n",
      "Epoch 58/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.9660 - val_loss: 0.0232 - val_mape: 65.9184\n",
      "Epoch 59/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 85.8084 - val_loss: 0.0224 - val_mape: 67.0858\n",
      "Epoch 60/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.9905 - val_loss: 0.0227 - val_mape: 66.5542\n",
      "Epoch 61/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 85.8868 - val_loss: 0.0225 - val_mape: 66.7278\n",
      "Epoch 62/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 85.3240 - val_loss: 0.0227 - val_mape: 65.0492\n",
      "Epoch 63/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 85.4818 - val_loss: 0.0233 - val_mape: 63.9830\n",
      "Epoch 64/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 85.1246 - val_loss: 0.0225 - val_mape: 64.9488\n",
      "Epoch 65/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 84.7598 - val_loss: 0.0224 - val_mape: 65.9208\n",
      "Epoch 66/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 84.8275 - val_loss: 0.0224 - val_mape: 66.0426\n",
      "Epoch 67/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0209 - mape: 84.9218 - val_loss: 0.0225 - val_mape: 64.5479\n",
      "Epoch 68/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 85.5894 - val_loss: 0.0227 - val_mape: 65.0505\n",
      "Epoch 69/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0209 - mape: 84.1785 - val_loss: 0.0230 - val_mape: 63.2344\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.0326 - mape: 29700.6484\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 10s 37ms/step - loss: 0.0383 - mape: 91.9828 - val_loss: 0.0416 - val_mape: 24525.7891\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0308 - mape: 102.1577 - val_loss: 0.0407 - val_mape: 24264.8926\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0296 - mape: 102.1417 - val_loss: 0.0398 - val_mape: 23456.3984\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0286 - mape: 103.5948 - val_loss: 0.0394 - val_mape: 25990.9844\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0282 - mape: 106.8029 - val_loss: 0.0392 - val_mape: 25670.9551\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0280 - mape: 107.8380 - val_loss: 0.0391 - val_mape: 26229.7363\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0278 - mape: 107.3829 - val_loss: 0.0390 - val_mape: 25860.2383\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0276 - mape: 105.8957 - val_loss: 0.0389 - val_mape: 26315.5547\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0274 - mape: 106.9707 - val_loss: 0.0388 - val_mape: 26078.7734\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0273 - mape: 106.8320 - val_loss: 0.0386 - val_mape: 26714.6055\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0270 - mape: 106.5404 - val_loss: 0.0385 - val_mape: 26991.6289\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0268 - mape: 105.4163 - val_loss: 0.0384 - val_mape: 26922.9062\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0266 - mape: 106.2956 - val_loss: 0.0383 - val_mape: 27508.1465\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0265 - mape: 105.4120 - val_loss: 0.0383 - val_mape: 27104.7617\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0263 - mape: 104.1070 - val_loss: 0.0382 - val_mape: 27032.1152\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0261 - mape: 103.7975 - val_loss: 0.0381 - val_mape: 27131.4336\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0260 - mape: 103.9391 - val_loss: 0.0380 - val_mape: 27468.1035\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0258 - mape: 103.7400 - val_loss: 0.0380 - val_mape: 27504.0078\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0256 - mape: 103.0690 - val_loss: 0.0379 - val_mape: 27548.3145\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0255 - mape: 103.1130 - val_loss: 0.0378 - val_mape: 27233.8359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0253 - mape: 102.0900 - val_loss: 0.0377 - val_mape: 27435.3496\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0253 - mape: 101.1187 - val_loss: 0.0377 - val_mape: 27277.6504\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0252 - mape: 100.4390 - val_loss: 0.0376 - val_mape: 27482.7285\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0250 - mape: 100.8035 - val_loss: 0.0375 - val_mape: 27100.0645\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0248 - mape: 99.8581 - val_loss: 0.0373 - val_mape: 27220.5996\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0247 - mape: 99.3732 - val_loss: 0.0370 - val_mape: 27994.8438\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0246 - mape: 99.4300 - val_loss: 0.0371 - val_mape: 27050.2793\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0244 - mape: 97.6492 - val_loss: 0.0370 - val_mape: 26707.6094\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0242 - mape: 98.4265 - val_loss: 0.0366 - val_mape: 27243.6895\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0241 - mape: 96.8878 - val_loss: 0.0365 - val_mape: 26957.1426\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0240 - mape: 96.7994 - val_loss: 0.0363 - val_mape: 26946.9922\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0239 - mape: 95.9507 - val_loss: 0.0360 - val_mape: 27426.4785\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0238 - mape: 96.2072 - val_loss: 0.0359 - val_mape: 26582.9844\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0236 - mape: 94.4083 - val_loss: 0.0357 - val_mape: 27238.5742\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0233 - mape: 93.8211 - val_loss: 0.0353 - val_mape: 27517.1270\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0233 - mape: 94.6169 - val_loss: 0.0354 - val_mape: 26316.9180\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0231 - mape: 92.0294 - val_loss: 0.0349 - val_mape: 27243.1719\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0229 - mape: 92.9923 - val_loss: 0.0350 - val_mape: 26437.0273\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0228 - mape: 92.2582 - val_loss: 0.0349 - val_mape: 26447.0547\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0227 - mape: 91.4835 - val_loss: 0.0346 - val_mape: 26682.0410\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0226 - mape: 90.4891 - val_loss: 0.0343 - val_mape: 26458.4473\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0225 - mape: 90.5039 - val_loss: 0.0340 - val_mape: 26765.5371\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 90.8442 - val_loss: 0.0335 - val_mape: 27540.8223\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0225 - mape: 90.5597 - val_loss: 0.0340 - val_mape: 25603.9707\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0223 - mape: 89.7309 - val_loss: 0.0336 - val_mape: 26517.8027\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0222 - mape: 90.1585 - val_loss: 0.0341 - val_mape: 25014.4570\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0221 - mape: 88.8001 - val_loss: 0.0336 - val_mape: 25228.2148\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0221 - mape: 88.6323 - val_loss: 0.0336 - val_mape: 25429.1992\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 88.4959 - val_loss: 0.0333 - val_mape: 25839.5586\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0219 - mape: 88.8314 - val_loss: 0.0330 - val_mape: 26493.5723\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0218 - mape: 87.7900 - val_loss: 0.0330 - val_mape: 25955.2773\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0218 - mape: 86.8244 - val_loss: 0.0330 - val_mape: 25572.4512\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0217 - mape: 87.3963 - val_loss: 0.0331 - val_mape: 24921.0312\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 86.3389 - val_loss: 0.0329 - val_mape: 25345.2754\n",
      "Epoch 55/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0216 - mape: 85.8661 - val_loss: 0.0327 - val_mape: 25949.8203\n",
      "Epoch 56/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 87.4881 - val_loss: 0.0328 - val_mape: 25159.0176\n",
      "Epoch 57/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 86.3064 - val_loss: 0.0325 - val_mape: 25712.1582\n",
      "Epoch 58/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 86.4082 - val_loss: 0.0324 - val_mape: 25304.9395\n",
      "Epoch 59/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0215 - mape: 86.6014 - val_loss: 0.0323 - val_mape: 25398.0234\n",
      "Epoch 60/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 85.3157 - val_loss: 0.0325 - val_mape: 25169.5566\n",
      "Epoch 61/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.4634 - val_loss: 0.0325 - val_mape: 24681.1914\n",
      "Epoch 62/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.5659 - val_loss: 0.0325 - val_mape: 24795.7812\n",
      "Epoch 63/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.9617 - val_loss: 0.0322 - val_mape: 25324.6992\n",
      "Epoch 64/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0214 - mape: 86.0706 - val_loss: 0.0323 - val_mape: 24919.6133\n",
      "Epoch 65/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0213 - mape: 85.1193 - val_loss: 0.0325 - val_mape: 24558.6758\n",
      "Epoch 66/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 84.2244 - val_loss: 0.0323 - val_mape: 24840.6875\n",
      "Epoch 67/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 84.7224 - val_loss: 0.0325 - val_mape: 24222.5664\n",
      "Epoch 68/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0212 - mape: 84.7170 - val_loss: 0.0325 - val_mape: 23686.8086\n",
      "Epoch 69/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 84.3041 - val_loss: 0.0323 - val_mape: 24405.6211\n",
      "Epoch 70/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 84.7103 - val_loss: 0.0324 - val_mape: 24056.9434\n",
      "Epoch 71/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 84.4453 - val_loss: 0.0323 - val_mape: 23586.7168\n",
      "Epoch 72/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0211 - mape: 84.7633 - val_loss: 0.0322 - val_mape: 24367.6484\n",
      "Epoch 73/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 84.7063 - val_loss: 0.0327 - val_mape: 22876.4473\n",
      "Epoch 74/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 84.0175 - val_loss: 0.0320 - val_mape: 24536.1543\n",
      "Epoch 75/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0210 - mape: 85.0490 - val_loss: 0.0323 - val_mape: 23508.5918\n",
      "Epoch 76/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0209 - mape: 83.6826 - val_loss: 0.0321 - val_mape: 24030.2324\n",
      "Epoch 77/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0209 - mape: 83.7436 - val_loss: 0.0323 - val_mape: 23396.5742\n",
      "Epoch 78/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0208 - mape: 83.5438 - val_loss: 0.0321 - val_mape: 23510.7168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0209 - mape: 83.9197 - val_loss: 0.0323 - val_mape: 23037.0078\n",
      "Epoch 80/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0208 - mape: 83.0453 - val_loss: 0.0328 - val_mape: 21916.5332\n",
      "Epoch 81/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0208 - mape: 83.4403 - val_loss: 0.0321 - val_mape: 23404.5938\n",
      "Epoch 82/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0208 - mape: 84.2658 - val_loss: 0.0324 - val_mape: 22812.8379\n",
      "Epoch 83/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0209 - mape: 85.0340 - val_loss: 0.0322 - val_mape: 23174.0918\n",
      "Epoch 84/200\n",
      "223/223 [==============================] - 8s 35ms/step - loss: 0.0208 - mape: 83.7932 - val_loss: 0.0321 - val_mape: 23381.5156\n",
      "159/159 [==============================] - 1s 8ms/step - loss: 0.0209 - mape: 68.8410\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 8s 20ms/step - loss: 0.0436 - mape: 1609.0875 - val_loss: 0.0323 - val_mape: 87.8193\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0384 - mape: 1570.6161 - val_loss: 0.0322 - val_mape: 89.4742\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0382 - mape: 1589.1791 - val_loss: 0.0321 - val_mape: 90.6384\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0381 - mape: 1581.4217 - val_loss: 0.0322 - val_mape: 89.6814\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0382 - mape: 1593.8988 - val_loss: 0.0322 - val_mape: 89.6820\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0382 - mape: 1580.9346 - val_loss: 0.0322 - val_mape: 88.9524\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0382 - mape: 1570.9717 - val_loss: 0.0322 - val_mape: 88.5879\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0383 - mape: 1562.7686 - val_loss: 0.0322 - val_mape: 88.2506\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0383 - mape: 1552.4677 - val_loss: 0.0322 - val_mape: 87.9528\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0383 - mape: 1546.9480 - val_loss: 0.0322 - val_mape: 87.8061\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0384 - mape: 1538.5098 - val_loss: 0.0322 - val_mape: 87.3383\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0384 - mape: 1535.5098 - val_loss: 0.0322 - val_mape: 87.2030\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0384 - mape: 1532.2006 - val_loss: 0.0322 - val_mape: 86.8957\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0288 - mape: 84.1205\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 8s 20ms/step - loss: 0.0327 - mape: 1571.7866 - val_loss: 0.0323 - val_mape: 88.2047\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 1565.2617 - val_loss: 0.0322 - val_mape: 89.9719\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 1570.9917 - val_loss: 0.0322 - val_mape: 88.8000\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1559.8611 - val_loss: 0.0322 - val_mape: 88.2984\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1565.6418 - val_loss: 0.0322 - val_mape: 88.6911\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1552.0993 - val_loss: 0.0322 - val_mape: 88.0027\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1543.6885 - val_loss: 0.0322 - val_mape: 87.6839\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1542.5082 - val_loss: 0.0322 - val_mape: 87.5122\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1540.6737 - val_loss: 0.0322 - val_mape: 87.2835\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1537.7420 - val_loss: 0.0322 - val_mape: 87.2069\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0292 - mape: 1537.0479 - val_loss: 0.0322 - val_mape: 86.8122\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 1534.2779 - val_loss: 0.0322 - val_mape: 86.8644\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0427 - mape: 85.2970\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 8s 19ms/step - loss: 0.0331 - mape: 1676.3864 - val_loss: 0.0321 - val_mape: 93.2159\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0297 - mape: 1711.9458 - val_loss: 0.0321 - val_mape: 93.0697\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1752.0115 - val_loss: 0.0321 - val_mape: 92.8057\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1768.3734 - val_loss: 0.0321 - val_mape: 92.6064\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1763.6170 - val_loss: 0.0321 - val_mape: 91.4744\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1795.6527 - val_loss: 0.0322 - val_mape: 90.8866\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1808.2035 - val_loss: 0.0322 - val_mape: 89.5087\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1820.7257 - val_loss: 0.0322 - val_mape: 88.6412\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1835.7526 - val_loss: 0.0322 - val_mape: 87.7453\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1853.3319 - val_loss: 0.0322 - val_mape: 87.0286\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1859.7827 - val_loss: 0.0322 - val_mape: 86.3005\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0296 - mape: 1871.4386 - val_loss: 0.0323 - val_mape: 85.9455\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0357 - mape: 90.7924\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 8s 19ms/step - loss: 0.0330 - mape: 102.6261 - val_loss: 0.0326 - val_mape: 83.5898\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0297 - mape: 104.6529 - val_loss: 0.0324 - val_mape: 85.6315\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.3650 - val_loss: 0.0324 - val_mape: 87.0597\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.4256 - val_loss: 0.0324 - val_mape: 88.2637\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.2617 - val_loss: 0.0323 - val_mape: 89.1498\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.2687 - val_loss: 0.0323 - val_mape: 89.5451\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.2363 - val_loss: 0.0323 - val_mape: 90.2081\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.1744 - val_loss: 0.0323 - val_mape: 90.8650\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.1379 - val_loss: 0.0323 - val_mape: 91.4914\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0864 - val_loss: 0.0323 - val_mape: 92.0697\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.1318 - val_loss: 0.0323 - val_mape: 92.8277\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0713 - val_loss: 0.0323 - val_mape: 93.5555\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.1261 - val_loss: 0.0323 - val_mape: 94.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0636 - val_loss: 0.0323 - val_mape: 94.3957\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.7843 - val_loss: 0.0324 - val_mape: 89.5108\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.2278 - val_loss: 0.0323 - val_mape: 93.4790\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0648 - val_loss: 0.0323 - val_mape: 94.2305\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.9636 - val_loss: 0.0323 - val_mape: 95.0712\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.9068 - val_loss: 0.0322 - val_mape: 95.5374\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.8194 - val_loss: 0.0322 - val_mape: 96.0309\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.6409 - val_loss: 0.0322 - val_mape: 96.5275\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.6592 - val_loss: 0.0322 - val_mape: 97.2672\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.6479 - val_loss: 0.0322 - val_mape: 97.9301\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.8203 - val_loss: 0.0322 - val_mape: 98.5950\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.8335 - val_loss: 0.0322 - val_mape: 99.2472\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 104.9241 - val_loss: 0.0322 - val_mape: 99.8560\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9453 - val_loss: 0.0322 - val_mape: 100.5074\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9695 - val_loss: 0.0322 - val_mape: 100.9123\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9809 - val_loss: 0.0322 - val_mape: 101.6011\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9364 - val_loss: 0.0322 - val_mape: 102.0354\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9568 - val_loss: 0.0322 - val_mape: 102.4656\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9303 - val_loss: 0.0322 - val_mape: 102.9445\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9544 - val_loss: 0.0322 - val_mape: 103.3021\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 104.9826 - val_loss: 0.0322 - val_mape: 103.9076\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.0651 - val_loss: 0.0322 - val_mape: 104.2257\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.0365 - val_loss: 0.0322 - val_mape: 104.4429\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.0252 - val_loss: 0.0322 - val_mape: 104.8772\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.0585 - val_loss: 0.0322 - val_mape: 105.2140\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.0883 - val_loss: 0.0322 - val_mape: 105.4622\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.0817 - val_loss: 0.0322 - val_mape: 105.7464\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.1232 - val_loss: 0.0322 - val_mape: 106.0434\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.1126 - val_loss: 0.0322 - val_mape: 106.3850\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0293 - mape: 105.1558 - val_loss: 0.0322 - val_mape: 106.4511\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0415 - mape: 31609.3164\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 8s 20ms/step - loss: 0.0330 - mape: 102.7758 - val_loss: 0.0408 - val_mape: 21500.3828\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0297 - mape: 104.1148 - val_loss: 0.0406 - val_mape: 22417.5645\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.2353 - val_loss: 0.0405 - val_mape: 22413.5840\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0295 - mape: 105.0631 - val_loss: 0.0405 - val_mape: 23179.5527\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0041 - val_loss: 0.0406 - val_mape: 23480.6719\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0150 - val_loss: 0.0406 - val_mape: 23606.4961\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0423 - val_loss: 0.0406 - val_mape: 23663.4434\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0454 - val_loss: 0.0406 - val_mape: 23813.9648\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.1030 - val_loss: 0.0406 - val_mape: 23823.0293\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0563 - val_loss: 0.0406 - val_mape: 23926.8086\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0349 - val_loss: 0.0406 - val_mape: 24052.0547\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0982 - val_loss: 0.0406 - val_mape: 24097.1191\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 4s 17ms/step - loss: 0.0294 - mape: 105.0066 - val_loss: 0.0406 - val_mape: 24153.5430\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0313 - mape: 91.0298\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 23ms/step - loss: 0.0378 - mape: 1697.2468 - val_loss: 0.0321 - val_mape: 98.2210\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0378 - mape: 1557.2072 - val_loss: 0.0321 - val_mape: 96.5928\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0378 - mape: 1562.5278 - val_loss: 0.0321 - val_mape: 96.5195\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0379 - mape: 1561.3209 - val_loss: 0.0321 - val_mape: 96.2998\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0379 - mape: 1560.1730 - val_loss: 0.0321 - val_mape: 96.1290\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0379 - mape: 1557.9054 - val_loss: 0.0321 - val_mape: 96.4300\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0379 - mape: 1561.2443 - val_loss: 0.0321 - val_mape: 96.5965\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0378 - mape: 1558.5167 - val_loss: 0.0321 - val_mape: 96.5015\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0378 - mape: 1562.6092 - val_loss: 0.0321 - val_mape: 96.4542\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0379 - mape: 1560.8812 - val_loss: 0.0321 - val_mape: 96.4306\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0379 - mape: 1561.7614 - val_loss: 0.0321 - val_mape: 96.5147\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0283 - mape: 89.0306\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 23ms/step - loss: 0.0309 - mape: 1690.5094 - val_loss: 0.0321 - val_mape: 99.4106\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0293 - mape: 1549.5755 - val_loss: 0.0321 - val_mape: 97.6682\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0292 - mape: 1544.0158 - val_loss: 0.0321 - val_mape: 97.3416\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0292 - mape: 1540.4616 - val_loss: 0.0321 - val_mape: 97.0597\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0292 - mape: 1537.9897 - val_loss: 0.0321 - val_mape: 97.0666\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0292 - mape: 1543.8996 - val_loss: 0.0321 - val_mape: 98.0215\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0292 - mape: 1541.4978 - val_loss: 0.0321 - val_mape: 97.6278\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0292 - mape: 1537.8219 - val_loss: 0.0321 - val_mape: 97.5301\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0292 - mape: 1541.7921 - val_loss: 0.0321 - val_mape: 97.4425\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0292 - mape: 1542.6253 - val_loss: 0.0321 - val_mape: 98.5252\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0292 - mape: 1542.5326 - val_loss: 0.0321 - val_mape: 97.8886\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0415 - mape: 89.7463\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 23ms/step - loss: 0.0313 - mape: 1500.1089 - val_loss: 0.0321 - val_mape: 99.6160\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0298 - mape: 1557.6822 - val_loss: 0.0321 - val_mape: 98.5895\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1591.7120 - val_loss: 0.0321 - val_mape: 97.5458\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1589.3743 - val_loss: 0.0321 - val_mape: 97.2717\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1588.8109 - val_loss: 0.0321 - val_mape: 97.5035\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1591.8136 - val_loss: 0.0321 - val_mape: 97.8692\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1588.6320 - val_loss: 0.0321 - val_mape: 96.8849\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1591.2911 - val_loss: 0.0321 - val_mape: 97.3619\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1591.9814 - val_loss: 0.0321 - val_mape: 98.1313\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1591.4631 - val_loss: 0.0321 - val_mape: 97.4186\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0297 - mape: 1593.1988 - val_loss: 0.0321 - val_mape: 97.8937\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0357 - mape: 97.3802\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 23ms/step - loss: 0.0312 - mape: 117.9984 - val_loss: 0.0322 - val_mape: 108.5855\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 112.9801 - val_loss: 0.0322 - val_mape: 101.2788\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.0843 - val_loss: 0.0322 - val_mape: 102.4298\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.1187 - val_loss: 0.0322 - val_mape: 102.5802\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.0329 - val_loss: 0.0322 - val_mape: 102.2370\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.1759 - val_loss: 0.0322 - val_mape: 104.5842\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2631 - val_loss: 0.0322 - val_mape: 103.7045\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3618 - val_loss: 0.0322 - val_mape: 103.6673\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3360 - val_loss: 0.0322 - val_mape: 104.2607\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2165 - val_loss: 0.0322 - val_mape: 103.3589\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2561 - val_loss: 0.0322 - val_mape: 103.2516\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3531 - val_loss: 0.0322 - val_mape: 103.3968\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3631 - val_loss: 0.0322 - val_mape: 104.0238\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.1566 - val_loss: 0.0322 - val_mape: 103.9480\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3462 - val_loss: 0.0322 - val_mape: 103.8576\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3610 - val_loss: 0.0322 - val_mape: 103.7679\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2960 - val_loss: 0.0322 - val_mape: 104.5395\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2339 - val_loss: 0.0322 - val_mape: 104.4829\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2111 - val_loss: 0.0322 - val_mape: 104.4123\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3004 - val_loss: 0.0322 - val_mape: 104.5244\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.0477 - val_loss: 0.0322 - val_mape: 104.4587\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0296 - mape: 113.3568 - val_loss: 0.0322 - val_mape: 103.6605\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0415 - mape: 31638.3398\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 7s 23ms/step - loss: 0.0312 - mape: 118.9864 - val_loss: 0.0411 - val_mape: 27901.3398\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 112.9173 - val_loss: 0.0408 - val_mape: 26139.6973\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.0974 - val_loss: 0.0408 - val_mape: 25983.6660\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.1857 - val_loss: 0.0409 - val_mape: 26352.8906\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.1952 - val_loss: 0.0408 - val_mape: 26043.0508\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2305 - val_loss: 0.0409 - val_mape: 26447.0293\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2815 - val_loss: 0.0409 - val_mape: 26435.2891\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3374 - val_loss: 0.0409 - val_mape: 26338.0449\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.2218 - val_loss: 0.0409 - val_mape: 26337.7070\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3513 - val_loss: 0.0409 - val_mape: 26371.2715\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 5s 22ms/step - loss: 0.0296 - mape: 113.3326 - val_loss: 0.0409 - val_mape: 26525.1191\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0296 - mape: 113.1627 - val_loss: 0.0409 - val_mape: 26504.3340\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 5s 21ms/step - loss: 0.0296 - mape: 113.3590 - val_loss: 0.0409 - val_mape: 26478.0645\n",
      "159/159 [==============================] - 1s 4ms/step - loss: 0.0311 - mape: 104.6567\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 12ms/step - loss: 0.0567 - mape: 195.1165 - val_loss: 0.0436 - val_mape: 88.6865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0546 - mape: 309.2283 - val_loss: 0.0416 - val_mape: 77.2050\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0525 - mape: 425.0674 - val_loss: 0.0396 - val_mape: 68.9223\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0507 - mape: 536.2799 - val_loss: 0.0381 - val_mape: 65.3413\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0491 - mape: 644.8108 - val_loss: 0.0369 - val_mape: 64.3108\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0478 - mape: 751.5003 - val_loss: 0.0358 - val_mape: 65.0818\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0465 - mape: 856.7918 - val_loss: 0.0350 - val_mape: 66.9449\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0454 - mape: 958.8437 - val_loss: 0.0342 - val_mape: 69.6594\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0444 - mape: 1054.3947 - val_loss: 0.0337 - val_mape: 72.9445\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0436 - mape: 1141.8157 - val_loss: 0.0334 - val_mape: 76.4961\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0429 - mape: 1221.1993 - val_loss: 0.0331 - val_mape: 80.0008\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0423 - mape: 1292.4603 - val_loss: 0.0329 - val_mape: 83.4595\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0417 - mape: 1359.0408 - val_loss: 0.0327 - val_mape: 86.8451\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0413 - mape: 1421.0862 - val_loss: 0.0326 - val_mape: 90.1291\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0409 - mape: 1478.0350 - val_loss: 0.0325 - val_mape: 93.2097\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0405 - mape: 1529.1738 - val_loss: 0.0325 - val_mape: 96.0506\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0402 - mape: 1575.1942 - val_loss: 0.0324 - val_mape: 98.6793\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0400 - mape: 1616.0714 - val_loss: 0.0324 - val_mape: 101.0495\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0398 - mape: 1652.3689 - val_loss: 0.0324 - val_mape: 103.2009\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0396 - mape: 1683.7492 - val_loss: 0.0324 - val_mape: 105.0851\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0395 - mape: 1710.1299 - val_loss: 0.0324 - val_mape: 106.6789\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0393 - mape: 1732.1681 - val_loss: 0.0324 - val_mape: 108.0302\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0393 - mape: 1750.4950 - val_loss: 0.0324 - val_mape: 109.1312\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0392 - mape: 1765.0319 - val_loss: 0.0324 - val_mape: 109.9748\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0391 - mape: 1776.8375 - val_loss: 0.0324 - val_mape: 110.6904\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0391 - mape: 1786.4726 - val_loss: 0.0324 - val_mape: 111.2833\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0391 - mape: 1793.6859 - val_loss: 0.0324 - val_mape: 111.6823\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0390 - mape: 1799.5287 - val_loss: 0.0324 - val_mape: 112.0339\n",
      "Epoch 29/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0390 - mape: 1804.6509 - val_loss: 0.0324 - val_mape: 112.3156\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0390 - mape: 1809.1619 - val_loss: 0.0324 - val_mape: 112.5883\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0286 - mape: 95.2997\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 12ms/step - loss: 0.0449 - mape: 191.4874 - val_loss: 0.0437 - val_mape: 89.0996\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0429 - mape: 300.4802 - val_loss: 0.0417 - val_mape: 77.9125\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0409 - mape: 412.5447 - val_loss: 0.0398 - val_mape: 69.4573\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0391 - mape: 521.7204 - val_loss: 0.0383 - val_mape: 65.6520\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0376 - mape: 628.8718 - val_loss: 0.0370 - val_mape: 64.3406\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0363 - mape: 733.7441 - val_loss: 0.0360 - val_mape: 64.9213\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0351 - mape: 836.5197 - val_loss: 0.0351 - val_mape: 66.6034\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0341 - mape: 935.8421 - val_loss: 0.0344 - val_mape: 69.0990\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0332 - mape: 1029.9470 - val_loss: 0.0338 - val_mape: 72.1683\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0325 - mape: 1115.6880 - val_loss: 0.0335 - val_mape: 75.5343\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0320 - mape: 1192.8601 - val_loss: 0.0332 - val_mape: 78.8526\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0315 - mape: 1259.4174 - val_loss: 0.0330 - val_mape: 81.9124\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0312 - mape: 1319.6242 - val_loss: 0.0328 - val_mape: 84.8889\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0309 - mape: 1374.9036 - val_loss: 0.0327 - val_mape: 87.7029\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 1424.9915 - val_loss: 0.0326 - val_mape: 90.2958\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 1473.7867 - val_loss: 0.0325 - val_mape: 92.8638\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 1513.2459 - val_loss: 0.0325 - val_mape: 94.9887\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0302 - mape: 1546.7203 - val_loss: 0.0325 - val_mape: 96.8356\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0302 - mape: 1574.8816 - val_loss: 0.0324 - val_mape: 98.3644\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0301 - mape: 1598.5494 - val_loss: 0.0324 - val_mape: 99.6866\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0300 - mape: 1617.4343 - val_loss: 0.0324 - val_mape: 100.7268\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0300 - mape: 1632.9941 - val_loss: 0.0324 - val_mape: 101.5891\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0300 - mape: 1646.6823 - val_loss: 0.0324 - val_mape: 102.3660\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0299 - mape: 1658.1452 - val_loss: 0.0324 - val_mape: 103.0253\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0299 - mape: 1666.9688 - val_loss: 0.0324 - val_mape: 103.5174\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0299 - mape: 1673.9574 - val_loss: 0.0324 - val_mape: 103.9166\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0299 - mape: 1679.2980 - val_loss: 0.0324 - val_mape: 104.2166\n",
      "Epoch 28/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1683.7752 - val_loss: 0.0324 - val_mape: 104.4643\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1687.0247 - val_loss: 0.0324 - val_mape: 104.6480\n",
      "Epoch 30/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1689.3931 - val_loss: 0.0323 - val_mape: 104.7651\n",
      "Epoch 31/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1691.4514 - val_loss: 0.0323 - val_mape: 104.8745\n",
      "Epoch 32/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1693.0836 - val_loss: 0.0323 - val_mape: 104.9572\n",
      "Epoch 33/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1694.2694 - val_loss: 0.0323 - val_mape: 105.0191\n",
      "Epoch 34/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1695.1563 - val_loss: 0.0323 - val_mape: 105.0535\n",
      "Epoch 35/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1696.1776 - val_loss: 0.0323 - val_mape: 105.0964\n",
      "Epoch 36/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1697.0723 - val_loss: 0.0323 - val_mape: 105.1282\n",
      "Epoch 37/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1697.9072 - val_loss: 0.0323 - val_mape: 105.1673\n",
      "Epoch 38/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1698.5165 - val_loss: 0.0323 - val_mape: 105.1954\n",
      "Epoch 39/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0298 - mape: 1698.9008 - val_loss: 0.0323 - val_mape: 105.1993\n",
      "Epoch 40/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.1702 - val_loss: 0.0323 - val_mape: 105.1986\n",
      "Epoch 41/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.3833 - val_loss: 0.0323 - val_mape: 105.1972\n",
      "Epoch 42/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5868 - val_loss: 0.0323 - val_mape: 105.1939\n",
      "Epoch 43/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.6588 - val_loss: 0.0323 - val_mape: 105.1862\n",
      "Epoch 44/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.9402 - val_loss: 0.0323 - val_mape: 105.1924\n",
      "Epoch 45/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.9764 - val_loss: 0.0323 - val_mape: 105.1863\n",
      "Epoch 46/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.9309 - val_loss: 0.0323 - val_mape: 105.1623\n",
      "Epoch 47/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.7693 - val_loss: 0.0323 - val_mape: 105.1423\n",
      "Epoch 48/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.6576 - val_loss: 0.0323 - val_mape: 105.1262\n",
      "Epoch 49/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5474 - val_loss: 0.0323 - val_mape: 105.1085\n",
      "Epoch 50/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5547 - val_loss: 0.0323 - val_mape: 105.0956\n",
      "Epoch 51/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5850 - val_loss: 0.0323 - val_mape: 105.0941\n",
      "Epoch 52/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5749 - val_loss: 0.0323 - val_mape: 105.0863\n",
      "Epoch 53/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5846 - val_loss: 0.0323 - val_mape: 105.0807\n",
      "Epoch 54/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.5325 - val_loss: 0.0323 - val_mape: 105.0602\n",
      "Epoch 55/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.3295 - val_loss: 0.0323 - val_mape: 105.0370\n",
      "Epoch 56/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1699.1214 - val_loss: 0.0323 - val_mape: 105.0146\n",
      "Epoch 57/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1698.8770 - val_loss: 0.0323 - val_mape: 104.9932\n",
      "Epoch 58/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1698.6647 - val_loss: 0.0323 - val_mape: 104.9705\n",
      "Epoch 59/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0297 - mape: 1698.7156 - val_loss: 0.0323 - val_mape: 104.9613\n",
      "Epoch 60/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1698.6841 - val_loss: 0.0323 - val_mape: 104.9528\n",
      "Epoch 61/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1698.7786 - val_loss: 0.0323 - val_mape: 104.9530\n",
      "Epoch 62/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1698.6645 - val_loss: 0.0323 - val_mape: 104.9394\n",
      "Epoch 63/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1698.4277 - val_loss: 0.0322 - val_mape: 104.9069\n",
      "Epoch 64/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1698.0596 - val_loss: 0.0322 - val_mape: 104.8756\n",
      "Epoch 65/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.6580 - val_loss: 0.0322 - val_mape: 104.8380\n",
      "Epoch 66/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.2086 - val_loss: 0.0322 - val_mape: 104.8021\n",
      "Epoch 67/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.0500 - val_loss: 0.0322 - val_mape: 104.7900\n",
      "Epoch 68/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.0459 - val_loss: 0.0322 - val_mape: 104.7810\n",
      "Epoch 69/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.1402 - val_loss: 0.0322 - val_mape: 104.7829\n",
      "Epoch 70/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.1767 - val_loss: 0.0322 - val_mape: 104.7790\n",
      "Epoch 71/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.2211 - val_loss: 0.0322 - val_mape: 104.7750\n",
      "Epoch 72/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.1933 - val_loss: 0.0322 - val_mape: 104.7714\n",
      "Epoch 73/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.9406 - val_loss: 0.0322 - val_mape: 104.7419\n",
      "Epoch 74/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.5689 - val_loss: 0.0322 - val_mape: 104.7079\n",
      "Epoch 75/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.3206 - val_loss: 0.0322 - val_mape: 104.6877\n",
      "Epoch 76/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.1503 - val_loss: 0.0322 - val_mape: 104.6705\n",
      "Epoch 77/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.3866 - val_loss: 0.0322 - val_mape: 104.6812\n",
      "Epoch 78/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.7359 - val_loss: 0.0322 - val_mape: 104.6974\n",
      "Epoch 79/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.1032 - val_loss: 0.0322 - val_mape: 104.7109\n",
      "Epoch 80/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.1859 - val_loss: 0.0322 - val_mape: 104.7121\n",
      "Epoch 81/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1697.1228 - val_loss: 0.0322 - val_mape: 104.7027\n",
      "Epoch 82/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.8484 - val_loss: 0.0322 - val_mape: 104.6782\n",
      "Epoch 83/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1696.4368 - val_loss: 0.0322 - val_mape: 104.6509\n",
      "Epoch 84/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1695.7901 - val_loss: 0.0322 - val_mape: 104.6056\n",
      "Epoch 85/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1695.0981 - val_loss: 0.0322 - val_mape: 104.5569\n",
      "Epoch 86/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1694.4344 - val_loss: 0.0322 - val_mape: 104.5098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1694.1565 - val_loss: 0.0322 - val_mape: 104.4889\n",
      "Epoch 88/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.9807 - val_loss: 0.0322 - val_mape: 104.4722\n",
      "Epoch 89/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.8362 - val_loss: 0.0322 - val_mape: 104.4555\n",
      "Epoch 90/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.7813 - val_loss: 0.0322 - val_mape: 104.4467\n",
      "Epoch 91/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.6620 - val_loss: 0.0322 - val_mape: 104.4369\n",
      "Epoch 92/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.5956 - val_loss: 0.0322 - val_mape: 104.4286\n",
      "Epoch 93/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.4928 - val_loss: 0.0322 - val_mape: 104.4196\n",
      "Epoch 94/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0296 - mape: 1693.3295 - val_loss: 0.0322 - val_mape: 104.4057\n",
      "Epoch 95/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1693.0566 - val_loss: 0.0322 - val_mape: 104.3865\n",
      "Epoch 96/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1692.7137 - val_loss: 0.0322 - val_mape: 104.3612\n",
      "Epoch 97/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1692.4065 - val_loss: 0.0322 - val_mape: 104.3376\n",
      "Epoch 98/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1692.2129 - val_loss: 0.0322 - val_mape: 104.3241\n",
      "Epoch 99/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1691.9393 - val_loss: 0.0322 - val_mape: 104.3053\n",
      "Epoch 100/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1691.7325 - val_loss: 0.0322 - val_mape: 104.2864\n",
      "Epoch 101/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1691.4824 - val_loss: 0.0322 - val_mape: 104.2632\n",
      "Epoch 102/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1691.1838 - val_loss: 0.0322 - val_mape: 104.2388\n",
      "Epoch 103/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1690.8855 - val_loss: 0.0322 - val_mape: 104.2194\n",
      "Epoch 104/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1690.6062 - val_loss: 0.0322 - val_mape: 104.1968\n",
      "Epoch 105/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1690.3265 - val_loss: 0.0322 - val_mape: 104.1705\n",
      "Epoch 106/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1690.0541 - val_loss: 0.0322 - val_mape: 104.1510\n",
      "Epoch 107/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.8967 - val_loss: 0.0322 - val_mape: 104.1393\n",
      "Epoch 108/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.9249 - val_loss: 0.0322 - val_mape: 104.1349\n",
      "Epoch 109/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1690.0090 - val_loss: 0.0322 - val_mape: 104.1368\n",
      "Epoch 110/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1690.0339 - val_loss: 0.0322 - val_mape: 104.1351\n",
      "Epoch 111/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.9696 - val_loss: 0.0322 - val_mape: 104.1319\n",
      "Epoch 112/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.8777 - val_loss: 0.0322 - val_mape: 104.1233\n",
      "Epoch 113/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.9071 - val_loss: 0.0322 - val_mape: 104.1241\n",
      "Epoch 114/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.9108 - val_loss: 0.0322 - val_mape: 104.1221\n",
      "Epoch 115/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.6467 - val_loss: 0.0322 - val_mape: 104.1027\n",
      "Epoch 116/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1689.2911 - val_loss: 0.0322 - val_mape: 104.0795\n",
      "Epoch 117/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1688.8099 - val_loss: 0.0322 - val_mape: 104.0423\n",
      "Epoch 118/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1688.2559 - val_loss: 0.0322 - val_mape: 104.0031\n",
      "Epoch 119/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1687.7023 - val_loss: 0.0322 - val_mape: 103.9650\n",
      "Epoch 120/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1687.1640 - val_loss: 0.0322 - val_mape: 103.9293\n",
      "Epoch 121/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.9156 - val_loss: 0.0322 - val_mape: 103.9128\n",
      "Epoch 122/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.7130 - val_loss: 0.0322 - val_mape: 103.8958\n",
      "Epoch 123/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.5279 - val_loss: 0.0322 - val_mape: 103.8816\n",
      "Epoch 124/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.4312 - val_loss: 0.0322 - val_mape: 103.8715\n",
      "Epoch 125/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.3919 - val_loss: 0.0322 - val_mape: 103.8639\n",
      "Epoch 126/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.3406 - val_loss: 0.0322 - val_mape: 103.8584\n",
      "Epoch 127/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.2881 - val_loss: 0.0322 - val_mape: 103.8536\n",
      "Epoch 128/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.2544 - val_loss: 0.0322 - val_mape: 103.8439\n",
      "Epoch 129/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1686.0806 - val_loss: 0.0322 - val_mape: 103.8301\n",
      "Epoch 130/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1685.8555 - val_loss: 0.0322 - val_mape: 103.7917\n",
      "Epoch 131/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1685.6364 - val_loss: 0.0322 - val_mape: 103.7990\n",
      "Epoch 132/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1685.4074 - val_loss: 0.0322 - val_mape: 103.7815\n",
      "Epoch 133/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1685.0625 - val_loss: 0.0322 - val_mape: 103.7578\n",
      "Epoch 134/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1684.7916 - val_loss: 0.0322 - val_mape: 103.7384\n",
      "Epoch 135/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1684.4784 - val_loss: 0.0322 - val_mape: 103.7179\n",
      "Epoch 136/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1684.0563 - val_loss: 0.0322 - val_mape: 103.6895\n",
      "Epoch 137/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1683.6528 - val_loss: 0.0322 - val_mape: 103.6625\n",
      "Epoch 138/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1683.3382 - val_loss: 0.0322 - val_mape: 103.6410\n",
      "Epoch 139/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1683.0081 - val_loss: 0.0322 - val_mape: 103.6198\n",
      "Epoch 140/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1682.7411 - val_loss: 0.0322 - val_mape: 103.5996\n",
      "Epoch 141/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1682.5110 - val_loss: 0.0322 - val_mape: 103.5820\n",
      "Epoch 142/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1682.2609 - val_loss: 0.0322 - val_mape: 103.5648\n",
      "Epoch 143/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1682.0845 - val_loss: 0.0322 - val_mape: 103.5524\n",
      "Epoch 144/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.9410 - val_loss: 0.0322 - val_mape: 103.5399\n",
      "Epoch 145/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.7683 - val_loss: 0.0322 - val_mape: 103.5263\n",
      "Epoch 146/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.6165 - val_loss: 0.0322 - val_mape: 103.5154\n",
      "Epoch 147/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.4834 - val_loss: 0.0322 - val_mape: 103.5028\n",
      "Epoch 148/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.4983 - val_loss: 0.0322 - val_mape: 103.5021\n",
      "Epoch 149/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.5873 - val_loss: 0.0321 - val_mape: 103.4975\n",
      "Epoch 150/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.7249 - val_loss: 0.0321 - val_mape: 103.5135\n",
      "Epoch 151/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.8305 - val_loss: 0.0321 - val_mape: 103.5161\n",
      "Epoch 152/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.8516 - val_loss: 0.0321 - val_mape: 103.5176\n",
      "Epoch 153/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.8477 - val_loss: 0.0321 - val_mape: 103.5158\n",
      "Epoch 154/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.9027 - val_loss: 0.0321 - val_mape: 103.5169\n",
      "Epoch 155/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.9649 - val_loss: 0.0321 - val_mape: 103.5078\n",
      "Epoch 156/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.9600 - val_loss: 0.0321 - val_mape: 103.5067\n",
      "Epoch 157/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1682.0013 - val_loss: 0.0321 - val_mape: 103.5060\n",
      "Epoch 158/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.7909 - val_loss: 0.0321 - val_mape: 103.4931\n",
      "Epoch 159/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.4649 - val_loss: 0.0321 - val_mape: 103.4714\n",
      "Epoch 160/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.1264 - val_loss: 0.0321 - val_mape: 103.4499\n",
      "Epoch 161/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.7688 - val_loss: 0.0321 - val_mape: 103.4259\n",
      "Epoch 162/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.4519 - val_loss: 0.0321 - val_mape: 103.4071\n",
      "Epoch 163/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.1480 - val_loss: 0.0321 - val_mape: 103.3869\n",
      "Epoch 164/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.8069 - val_loss: 0.0321 - val_mape: 103.3610\n",
      "Epoch 165/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.4895 - val_loss: 0.0321 - val_mape: 103.3402\n",
      "Epoch 166/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.3148 - val_loss: 0.0321 - val_mape: 103.3298\n",
      "Epoch 167/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.3037 - val_loss: 0.0321 - val_mape: 103.3249\n",
      "Epoch 168/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.3232 - val_loss: 0.0321 - val_mape: 103.3265\n",
      "Epoch 169/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.3246 - val_loss: 0.0321 - val_mape: 103.3267\n",
      "Epoch 170/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.3627 - val_loss: 0.0321 - val_mape: 103.3294\n",
      "Epoch 171/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.4092 - val_loss: 0.0321 - val_mape: 103.3314\n",
      "Epoch 172/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.5676 - val_loss: 0.0321 - val_mape: 103.3414\n",
      "Epoch 173/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1679.7850 - val_loss: 0.0321 - val_mape: 103.3530\n",
      "Epoch 174/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.0163 - val_loss: 0.0321 - val_mape: 103.3646\n",
      "Epoch 175/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.3076 - val_loss: 0.0321 - val_mape: 103.3845\n",
      "Epoch 176/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.6497 - val_loss: 0.0321 - val_mape: 103.4026\n",
      "Epoch 177/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.9396 - val_loss: 0.0321 - val_mape: 103.4207\n",
      "Epoch 178/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.1113 - val_loss: 0.0321 - val_mape: 103.4296\n",
      "Epoch 179/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.2056 - val_loss: 0.0321 - val_mape: 103.4346\n",
      "Epoch 180/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.1769 - val_loss: 0.0321 - val_mape: 103.4295\n",
      "Epoch 181/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1681.0321 - val_loss: 0.0321 - val_mape: 103.4190\n",
      "Epoch 182/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0295 - mape: 1680.8565 - val_loss: 0.0321 - val_mape: 103.4069\n",
      "Epoch 183/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1680.6420 - val_loss: 0.0321 - val_mape: 103.3924\n",
      "Epoch 184/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1680.3285 - val_loss: 0.0321 - val_mape: 103.3711\n",
      "Epoch 185/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1679.9411 - val_loss: 0.0321 - val_mape: 103.3440\n",
      "Epoch 186/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1679.5899 - val_loss: 0.0321 - val_mape: 103.3202\n",
      "Epoch 187/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1679.2669 - val_loss: 0.0321 - val_mape: 103.3005\n",
      "Epoch 188/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.9844 - val_loss: 0.0321 - val_mape: 103.2810\n",
      "Epoch 189/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.8541 - val_loss: 0.0321 - val_mape: 103.2733\n",
      "Epoch 190/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.7885 - val_loss: 0.0321 - val_mape: 103.2679\n",
      "Epoch 191/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.7288 - val_loss: 0.0321 - val_mape: 103.2606\n",
      "Epoch 192/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.6730 - val_loss: 0.0321 - val_mape: 103.2600\n",
      "Epoch 193/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.6865 - val_loss: 0.0321 - val_mape: 103.2549\n",
      "Epoch 194/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.7429 - val_loss: 0.0321 - val_mape: 103.2572\n",
      "Epoch 195/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.8101 - val_loss: 0.0321 - val_mape: 103.2611\n",
      "Epoch 196/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.8796 - val_loss: 0.0321 - val_mape: 103.2636\n",
      "Epoch 197/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1678.9344 - val_loss: 0.0321 - val_mape: 103.2662\n",
      "Epoch 198/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1679.0475 - val_loss: 0.0321 - val_mape: 103.2705\n",
      "Epoch 199/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1679.1084 - val_loss: 0.0321 - val_mape: 103.2763\n",
      "Epoch 200/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0294 - mape: 1679.1729 - val_loss: 0.0321 - val_mape: 103.2786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0412 - mape: 91.7867\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 12ms/step - loss: 0.0473 - mape: 191.5218 - val_loss: 0.0437 - val_mape: 89.1341\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0453 - mape: 300.0169 - val_loss: 0.0417 - val_mape: 78.0430\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0433 - mape: 409.0652 - val_loss: 0.0399 - val_mape: 69.6820\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0416 - mape: 519.4306 - val_loss: 0.0383 - val_mape: 65.7077\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0400 - mape: 630.0033 - val_loss: 0.0370 - val_mape: 64.2973\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0386 - mape: 740.5307 - val_loss: 0.0359 - val_mape: 64.9133\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0373 - mape: 851.0353 - val_loss: 0.0350 - val_mape: 66.7888\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0361 - mape: 960.1912 - val_loss: 0.0342 - val_mape: 69.6779\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0350 - mape: 1065.4186 - val_loss: 0.0337 - val_mape: 73.3582\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0341 - mape: 1165.8146 - val_loss: 0.0333 - val_mape: 77.5677\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0334 - mape: 1258.8266 - val_loss: 0.0330 - val_mape: 81.8647\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0328 - mape: 1345.0348 - val_loss: 0.0328 - val_mape: 86.2265\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0323 - mape: 1426.0671 - val_loss: 0.0326 - val_mape: 90.5119\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0318 - mape: 1500.3948 - val_loss: 0.0325 - val_mape: 94.5438\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0315 - mape: 1567.9805 - val_loss: 0.0325 - val_mape: 98.4045\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0312 - mape: 1628.4392 - val_loss: 0.0324 - val_mape: 101.9092\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0311 - mape: 1680.8196 - val_loss: 0.0324 - val_mape: 105.0331\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0309 - mape: 1723.4161 - val_loss: 0.0324 - val_mape: 107.5976\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0308 - mape: 1755.8987 - val_loss: 0.0324 - val_mape: 109.4807\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0308 - mape: 1780.0832 - val_loss: 0.0324 - val_mape: 110.9617\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 1798.1940 - val_loss: 0.0324 - val_mape: 112.0564\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 1812.6225 - val_loss: 0.0324 - val_mape: 112.8317\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 1823.3054 - val_loss: 0.0324 - val_mape: 113.4767\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 1833.3667 - val_loss: 0.0324 - val_mape: 114.0833\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0306 - mape: 1841.6626 - val_loss: 0.0324 - val_mape: 114.5747\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0306 - mape: 1847.8642 - val_loss: 0.0324 - val_mape: 114.9124\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0306 - mape: 1852.3535 - val_loss: 0.0324 - val_mape: 115.1257\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0360 - mape: 102.8307\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 12ms/step - loss: 0.0471 - mape: 97.8144 - val_loss: 0.0440 - val_mape: 89.6004\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0453 - mape: 88.4234 - val_loss: 0.0420 - val_mape: 78.9060\n",
      "Epoch 3/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0434 - mape: 79.9701 - val_loss: 0.0402 - val_mape: 70.3493\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0417 - mape: 75.0524 - val_loss: 0.0387 - val_mape: 66.0350\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0402 - mape: 72.4806 - val_loss: 0.0375 - val_mape: 64.2236\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0388 - mape: 71.2201 - val_loss: 0.0364 - val_mape: 64.4895\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0375 - mape: 70.8471 - val_loss: 0.0355 - val_mape: 65.9555\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0364 - mape: 71.2315 - val_loss: 0.0347 - val_mape: 68.4134\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0353 - mape: 72.2540 - val_loss: 0.0340 - val_mape: 71.6754\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0344 - mape: 73.8462 - val_loss: 0.0336 - val_mape: 75.5560\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0336 - mape: 75.8333 - val_loss: 0.0332 - val_mape: 79.8638\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0329 - mape: 78.1562 - val_loss: 0.0330 - val_mape: 84.3537\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0323 - mape: 80.7016 - val_loss: 0.0328 - val_mape: 88.9436\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0318 - mape: 83.4234 - val_loss: 0.0327 - val_mape: 93.4770\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0314 - mape: 86.2211 - val_loss: 0.0326 - val_mape: 97.7688\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0311 - mape: 88.9810 - val_loss: 0.0325 - val_mape: 101.8659\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0308 - mape: 91.6452 - val_loss: 0.0325 - val_mape: 105.5727\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 94.0781 - val_loss: 0.0326 - val_mape: 108.6890\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0306 - mape: 96.1553 - val_loss: 0.0326 - val_mape: 111.1324\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 97.7889 - val_loss: 0.0326 - val_mape: 112.9973\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 99.1252 - val_loss: 0.0326 - val_mape: 114.5054\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 100.1823 - val_loss: 0.0326 - val_mape: 115.7174\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 101.0409 - val_loss: 0.0326 - val_mape: 116.7822\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 101.8196 - val_loss: 0.0326 - val_mape: 117.8056\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 102.5658 - val_loss: 0.0326 - val_mape: 118.7458\n",
      "Epoch 26/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 103.2508 - val_loss: 0.0327 - val_mape: 119.5837\n",
      "Epoch 27/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 103.8620 - val_loss: 0.0327 - val_mape: 120.3565\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0419 - mape: 31920.4531\n",
      "Epoch 1/200\n",
      "223/223 [==============================] - 6s 13ms/step - loss: 0.0472 - mape: 97.9750 - val_loss: 0.0526 - val_mape: 1762.9838\n",
      "Epoch 2/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0455 - mape: 89.4011 - val_loss: 0.0508 - val_mape: 3481.5938\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0437 - mape: 81.3284 - val_loss: 0.0491 - val_mape: 5212.4189\n",
      "Epoch 4/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0421 - mape: 76.0845 - val_loss: 0.0475 - val_mape: 6852.0664\n",
      "Epoch 5/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0407 - mape: 73.1933 - val_loss: 0.0462 - val_mape: 8453.2295\n",
      "Epoch 6/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0394 - mape: 71.6614 - val_loss: 0.0451 - val_mape: 10058.7578\n",
      "Epoch 7/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0382 - mape: 70.9313 - val_loss: 0.0441 - val_mape: 11663.7871\n",
      "Epoch 8/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0371 - mape: 70.9064 - val_loss: 0.0432 - val_mape: 13268.5195\n",
      "Epoch 9/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0360 - mape: 71.4856 - val_loss: 0.0426 - val_mape: 14850.4902\n",
      "Epoch 10/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0351 - mape: 72.5944 - val_loss: 0.0420 - val_mape: 16374.0869\n",
      "Epoch 11/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0342 - mape: 74.1558 - val_loss: 0.0416 - val_mape: 17828.6270\n",
      "Epoch 12/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0335 - mape: 76.0422 - val_loss: 0.0414 - val_mape: 19231.7891\n",
      "Epoch 13/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0329 - mape: 78.2099 - val_loss: 0.0412 - val_mape: 20586.1406\n",
      "Epoch 14/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0323 - mape: 80.5696 - val_loss: 0.0412 - val_mape: 21891.7910\n",
      "Epoch 15/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0318 - mape: 83.0885 - val_loss: 0.0412 - val_mape: 23128.7500\n",
      "Epoch 16/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0315 - mape: 85.6894 - val_loss: 0.0412 - val_mape: 24266.6406\n",
      "Epoch 17/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0312 - mape: 88.2823 - val_loss: 0.0412 - val_mape: 25312.9824\n",
      "Epoch 18/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0309 - mape: 90.7891 - val_loss: 0.0413 - val_mape: 26254.5254\n",
      "Epoch 19/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0307 - mape: 93.1542 - val_loss: 0.0414 - val_mape: 27079.5332\n",
      "Epoch 20/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0306 - mape: 95.2842 - val_loss: 0.0414 - val_mape: 27730.8965\n",
      "Epoch 21/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0306 - mape: 96.9914 - val_loss: 0.0415 - val_mape: 28232.2969\n",
      "Epoch 22/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 98.3866 - val_loss: 0.0415 - val_mape: 28630.7480\n",
      "Epoch 23/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 99.5268 - val_loss: 0.0416 - val_mape: 28967.2988\n",
      "Epoch 24/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0305 - mape: 100.5039 - val_loss: 0.0416 - val_mape: 29247.3516\n",
      "Epoch 25/200\n",
      "223/223 [==============================] - 2s 10ms/step - loss: 0.0304 - mape: 101.3211 - val_loss: 0.0417 - val_mape: 29494.5801\n",
      "159/159 [==============================] - 0s 2ms/step - loss: 0.0316 - mape: 95.1879\n",
      "Epoch 1/200\n",
      "278/278 [==============================] - 4s 10ms/step - loss: 0.0332 - mape: 565.3765 - val_loss: 0.0362 - val_mape: 4311.9487\n",
      "Epoch 2/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0288 - mape: 622.6702 - val_loss: 0.0338 - val_mape: 3953.1216\n",
      "Epoch 3/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0269 - mape: 809.0133 - val_loss: 0.0288 - val_mape: 4144.1553\n",
      "Epoch 4/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0246 - mape: 636.9796 - val_loss: 0.0269 - val_mape: 4209.7681\n",
      "Epoch 5/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0233 - mape: 674.4731 - val_loss: 0.0274 - val_mape: 4718.7520\n",
      "Epoch 6/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0231 - mape: 532.9597 - val_loss: 0.0258 - val_mape: 4348.2188\n",
      "Epoch 7/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0225 - mape: 648.9924 - val_loss: 0.0252 - val_mape: 4485.0117\n",
      "Epoch 8/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0223 - mape: 623.2891 - val_loss: 0.0257 - val_mape: 4430.1133\n",
      "Epoch 9/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0219 - mape: 606.7202 - val_loss: 0.0260 - val_mape: 4444.7349\n",
      "Epoch 10/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0222 - mape: 618.8844 - val_loss: 0.0245 - val_mape: 4326.1025\n",
      "Epoch 11/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0217 - mape: 597.8613 - val_loss: 0.0243 - val_mape: 4149.7344\n",
      "Epoch 12/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0217 - mape: 566.6324 - val_loss: 0.0238 - val_mape: 4421.8789\n",
      "Epoch 13/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0214 - mape: 546.9499 - val_loss: 0.0231 - val_mape: 4293.3813\n",
      "Epoch 14/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0213 - mape: 435.1224 - val_loss: 0.0226 - val_mape: 4442.2236\n",
      "Epoch 15/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0211 - mape: 530.0413 - val_loss: 0.0225 - val_mape: 4289.3872\n",
      "Epoch 16/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - mape: 509.1780 - val_loss: 0.0222 - val_mape: 4293.4214\n",
      "Epoch 17/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - mape: 457.1346 - val_loss: 0.0220 - val_mape: 4304.2656\n",
      "Epoch 18/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - mape: 489.8463 - val_loss: 0.0218 - val_mape: 4410.9893\n",
      "Epoch 19/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0210 - mape: 447.9964 - val_loss: 0.0219 - val_mape: 4375.2871\n",
      "Epoch 20/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - mape: 428.0296 - val_loss: 0.0217 - val_mape: 4400.1338\n",
      "Epoch 21/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - mape: 462.6342 - val_loss: 0.0222 - val_mape: 4399.4229\n",
      "Epoch 22/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - mape: 385.2738 - val_loss: 0.0225 - val_mape: 4440.1440\n",
      "Epoch 23/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0209 - mape: 463.6443 - val_loss: 0.0222 - val_mape: 4212.6133\n",
      "Epoch 24/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - mape: 484.3396 - val_loss: 0.0242 - val_mape: 4357.9263\n",
      "Epoch 25/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0212 - mape: 425.7106 - val_loss: 0.0217 - val_mape: 4482.8599\n",
      "Epoch 26/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - mape: 451.9339 - val_loss: 0.0212 - val_mape: 4517.9224\n",
      "Epoch 27/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0207 - mape: 475.9903 - val_loss: 0.0210 - val_mape: 4464.1953\n",
      "Epoch 28/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0204 - mape: 496.5170 - val_loss: 0.0221 - val_mape: 4313.1396\n",
      "Epoch 29/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - mape: 443.0293 - val_loss: 0.0210 - val_mape: 4613.4199\n",
      "Epoch 30/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0203 - mape: 450.6190 - val_loss: 0.0208 - val_mape: 4370.9072\n",
      "Epoch 31/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0204 - mape: 468.1844 - val_loss: 0.0212 - val_mape: 4322.7300\n",
      "Epoch 32/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0205 - mape: 451.2927 - val_loss: 0.0240 - val_mape: 4106.5728\n",
      "Epoch 33/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0206 - mape: 392.2166 - val_loss: 0.0210 - val_mape: 4322.8916\n",
      "Epoch 34/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - mape: 444.9367 - val_loss: 0.0223 - val_mape: 4335.2100\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 [==============================] - 3s 9ms/step - loss: 0.0203 - mape: 433.3241 - val_loss: 0.0211 - val_mape: 4667.6929\n",
      "Epoch 36/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0203 - mape: 436.0148 - val_loss: 0.0210 - val_mape: 4245.3618\n",
      "Epoch 37/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0204 - mape: 484.7261 - val_loss: 0.0209 - val_mape: 4295.2705\n",
      "Epoch 38/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0201 - mape: 412.3691 - val_loss: 0.0210 - val_mape: 4251.1855\n",
      "Epoch 39/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0202 - mape: 352.3667 - val_loss: 0.0209 - val_mape: 4193.7749\n",
      "Epoch 40/200\n",
      "278/278 [==============================] - 2s 9ms/step - loss: 0.0200 - mape: 396.6330 - val_loss: 0.0210 - val_mape: 4359.1562\n",
      "{'n_neurons': 174, 'n_hidden': 3, 'learning_rate': 0.0003}\n",
      "score: -0.023978834599256517\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=50, learning_rate=1e-1, input_shape=(train_X.shape[1], train_X.shape[2])):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    model.add(layers.Conv1D(filters = 48, kernel_size = 3, padding='same', \n",
    "                            activation='relu', kernel_initializer =\"glorot_uniform\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(layers.Conv1D(filters = 32, kernel_size = 3, padding='same', \n",
    "                            activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(layers.Conv1D(filters = 16, kernel_size = 3, padding ='same', \n",
    "                            activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(layers.LSTM(n_neurons, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    #model.add(layers.Dropout(0.5))\n",
    "    #model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mae', metrics=['mape'])\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "param_distribs= {\n",
    "    \"n_hidden\": np.arange(1, 10).tolist(),\n",
    "    \"n_neurons\": np.arange(1, 500).tolist(),\n",
    "    \"learning_rate\": [3e-1, 3e-2, 3e-3, 3e-4, 3e-5, 3e-6],\n",
    "}\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('load_forecasting_New_best.h5', save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=5)\n",
    "rnd_search_cv.fit(train_X, train_y, epochs=200, validation_split=0.3, shuffle=False, batch_size=64,\n",
    "                  callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "\n",
    "\n",
    "print(rnd_search_cv.best_params_)\n",
    "print('score:', rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d84a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "263/263 - 8s - loss: 0.0438 - mse: 0.0053 - val_loss: 0.0365 - val_mse: 0.0072\n",
      "Epoch 2/100\n",
      "263/263 - 3s - loss: 0.0360 - mse: 0.0040 - val_loss: 0.0362 - val_mse: 0.0066\n",
      "Epoch 3/100\n",
      "263/263 - 3s - loss: 0.0348 - mse: 0.0038 - val_loss: 0.0364 - val_mse: 0.0065\n",
      "Epoch 4/100\n",
      "263/263 - 3s - loss: 0.0345 - mse: 0.0037 - val_loss: 0.0360 - val_mse: 0.0064\n",
      "Epoch 5/100\n",
      "263/263 - 2s - loss: 0.0334 - mse: 0.0035 - val_loss: 0.0342 - val_mse: 0.0064\n",
      "Epoch 6/100\n",
      "263/263 - 3s - loss: 0.0318 - mse: 0.0034 - val_loss: 0.0329 - val_mse: 0.0064\n",
      "Epoch 7/100\n",
      "263/263 - 3s - loss: 0.0313 - mse: 0.0034 - val_loss: 0.0323 - val_mse: 0.0063\n",
      "Epoch 8/100\n",
      "263/263 - 2s - loss: 0.0310 - mse: 0.0033 - val_loss: 0.0319 - val_mse: 0.0062\n",
      "Epoch 9/100\n",
      "263/263 - 3s - loss: 0.0308 - mse: 0.0033 - val_loss: 0.0318 - val_mse: 0.0062\n",
      "Epoch 10/100\n",
      "263/263 - 3s - loss: 0.0307 - mse: 0.0033 - val_loss: 0.0314 - val_mse: 0.0061\n",
      "Epoch 11/100\n",
      "263/263 - 3s - loss: 0.0304 - mse: 0.0032 - val_loss: 0.0312 - val_mse: 0.0061\n",
      "Epoch 12/100\n",
      "263/263 - 2s - loss: 0.0302 - mse: 0.0032 - val_loss: 0.0309 - val_mse: 0.0060\n",
      "Epoch 13/100\n",
      "263/263 - 2s - loss: 0.0299 - mse: 0.0032 - val_loss: 0.0307 - val_mse: 0.0060\n",
      "Epoch 14/100\n",
      "263/263 - 3s - loss: 0.0297 - mse: 0.0032 - val_loss: 0.0306 - val_mse: 0.0059\n",
      "Epoch 15/100\n",
      "263/263 - 2s - loss: 0.0296 - mse: 0.0031 - val_loss: 0.0302 - val_mse: 0.0058\n",
      "Epoch 16/100\n",
      "263/263 - 2s - loss: 0.0292 - mse: 0.0031 - val_loss: 0.0299 - val_mse: 0.0058\n",
      "Epoch 17/100\n",
      "263/263 - 2s - loss: 0.0289 - mse: 0.0030 - val_loss: 0.0296 - val_mse: 0.0057\n",
      "Epoch 18/100\n",
      "263/263 - 2s - loss: 0.0285 - mse: 0.0030 - val_loss: 0.0293 - val_mse: 0.0056\n",
      "Epoch 19/100\n",
      "263/263 - 2s - loss: 0.0282 - mse: 0.0029 - val_loss: 0.0290 - val_mse: 0.0055\n",
      "Epoch 20/100\n",
      "263/263 - 3s - loss: 0.0277 - mse: 0.0029 - val_loss: 0.0286 - val_mse: 0.0053\n",
      "Epoch 21/100\n",
      "263/263 - 3s - loss: 0.0275 - mse: 0.0028 - val_loss: 0.0281 - val_mse: 0.0052\n",
      "Epoch 22/100\n",
      "263/263 - 2s - loss: 0.0270 - mse: 0.0027 - val_loss: 0.0277 - val_mse: 0.0050\n",
      "Epoch 23/100\n",
      "263/263 - 3s - loss: 0.0266 - mse: 0.0027 - val_loss: 0.0273 - val_mse: 0.0048\n",
      "Epoch 24/100\n",
      "263/263 - 3s - loss: 0.0263 - mse: 0.0026 - val_loss: 0.0269 - val_mse: 0.0048\n",
      "Epoch 25/100\n",
      "263/263 - 3s - loss: 0.0255 - mse: 0.0025 - val_loss: 0.0263 - val_mse: 0.0045\n",
      "Epoch 26/100\n",
      "263/263 - 3s - loss: 0.0252 - mse: 0.0025 - val_loss: 0.0260 - val_mse: 0.0045\n",
      "Epoch 27/100\n",
      "263/263 - 2s - loss: 0.0249 - mse: 0.0024 - val_loss: 0.0254 - val_mse: 0.0043\n",
      "Epoch 28/100\n",
      "263/263 - 3s - loss: 0.0247 - mse: 0.0024 - val_loss: 0.0252 - val_mse: 0.0042\n",
      "Epoch 29/100\n",
      "263/263 - 2s - loss: 0.0243 - mse: 0.0023 - val_loss: 0.0248 - val_mse: 0.0041\n",
      "Epoch 30/100\n",
      "263/263 - 3s - loss: 0.0238 - mse: 0.0023 - val_loss: 0.0249 - val_mse: 0.0042\n",
      "Epoch 31/100\n",
      "263/263 - 3s - loss: 0.0237 - mse: 0.0022 - val_loss: 0.0243 - val_mse: 0.0040\n",
      "Epoch 32/100\n",
      "263/263 - 3s - loss: 0.0234 - mse: 0.0022 - val_loss: 0.0243 - val_mse: 0.0040\n",
      "Epoch 33/100\n",
      "263/263 - 2s - loss: 0.0233 - mse: 0.0022 - val_loss: 0.0241 - val_mse: 0.0040\n",
      "Epoch 34/100\n",
      "263/263 - 2s - loss: 0.0231 - mse: 0.0021 - val_loss: 0.0239 - val_mse: 0.0039\n",
      "Epoch 35/100\n",
      "263/263 - 2s - loss: 0.0230 - mse: 0.0021 - val_loss: 0.0237 - val_mse: 0.0039\n",
      "Epoch 36/100\n",
      "263/263 - 2s - loss: 0.0229 - mse: 0.0021 - val_loss: 0.0239 - val_mse: 0.0039\n",
      "Epoch 37/100\n",
      "263/263 - 2s - loss: 0.0228 - mse: 0.0021 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 38/100\n",
      "263/263 - 2s - loss: 0.0227 - mse: 0.0020 - val_loss: 0.0235 - val_mse: 0.0038\n",
      "Epoch 39/100\n",
      "263/263 - 2s - loss: 0.0226 - mse: 0.0020 - val_loss: 0.0235 - val_mse: 0.0038\n",
      "Epoch 40/100\n",
      "263/263 - 2s - loss: 0.0226 - mse: 0.0020 - val_loss: 0.0235 - val_mse: 0.0038\n",
      "Epoch 41/100\n",
      "263/263 - 3s - loss: 0.0226 - mse: 0.0020 - val_loss: 0.0236 - val_mse: 0.0039\n",
      "Epoch 42/100\n",
      "263/263 - 2s - loss: 0.0224 - mse: 0.0020 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 43/100\n",
      "263/263 - 2s - loss: 0.0224 - mse: 0.0020 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 44/100\n",
      "263/263 - 3s - loss: 0.0224 - mse: 0.0020 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 45/100\n",
      "263/263 - 3s - loss: 0.0224 - mse: 0.0020 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 46/100\n",
      "263/263 - 3s - loss: 0.0224 - mse: 0.0020 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 47/100\n",
      "263/263 - 2s - loss: 0.0221 - mse: 0.0020 - val_loss: 0.0232 - val_mse: 0.0037\n",
      "Epoch 48/100\n",
      "263/263 - 2s - loss: 0.0222 - mse: 0.0020 - val_loss: 0.0232 - val_mse: 0.0037\n",
      "Epoch 49/100\n",
      "263/263 - 2s - loss: 0.0222 - mse: 0.0020 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 50/100\n",
      "263/263 - 3s - loss: 0.0221 - mse: 0.0020 - val_loss: 0.0232 - val_mse: 0.0037\n",
      "Epoch 51/100\n",
      "263/263 - 2s - loss: 0.0221 - mse: 0.0020 - val_loss: 0.0232 - val_mse: 0.0038\n",
      "Epoch 52/100\n",
      "263/263 - 2s - loss: 0.0221 - mse: 0.0020 - val_loss: 0.0238 - val_mse: 0.0039\n",
      "Epoch 53/100\n",
      "263/263 - 2s - loss: 0.0218 - mse: 0.0019 - val_loss: 0.0232 - val_mse: 0.0038\n",
      "Epoch 54/100\n",
      "263/263 - 2s - loss: 0.0219 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 55/100\n",
      "263/263 - 2s - loss: 0.0219 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 56/100\n",
      "263/263 - 3s - loss: 0.0219 - mse: 0.0019 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 57/100\n",
      "263/263 - 2s - loss: 0.0218 - mse: 0.0019 - val_loss: 0.0230 - val_mse: 0.0037\n",
      "Epoch 58/100\n",
      "263/263 - 3s - loss: 0.0217 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 59/100\n",
      "263/263 - 2s - loss: 0.0217 - mse: 0.0019 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 60/100\n",
      "263/263 - 3s - loss: 0.0217 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 61/100\n",
      "263/263 - 2s - loss: 0.0217 - mse: 0.0019 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 62/100\n",
      "263/263 - 2s - loss: 0.0216 - mse: 0.0019 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 63/100\n",
      "263/263 - 2s - loss: 0.0217 - mse: 0.0019 - val_loss: 0.0235 - val_mse: 0.0038\n",
      "Epoch 64/100\n",
      "263/263 - 2s - loss: 0.0217 - mse: 0.0019 - val_loss: 0.0238 - val_mse: 0.0039\n",
      "Epoch 65/100\n",
      "263/263 - 2s - loss: 0.0215 - mse: 0.0019 - val_loss: 0.0230 - val_mse: 0.0037\n",
      "Epoch 66/100\n",
      "263/263 - 2s - loss: 0.0215 - mse: 0.0019 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 67/100\n",
      "263/263 - 2s - loss: 0.0214 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 68/100\n",
      "263/263 - 2s - loss: 0.0214 - mse: 0.0018 - val_loss: 0.0232 - val_mse: 0.0037\n",
      "Epoch 69/100\n",
      "263/263 - 2s - loss: 0.0215 - mse: 0.0019 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 70/100\n",
      "263/263 - 2s - loss: 0.0214 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 71/100\n",
      "263/263 - 2s - loss: 0.0214 - mse: 0.0019 - val_loss: 0.0230 - val_mse: 0.0037\n",
      "Epoch 72/100\n",
      "263/263 - 2s - loss: 0.0215 - mse: 0.0019 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 73/100\n",
      "263/263 - 2s - loss: 0.0213 - mse: 0.0019 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 74/100\n",
      "263/263 - 2s - loss: 0.0213 - mse: 0.0018 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 75/100\n",
      "263/263 - 2s - loss: 0.0213 - mse: 0.0019 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 76/100\n",
      "263/263 - 2s - loss: 0.0213 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 77/100\n",
      "263/263 - 2s - loss: 0.0213 - mse: 0.0018 - val_loss: 0.0232 - val_mse: 0.0038\n",
      "Epoch 78/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0019 - val_loss: 0.0230 - val_mse: 0.0037\n",
      "Epoch 79/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 80/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0018 - val_loss: 0.0230 - val_mse: 0.0037\n",
      "Epoch 81/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0018 - val_loss: 0.0235 - val_mse: 0.0038\n",
      "Epoch 82/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0019 - val_loss: 0.0235 - val_mse: 0.0038\n",
      "Epoch 83/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 84/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 85/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0232 - val_mse: 0.0038\n",
      "Epoch 86/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0230 - val_mse: 0.0037\n",
      "Epoch 87/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0233 - val_mse: 0.0038\n",
      "Epoch 88/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 89/100\n",
      "263/263 - 2s - loss: 0.0212 - mse: 0.0018 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 90/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0232 - val_mse: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 92/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0229 - val_mse: 0.0037\n",
      "Epoch 93/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0232 - val_mse: 0.0038\n",
      "Epoch 94/100\n",
      "263/263 - 2s - loss: 0.0211 - mse: 0.0018 - val_loss: 0.0233 - val_mse: 0.0037\n",
      "Epoch 95/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0234 - val_mse: 0.0038\n",
      "Epoch 96/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0231 - val_mse: 0.0037\n",
      "Epoch 97/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0232 - val_mse: 0.0038\n",
      "Epoch 98/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0231 - val_mse: 0.0038\n",
      "Epoch 99/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0231 - val_mse: 0.0038\n",
      "Epoch 100/100\n",
      "263/263 - 2s - loss: 0.0210 - mse: 0.0018 - val_loss: 0.0228 - val_mse: 0.0037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (None, 48)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-260e7cd2eb6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hours\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# invert scaling for forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:259 assert_input_compatibility\n        ' but received input with shape ' + display_shape(x.shape))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected axis -1 of input shape to have value 8 but received input with shape (None, 48)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "{'n_neurons': 123, 'n_hidden': 5, 'learning_rate': 3e-05} n_hours = 6\n",
    "score: -0.022615093365311624\n",
    "'''\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(layers.Conv1D(filters = 48, kernel_size = 3, padding='same', \n",
    "                        activation='relu', kernel_initializer =\"glorot_uniform\"))\n",
    "model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(layers.Conv1D(filters = 32, kernel_size = 3, padding='same', \n",
    "                        activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
    "model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(layers.Conv1D(filters = 16, kernel_size = 3, padding='same', \n",
    "                        activation='relu', kernel_initializer=\"glorot_uniform\"))\n",
    "model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(LSTM(123, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(123, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(123, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(123, return_sequences=True, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(LSTM(123, return_sequences=False, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "#model.add(Dense(32, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "optimizer = optimizers.Adam(learning_rate=3e-05)\n",
    "model.compile(loss='mae', metrics=['mse'], optimizer=optimizer)\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=100, batch_size=64, validation_split=0.3, \n",
    "                     verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='valiation')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours*n_features))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, -7:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, -7:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)\n",
    "print(mean_absolute_error(inv_y, inv_yhat))\n",
    "print(mean_absolute_percentage_error(inv_y, inv_yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558eb17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
