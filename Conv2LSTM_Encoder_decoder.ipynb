{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb13700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1349/1349 - 44s - loss: 44.2817 - mape: 3.8878 - val_loss: 2.2605 - val_mape: 0.1985\n",
      "Epoch 2/20\n",
      "1349/1349 - 38s - loss: 8.1492 - mape: 0.7155 - val_loss: 8.5799 - val_mape: 0.7533\n",
      "Epoch 3/20\n",
      "1349/1349 - 38s - loss: 8.6749 - mape: 0.7616 - val_loss: 2.4556 - val_mape: 0.2156\n",
      "Epoch 4/20\n",
      "1349/1349 - 38s - loss: 8.0575 - mape: 0.7074 - val_loss: 2.4032 - val_mape: 0.2110\n",
      "Epoch 5/20\n",
      "1349/1349 - 39s - loss: 18.3414 - mape: 1.6103 - val_loss: 9.1482 - val_mape: 0.8032\n",
      "Epoch 6/20\n",
      "1349/1349 - 39s - loss: 10.1297 - mape: 0.8893 - val_loss: 8.1475 - val_mape: 0.7153\n",
      "Epoch 7/20\n",
      "1349/1349 - 41s - loss: 8.2256 - mape: 0.7222 - val_loss: 11.3219 - val_mape: 0.9940\n",
      "Epoch 8/20\n",
      "1349/1349 - 38s - loss: 6.8387 - mape: 0.6004 - val_loss: 10.5281 - val_mape: 0.9243\n",
      "Epoch 9/20\n",
      "1349/1349 - 30s - loss: 7.5598 - mape: 0.6637 - val_loss: 3.9110 - val_mape: 0.3434\n",
      "Epoch 10/20\n",
      "1349/1349 - 35s - loss: 7.0911 - mape: 0.6226 - val_loss: 1.3932 - val_mape: 0.1223\n",
      "Epoch 11/20\n",
      "1349/1349 - 35s - loss: 7.0071 - mape: 0.6152 - val_loss: 4.7999 - val_mape: 0.4214\n",
      "Epoch 12/20\n",
      "1349/1349 - 35s - loss: 6.8495 - mape: 0.6014 - val_loss: 6.1586 - val_mape: 0.5407\n",
      "Epoch 13/20\n",
      "1349/1349 - 35s - loss: 6.9517 - mape: 0.6103 - val_loss: 12.8939 - val_mape: 1.1320\n",
      "Epoch 14/20\n",
      "1349/1349 - 36s - loss: 6.3056 - mape: 0.5536 - val_loss: 5.1945 - val_mape: 0.4561\n",
      "Epoch 15/20\n",
      "1349/1349 - 35s - loss: 6.6740 - mape: 0.5860 - val_loss: 7.3304 - val_mape: 0.6436\n",
      "Epoch 16/20\n",
      "1349/1349 - 35s - loss: 6.3658 - mape: 0.5589 - val_loss: 3.1509 - val_mape: 0.2766\n",
      "Epoch 17/20\n",
      "1349/1349 - 34s - loss: 5.5455 - mape: 0.4869 - val_loss: 3.6285 - val_mape: 0.3186\n",
      "Epoch 18/20\n",
      "1349/1349 - 35s - loss: 6.0482 - mape: 0.5310 - val_loss: 8.5938 - val_mape: 0.7545\n",
      "Epoch 19/20\n",
      "1349/1349 - 34s - loss: 6.5719 - mape: 0.5770 - val_loss: 7.0519 - val_mape: 0.6191\n",
      "Epoch 20/20\n",
      "1349/1349 - 34s - loss: 5.4326 - mape: 0.4770 - val_loss: 0.6758 - val_mape: 0.0593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qcraft/Documents/Fan/miniconda3/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:97: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-501dc72cca6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0mn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_length\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;31m# summarize scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0msummarize_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-501dc72cca6a>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(train, test, n_steps, n_length, n_input)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;31m# predict the week\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                 \u001b[0myhat_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                 \u001b[0;31m# store the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-501dc72cca6a>\u001b[0m in \u001b[0;36mforecast\u001b[0;34m(model, history, n_steps, n_length, n_input)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# flatten data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m# retrieve last observations for input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0minput_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# univariate multi-step encoder-decoder convlstm\n",
    "from math import sqrt\n",
    "from numpy import split\n",
    "from numpy import array\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import ConvLSTM2D\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def split_dataset(data):\n",
    "\t# split into dataset\n",
    "\ttrain, test = data[1:24001], data[24001:-2]\n",
    "\t# restructure into windows of daily data\n",
    "\ttrain = array(split(train, len(train)/48))\n",
    "\ttest = array(split(test, len(test)/48))\n",
    "\treturn train, test\n",
    "\n",
    "# evaluate one or more weekly forecasts against expected values\n",
    "def evaluate_forecasts(actual, predicted):\n",
    "\tscores = list()\n",
    "\t# calculate an RMSE score for each day\n",
    "\tfor i in range(actual.shape[1]):\n",
    "\t\t# calculate mse\n",
    "\t\tmse = mean_squared_error(actual[:, i], predicted[:, i])\n",
    "\t\t# calculate rmse\n",
    "\t\trmse = sqrt(mse)\n",
    "\t\t# store\n",
    "\t\tscores.append(rmse)\n",
    "\t# calculate overall RMSE\n",
    "\ts = 0\n",
    "\tfor row in range(actual.shape[0]):\n",
    "\t\tfor col in range(actual.shape[1]):\n",
    "\t\t\ts += (actual[row, col] - predicted[row, col])**2\n",
    "\tscore = sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "\treturn score, scores\n",
    "\n",
    "# summarize scores\n",
    "def summarize_scores(name, score, scores):\n",
    "\ts_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "\tprint('%s: [%.3f] %s' % (name, score, s_scores))\n",
    "\n",
    "# convert history into inputs and outputs\n",
    "def to_supervised(train, n_input, n_out=12):\n",
    "\t# flatten data\n",
    "\tdata = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "\tX, y = list(), list()\n",
    "\tin_start = 0\n",
    "\t# step over the entire history one time step at a time\n",
    "\tfor _ in range(len(data)):\n",
    "\t\t# define the end of the input sequence\n",
    "\t\tin_end = in_start + n_input\n",
    "\t\tout_end = in_end + n_out\n",
    "\t\t# ensure we have enough data for this instance\n",
    "\t\tif out_end <= len(data):\n",
    "\t\t\tx_input = data[in_start:in_end, 0]\n",
    "\t\t\tx_input = x_input.reshape((len(x_input), 1))\n",
    "\t\t\tX.append(x_input)\n",
    "\t\t\ty.append(data[in_end:out_end, 0])\n",
    "\t\t# move along one time step\n",
    "\t\tin_start += 1\n",
    "\treturn array(X), array(y)\n",
    "\n",
    "# train the model\n",
    "def build_model(train, n_steps, n_length, n_input):\n",
    "\t# prepare data\n",
    "\ttrain_x, train_y = to_supervised(train, n_input)\n",
    "\t# define parameters\n",
    "\tverbose, epochs, batch_size = 2, 20, 16\n",
    "\tn_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "\t# reshape into subsequences [samples, time steps, rows, cols, channels]\n",
    "\ttrain_x = train_x.reshape((train_x.shape[0], n_steps, 1, n_length, n_features))\n",
    "\t# reshape output into [samples, timesteps, features]\n",
    "\ttrain_y = train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(RepeatVector(n_outputs))\n",
    "\tmodel.add(LSTM(200, activation='relu', return_sequences=True))\n",
    "\tmodel.add(TimeDistributed(Dense(100, activation='relu')))\n",
    "\tmodel.add(TimeDistributed(Dense(1)))\n",
    "\tmodel.compile(loss='mae', metrics=['mape'], optimizer='adam')\n",
    "\t# fit network\n",
    "\tmodel.fit(train_x, train_y, epochs=epochs, validation_split=0.1, batch_size=batch_size, verbose=verbose)\n",
    "\treturn model\n",
    "\n",
    "# make a forecast\n",
    "def forecast(model, history, n_steps, n_length, n_input):\n",
    "\t# flatten data\n",
    "\tdata = array(history)\n",
    "\tdata = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "\t# retrieve last observations for input data\n",
    "\tinput_x = data[-n_input:, 0]\n",
    "\t# reshape into [samples, time steps, rows, cols, channels]\n",
    "\tinput_x = input_x.reshape((1, n_steps, 1, n_length, 1))\n",
    "\t# forecast the next week\n",
    "\tyhat = model.predict(input_x, verbose=0)\n",
    "\t# we only want the vector forecast\n",
    "\tyhat = yhat[0]\n",
    "\treturn yhat\n",
    "\n",
    "# evaluate a single model\n",
    "def evaluate_model(train, test, n_steps, n_length, n_input):\n",
    "\t# fit model\n",
    "\tmodel = build_model(train, n_steps, n_length, n_input)\n",
    "\t# history is a list of weekly data\n",
    "\thistory = [x for x in train]\n",
    "\t# walk-forward validation over each week\n",
    "\tpredictions = list()\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# predict the week\n",
    "\t\tyhat_sequence = forecast(model, history, n_steps, n_length, n_input)\n",
    "\t\t# store the predictions\n",
    "\t\tpredictions.append(yhat_sequence)\n",
    "\t\t# get real observation and add to history for predicting the next week\n",
    "\t\thistory.append(test[i, :])\n",
    "\t# evaluate predictions days for each week\n",
    "\tpredictions = array(predictions)\n",
    "\tscore, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "\treturn score, scores\n",
    "\n",
    "# load the new file\n",
    "dataset = read_csv('CER_line_1139_clean.csv', header=0, index_col=0)\n",
    "# split into train and test\n",
    "train, test = split_dataset(dataset.values)\n",
    "# define the number of subsequences and the length of subsequences\n",
    "n_steps, n_length = 1, 12\n",
    "# define the total days to use as input\n",
    "n_input = n_length * n_steps\n",
    "score, scores = evaluate_model(train, test, n_steps, n_length, n_input)\n",
    "# summarize scores\n",
    "summarize_scores('lstm', score, scores)\n",
    "# plot scores\n",
    "pyplot.plot(days, scores, marker='o', label='lstm')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbf86eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
